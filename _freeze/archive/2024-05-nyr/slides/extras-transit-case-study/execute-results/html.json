{
  "hash": "ab0cf007fdfc7dcac22e6319151e49ee",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Case Study on Transportation\"\nsubtitle: \"Machine learning with tidymodels\"\nformat:\n  revealjs: \n    slide-number: true\n    footer: <https://workshops.tidymodels.org>\n    include-before-body: header.html\n    include-after-body: footer-annotations.html\n    theme: [default, tidymodels.scss]\n    width: 1280\n    height: 720\nknitr:\n  opts_chunk: \n    echo: true\n    collapse: true\n    comment: \"#>\"\n    fig.path: \"figures/\"\n---\n\n\n\n\n\n\n\n## Chicago L-Train data\n\nSeveral years worth of pre-pandemic data were assembled to try to predict the daily number of people entering the Clark and Lake elevated (\"L\") train station in Chicago. \n\n\nMore information: \n\n- Several Chapters in _Feature Engineering and Selection_. \n\n  - Start with [Section 4.1](https://bookdown.org/max/FES/chicago-intro.html) \n  - See [Section 1.3](https://bookdown.org/max/FES/a-more-complex-example.html)\n\n- Video: [_The Global Pandemic Ruined My Favorite Data Set_](https://www.youtube.com/watch?v=KkpKSqbGnBA)\n\n\n## Predictors\n\n- the 14-day lagged ridership at this and other stations (units: thousands of rides/day)\n- weather data\n- home/away game schedules for Chicago teams\n- the date\n\nThe data are in `modeldata`. See `?Chicago`. \n\n\n## L Train Locations\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"leaflet html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-b2d216597680820eeb24\" style=\"width:100%;height:480px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-b2d216597680820eeb24\">{\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addProviderTiles\",\"args\":[\"CartoDB.Positron\",null,null,{\"errorTileUrl\":\"\",\"noWrap\":false,\"detectRetina\":false}]},{\"method\":\"addCircleMarkers\",\"args\":[[41.870851,41.886848,41.885412,41.878723,42.04771,41.938132,41.878183,41.953775,41.966286,42.008362,41.829353,41.80209,42.038951,41.853732,41.8768,41.885269,41.872108,41.831191,41.884431,41.854517,41.875478,41.984246,41.750419,41.874341,41.88574,42.033456,41.887389,41.77886,41.821732,41.804546,41.903355,41.891665,41.977984,41.875474,41.943744,41.883164,41.874257,42.058282,41.85182,41.875539,41.854109,41.722377,41.888969,41.87592,41.886519,41.891189,41.8837,41.795172,42.05416,41.932732,41.964273,41.952925,41.878153,41.921939,41.85177331,41.909744,41.853751,41.887159,41.90392,41.882023,41.910655,41.918217,41.916157,41.879507,42.041655,41.887163,41.89681,41.780309,41.882695,41.854225,41.98227,41.993664,41.969139,41.853839,41.880703,41.910409,41.875706,41.983507,41.857908,42.027612,41.876862,41.966046,41.990259,41.97766526,42.019063,41.780536,41.873797,41.78661,41.778943,41.799756,41.871574,41.87349,41.768367,41.853206,41.966115,41.929728,41.871551,41.853964,42.073153,41.839234,41.884321,41.809209,41.880745,41.831677,41.84678,41.78013,41.804236,41.885678,41.79542,41.965996,42.015876,41.973453,41.936033,41.925051,41.810318,41.94738,42.063987,41.887293,41.816462,41.970634,41.967901,42.001073,41.943623,41.939751,41.961539,41.875568,41.886988,41.88422,41.983504,41.867405,41.896075,41.947428,41.735372,41.947028,41.896671,41.954521,41.966163,41.874039,41.961756,41.885586,41.884914,41.884809,41.884904,42.02624348,41.853115,41.88322],[-87.77681200000001,-87.80317599999999,-87.725404,-87.63374,-87.683543,-87.71235900000001,-87.629296,-87.654929,-87.678639,-87.665909,-87.680622,-87.618487,-87.751919,-87.724311,-87.631739,-87.66696899999999,-87.791602,-87.630636,-87.626149,-87.67597499999999,-87.688436,-87.83802799999999,-87.625112,-87.70604,-87.627835,-87.67953799999999,-87.76564999999999,-87.663766,-87.621371,-87.68401900000001,-87.666496,-87.628021,-87.65866800000001,-87.64970700000001,-87.663619,-87.62944,-87.817318,-87.68333699999999,-87.74533599999999,-87.640984,-87.694774,-87.624342,-87.63392399999999,-87.659458,-87.744698,-87.647578,-87.62779999999999,-87.61832699999999,-87.68356,-87.653131,-87.657588,-87.729229,-87.627596,-87.69689,-87.75669200999999,-87.677437,-87.73325800000001,-87.783661,-87.631412,-87.626098,-87.64917699999999,-87.652644,-87.687364,-87.626037,-87.681602,-87.754986,-87.635924,-87.605857,-87.63378,-87.685129,-87.80889999999999,-87.65920199999999,-87.65849300000001,-87.714842,-87.629378,-87.639302,-87.67393199999999,-87.859388,-87.669147,-87.67832900000001,-87.628196,-87.701644,-87.659076,-87.90422307,-87.672892,-87.63095199999999,-87.725663,-87.737875,-87.644244,-87.724493,-87.745154,-87.806961,-87.62572400000001,-87.630968,-87.69410000000001,-87.708541,-87.66952999999999,-87.70540800000001,-87.69073,-87.665317,-87.706155,-87.618826,-87.627696,-87.625826,-87.648088,-87.61554599999999,-87.70440600000001,-87.64178200000001,-87.631157,-87.708821,-87.66909200000001,-87.65853,-87.653266,-87.652866,-87.63094,-87.71906,-87.68561699999999,-87.774135,-87.619021,-87.760892,-87.713065,-87.661061,-87.670907,-87.65338,-87.743574,-87.631722,-87.793783,-87.696234,-87.65884,-87.62658999999999,-87.655214,-87.653626,-87.624717,-87.67464200000001,-87.628176,-87.674868,-87.688502,-87.62747899999999,-87.67504700000001,-87.652193,-87.711327,-87.627813,-87.716523,-87.74722084,-87.626402,-87.626189],3,null,null,{\"interactive\":true,\"className\":\"\",\"stroke\":true,\"color\":\"red\",\"weight\":5,\"opacity\":0.5,\"fill\":true,\"fillColor\":\"red\",\"fillOpacity\":0.2},null,null,[\"Austin (Blue Line)\",\"Harlem/Lake (Green Line)\",\"Pulaski (Green Line)\",\"Quincy/Wells (Brown, Orange, Purple & Pink Lines)\",\"Davis (Purple Line)\",\"Belmont (Blue Line)\",\"Jackson (Blue Line)\",\"Sheridan (Red Line)\",\"Damen (Brown Line)\",\"Morse (Red Line)\",\"35th/Archer (Orange Line)\",\"51st (Green Line)\",\"Dempster-Skokie  (Yellow Line)\",\"Pulaski (Pink Line)\",\"LaSalle/Van Buren (Brown, Orange, Purple & Pink Lines)\",\"Ashland (Green & Pink Lines)\",\"Oak Park (Blue Line)\",\"Sox-35th (Red Line)\",\"Randolph/Wabash (Brown, Green, Orange, Pink & Purple Lines)\",\"Damen (Pink Line)\",\"Western (Blue Line - Forest Park Branch)\",\"Cumberland (Blue Line)\",\"79th (Red Line)\",\"Kedzie-Homan (Blue Line)\",\"State/Lake (Brown, Green, Orange, Pink & Purple Lines)\",\"Main (Purple Line)\",\"Central (Green Line)\",\"Ashland/63rd (Green Line)\",\"Indiana (Green Line)\",\"Western (Orange Line)\",\"Division (Blue Line)\",\"Grand (Red Line)\",\"Berwyn (Red Line)\",\"UIC-Halsted (Blue Line)\",\"Southport (Brown Line)\",\"Washington (Blue Line)\",\"Forest Park (Blue Line)\",\"Noyes (Purple Line)\",\"Cicero (Pink Line)\",\"Clinton (Blue Line)\",\"California (Pink Line)\",\"95th/Dan Ryan (Red Line)\",\"Merchandise Mart (Brown & Purple Lines)\",\"Racine (Blue Line)\",\"Cicero (Green Line)\",\"Grand (Blue Line)\",\"Washington (Red Line)\",\"Garfield (Green Line)\",\"Foster (Purple Line)\",\"Diversey (Brown & Purple Lines)\",\"Wilson (Red & Purple Lines)\",\"Irving Park (Blue Line)\",\"Jackson (Red Line)\",\"California (Blue Line)\",\"54th/Cermak (Pink Line)\",\"Damen (Blue Line)\",\"Kostner (Pink Line)\",\"Ridgeland (Green Line)\",\"Clark/Division (Red Line)\",\"Madison/Wabash (Brown, Green, Orange, Pink & Purple Lines)\",\"North/Clybourn (Red Line)\",\"Armitage (Brown & Purple Lines)\",\"Western (Blue Line - O'Hare Branch)\",\"Adams/Wabash (Brown, Green, Orange, Pink & Purple Lines)\",\"Dempster (Purple Line)\",\"Laramie (Green Line)\",\"Chicago (Brown & Purple Lines)\",\"Cottage Grove (Green Line)\",\"Washington/Wells (Brown, Orange, Purple & Pink Lines)\",\"Western (Pink Line)\",\"Harlem (Blue Line - O'Hare Branch)\",\"Granville (Red Line)\",\"Lawrence (Red Line)\",\"Central Park (Pink Line)\",\"Monroe (Blue Line)\",\"Sedgwick (Brown & Purple Lines)\",\"Illinois Medical District (Blue Line)\",\"Rosemont (Blue Line)\",\"18th (Pink Line)\",\"South Boulevard (Purple Line)\",\"Harold Washington Library-State/Van Buren (Brown, Orange, Purple & Pink Lines)\",\"Francisco (Brown Line)\",\"Thorndale (Red Line)\",\"O'Hare (Blue Line)\",\"Howard (Red, Purple & Yellow Lines)\",\"63rd (Red Line)\",\"Pulaski (Blue Line)\",\"Midway (Orange Line)\",\"Halsted (Green Line)\",\"Pulaski (Orange Line)\",\"Cicero (Blue Line)\",\"Harlem (Blue Line - Forest Park Branch)\",\"69th (Red Line)\",\"Cermak-Chinatown (Red Line)\",\"Rockwell (Brown Line)\",\"Logan Square (Blue Line)\",\"Polk (Pink Line)\",\"Kedzie (Pink Line)\",\"Linden (Purple Line)\",\"Ashland (Orange Line)\",\"Kedzie (Green Line)\",\"47th (Green Line)\",\"Monroe (Red Line)\",\"35th-Bronzeville-IIT (Green Line)\",\"Halsted (Orange Line)\",\"King Drive (Green Line)\",\"Kedzie (Orange Line)\",\"Clinton (Green & Pink Lines)\",\"Garfield (Red Line)\",\"Kedzie (Brown Line)\",\"Jarvis (Red Line)\",\"Argyle (Red Line)\",\"Wellington (Brown & Purple Lines)\",\"Fullerton (Red, Brown & Purple Lines)\",\"47th (Red Line)\",\"Addison (Blue Line)\",\"Central (Purple Line)\",\"Austin (Green Line)\",\"43rd (Green Line)\",\"Jefferson Park (Blue Line)\",\"Kimball (Brown Line)\",\"Loyola (Red Line)\",\"Paulina (Brown Line)\",\"Belmont (Red, Brown & Purple Lines)\",\"Montrose (Blue Line)\",\"LaSalle (Blue Line)\",\"Oak Park (Green Line)\",\"California (Green Line)\",\"Bryn Mawr (Red Line)\",\"Roosevelt (Red, Orange & Green Lines)\",\"Chicago (Blue Line)\",\"Addison (Red Line)\",\"87th (Red Line)\",\"Addison (Brown Line)\",\"Chicago (Red Line)\",\"Irving Park (Brown Line)\",\"Western (Brown Line)\",\"Harrison (Red Line)\",\"Montrose (Brown Line)\",\"Morgan (Green & Pink Lines)\",\"Homan (Green Line)\",\"Lake (Red Line)\",\"Conservatory (Green Line)\",\"Oakton-Skokie (Yellow Line)\",\"Cermak-McCormick Place (Green Line)\",\"Washington/Wabash (Brown, Green, Orange, Purple & Pink Lines)\"],null,null,{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]},{\"method\":\"addCircleMarkers\",\"args\":[41.885737,-87.630886,6,null,null,{\"interactive\":true,\"className\":\"\",\"stroke\":true,\"color\":\"green\",\"weight\":5,\"opacity\":0.5,\"fill\":true,\"fillColor\":\"green\",\"fillOpacity\":0.2},null,null,null,null,null,{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]}],\"limits\":{\"lat\":[41.722377,42.073153],\"lng\":[-87.90422307,-87.605857]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n## Your turn: Explore the Data\n\n*Take a look at these data for a few minutes and see if you can find any interesting characteristics in the predictors or the outcome.*  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(rules)\ndata(\"Chicago\")\ndim(Chicago)\n#> [1] 5698   50\nstations\n#>  [1] \"Austin\"           \"Quincy_Wells\"     \"Belmont\"          \"Archer_35th\"     \n#>  [5] \"Oak_Park\"         \"Western\"          \"Clark_Lake\"       \"Clinton\"         \n#>  [9] \"Merchandise_Mart\" \"Irving_Park\"      \"Washington_Wells\" \"Harlem\"          \n#> [13] \"Monroe\"           \"Polk\"             \"Ashland\"          \"Kedzie\"          \n#> [17] \"Addison\"          \"Jefferson_Park\"   \"Montrose\"         \"California\"\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"explore-chicago\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n\n## Splitting with Chicago data ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nLet's put the last two weeks of data into the test set. `initial_time_split()` can be used for this purpose:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(Chicago)\n\nchi_split <- initial_time_split(Chicago, prop = 1 - (14/nrow(Chicago)))\nchi_split\n#> <Training/Testing/Total>\n#> <5684/14/5698>\n\nchi_train <- training(chi_split)\nchi_test  <- testing(chi_split)\n\n## training\nnrow(chi_train)\n#> [1] 5684\n \n## testing\nnrow(chi_test)\n#> [1] 14\n```\n:::\n\n\n\n## Time series resampling \n\nOur Chicago data is over time. Regular cross-validation, which uses random sampling, may not be the best idea. \n\nWe can emulate our training/test split by making similar resamples. \n\n* Fold 1: Take the first X years of data as the analysis set, the next 2 weeks as the assessment set.\n\n* Fold 2: Take the first X years + 2 weeks of data as the analysis set, the next 2 weeks as the assessment set.\n\n* and so on\n\n##  Rolling forecast origin resampling \n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/rolling.svg){fig-align='center' width=70%}\n:::\n:::\n\n\n\n:::notes\nThis image shows overlapping assessment sets. We will use non-overlapping data but it could be done wither way.\n:::\n\n##  Times series resampling  ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"4|\"}\nchi_rs <-\n  chi_train %>%\n  sliding_period(\n    index = \"date\",  \n\n\n\n\n  )\n```\n:::\n\n\n\nUse the `date` column to find the date data. \n\n\n##   Times series resampling  ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"5|\"}\nchi_rs <-\n  chi_train %>%\n  sliding_period(\n    index = \"date\",  \n    period = \"week\",\n\n\n\n  )\n```\n:::\n\n\n\nOur units will be weeks. \n\n\n##   Times series resampling  ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"6|\"}\nchi_rs <-\n  chi_train %>%\n  sliding_period(\n    index = \"date\",  \n    period = \"week\",\n    lookback = 52 * 15  \n    \n    \n  )\n```\n:::\n\n\n\nEvery analysis set has 15 years of data\n\n\n\n##   Times series resampling  ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"7|\"}\nchi_rs <-\n  chi_train %>%\n  sliding_period(\n    index = \"date\",  \n    period = \"week\",\n    lookback = 52 * 15,\n    assess_stop = 2,\n\n  )\n```\n:::\n\n\n\nEvery assessment set has 2 weeks of data\n\n\n##   Times series resampling  ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"8|\"}\nchi_rs <-\n  chi_train %>%\n  sliding_period(\n    index = \"date\",  \n    period = \"week\",\n    lookback = 52 * 15,\n    assess_stop = 2,\n    step = 2 \n  )\n```\n:::\n\n\n\nIncrement by 2 weeks so that there are no overlapping assessment sets. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_rs$splits[[1]] %>% assessment() %>% pluck(\"date\") %>% range()\n#> [1] \"2016-01-07\" \"2016-01-20\"\nchi_rs$splits[[2]] %>% assessment() %>% pluck(\"date\") %>% range()\n#> [1] \"2016-01-21\" \"2016-02-03\"\n```\n:::\n\n\n\n\n## Our resampling object  ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"45%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_rs\n#> # Sliding period resampling \n#> # A tibble: 16 × 2\n#>    splits            id     \n#>    <list>            <chr>  \n#>  1 <split [5463/14]> Slice01\n#>  2 <split [5467/14]> Slice02\n#>  3 <split [5467/14]> Slice03\n#>  4 <split [5467/14]> Slice04\n#>  5 <split [5467/14]> Slice05\n#>  6 <split [5467/14]> Slice06\n#>  7 <split [5467/14]> Slice07\n#>  8 <split [5467/14]> Slice08\n#>  9 <split [5467/14]> Slice09\n#> 10 <split [5467/14]> Slice10\n#> 11 <split [5467/14]> Slice11\n#> 12 <split [5467/14]> Slice12\n#> 13 <split [5467/14]> Slice13\n#> 14 <split [5467/14]> Slice14\n#> 15 <split [5467/14]> Slice15\n#> 16 <split [5467/11]> Slice16\n```\n:::\n\n\n\n:::\n\n::: {.column width=\"5%\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\nWe will fit 16 models on  16 slightly different analysis sets. \n\nEach will produce a separate performance metrics. \n\nWe will average the  16 metrics to get the resampling estimate of that statistic. \n\n:::\n:::\n\n\n## Feature engineering with recipes  ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_rec <- \n  recipe(ridership ~ ., data = chi_train)\n```\n:::\n\n\n\nBased on the formula, the function assigns columns to roles of \"outcome\" or \"predictor\"\n\n## A recipe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(chi_rec)\n#> # A tibble: 50 × 4\n#>    variable         type      role      source  \n#>    <chr>            <list>    <chr>     <chr>   \n#>  1 Austin           <chr [2]> predictor original\n#>  2 Quincy_Wells     <chr [2]> predictor original\n#>  3 Belmont          <chr [2]> predictor original\n#>  4 Archer_35th      <chr [2]> predictor original\n#>  5 Oak_Park         <chr [2]> predictor original\n#>  6 Western          <chr [2]> predictor original\n#>  7 Clark_Lake       <chr [2]> predictor original\n#>  8 Clinton          <chr [2]> predictor original\n#>  9 Merchandise_Mart <chr [2]> predictor original\n#> 10 Irving_Park      <chr [2]> predictor original\n#> # ℹ 40 more rows\n```\n:::\n\n\n\n\n\n## A recipe - work with dates ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"3|\"}\nchi_rec <- \n  recipe(ridership ~ ., data = chi_train) %>% \n  step_date(date, features = c(\"dow\", \"month\", \"year\")) \n```\n:::\n\n\n\nThis creates three new columns in the data based on the date. Note that the day-of-the-week column is a factor.\n\n\n## A recipe - work with dates ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"4|\"}\nchi_rec <- \n  recipe(ridership ~ ., data = chi_train) %>% \n  step_date(date, features = c(\"dow\", \"month\", \"year\")) %>% \n  step_holiday(date) \n```\n:::\n\n\n\nAdd indicators for major holidays. Specific holidays, especially those non-USA, can also be generated. \n\nAt this point, we don't need `date` anymore. Instead of deleting it (there is a step for that) we will change its _role_ to be an identification variable. \n\n:::notes\nWe might want to change the role (instead of removing the column) because it will stay in the data set (even when resampled) and might be useful for diagnosing issues.\n:::\n\n\n## A recipe - work with dates ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"5,6|\"}\nchi_rec <- \n  recipe(ridership ~ ., data = chi_train) %>% \n  step_date(date, features = c(\"dow\", \"month\", \"year\")) %>% \n  step_holiday(date) %>% \n  update_role(date, new_role = \"id\") %>%\n  update_role_requirements(role = \"id\", bake = TRUE)\n```\n:::\n\n\n\n`date` is still in the data set but tidymodels knows not to treat it as an analysis column. \n\n`update_role_requirements()` is needed to make sure that this column is required when making new data points. \n\n## A recipe - remove constant columns ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"7|\"}\nchi_rec <- \n  recipe(ridership ~ ., data = chi_train) %>% \n  step_date(date, features = c(\"dow\", \"month\", \"year\")) %>% \n  step_holiday(date) %>% \n  update_role(date, new_role = \"id\") %>%\n  update_role_requirements(role = \"id\", bake = TRUE) %>% \n  step_zv(all_nominal_predictors()) \n```\n:::\n\n\n\n\n## A recipe - handle correlations ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nThe station columns have a very high degree of correlation. \n\nWe might want to decorrelated them with principle component analysis to help the model fits go more easily. \n\nThe vector `stations` contains all station names and can be used to identify all the relevant columns.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"7|\"}\nchi_pca_rec <- \n  chi_rec %>% \n  step_normalize(all_of(!!stations)) %>% \n  step_pca(all_of(!!stations), num_comp = tune())\n```\n:::\n\n\n\nWe'll tune the number of PCA components for (default) values of one to four.\n\n## Make some models ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/tune.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/rules.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"} ![](hexes/recipes.png){.absolute top=-20 right=192 width=\"64\" height=\"74.24\"} ![](hexes/parsnip.png){.absolute top=-20 right=256 width=\"64\" height=\"74.24\"}\n\nLet's try three models. The first one requires the `rules` package (loaded earlier).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncb_spec <- cubist_rules(committees = 25, neighbors = tune())\nmars_spec <- mars(prod_degree = tune()) %>% set_mode(\"regression\")\nlm_spec <- linear_reg()\n\nchi_set <- \n  workflow_set(\n    list(pca = chi_pca_rec, basic = chi_rec), \n    list(cubist = cb_spec, mars = mars_spec, lm = lm_spec)\n  ) %>% \n  # Evaluate models using mean absolute errors\n  option_add(metrics = metric_set(mae))\n```\n:::\n\n\n\n\n:::notes\nBriefly talk about Cubist being a (sort of) boosted rule-based model and MARS being a nonlinear regression model. Both incorporate feature selection nicely. \n:::\n\n## Process them on the resamples\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up some objects for stacking ensembles (in a few slides)\ngrid_ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)\n\nchi_res <- \n  chi_set %>% \n  workflow_map(\n    resamples = chi_rs,\n    grid = 10,\n    control = grid_ctrl,\n    verbose = TRUE,\n    seed = 12\n  )\n```\n:::\n\n\n\n## How do the results look? \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrank_results(chi_res)\n#> # A tibble: 31 × 9\n#>    wflow_id     .config              .metric  mean std_err     n preprocessor model   rank\n#>    <chr>        <chr>                <chr>   <dbl>   <dbl> <int> <chr>        <chr>  <int>\n#>  1 pca_cubist   Preprocessor1_Model1 mae     0.806   0.104    16 recipe       cubis…     1\n#>  2 pca_cubist   Preprocessor3_Model3 mae     0.990   0.114    16 recipe       cubis…     2\n#>  3 pca_cubist   Preprocessor4_Model2 mae     0.990   0.121    16 recipe       cubis…     3\n#>  4 pca_cubist   Preprocessor4_Model1 mae     1.00    0.127    16 recipe       cubis…     4\n#>  5 pca_cubist   Preprocessor3_Model2 mae     1.00    0.119    16 recipe       cubis…     5\n#>  6 pca_cubist   Preprocessor2_Model2 mae     1.02    0.118    16 recipe       cubis…     6\n#>  7 pca_cubist   Preprocessor1_Model3 mae     1.05    0.131    16 recipe       cubis…     7\n#>  8 basic_cubist Preprocessor1_Model8 mae     1.07    0.115    16 recipe       cubis…     8\n#>  9 basic_cubist Preprocessor1_Model7 mae     1.07    0.112    16 recipe       cubis…     9\n#> 10 basic_cubist Preprocessor1_Model6 mae     1.07    0.114    16 recipe       cubis…    10\n#> # ℹ 21 more rows\n```\n:::\n\n\n\n## Plot the results ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/ggplot2.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(chi_res)\n```\n\n::: {.cell-output-display}\n![](figures/set-results-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Pull out specific results ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/ggplot2.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\nWe can also pull out the specific tuning results and look at them: \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchi_res %>% \n  extract_workflow_set_result(\"pca_cubist\") %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](figures/cubist-autoplot-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Why choose just one `final_fit`? ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n_Model stacks_ generate predictions that are informed by several models.\n\n## Why choose just one `final_fit`? ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n![](images/stack_01.png)\n\n## Why choose just one `final_fit`? ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n![](images/stack_02.png)\n\n## Why choose just one `final_fit`? ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n![](images/stack_03.png)\n\n## Why choose just one `final_fit`? ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n![](images/stack_04.png)\n\n## Why choose just one `final_fit`? ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n![](images/stack_05.png)\n\n## Building a model stack ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stacks)\n```\n:::\n\n\n\n1) Define candidate members\n2) Initialize a data stack object\n3) Add candidate ensemble members to the data stack\n4) Evaluate how to combine their predictions\n5) Fit candidate ensemble members with non-zero stacking coefficients\n6) Predict on new data!\n\n\n## Start the stack and add members ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nCollect all of the resampling results for all model configurations. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_stack <- \n  stacks() %>% \n  add_candidates(chi_res)\n```\n:::\n\n\n\n\n## Estimate weights for each candidate ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWhich configurations should be retained? Uses a penalized linear model: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(122)\nchi_stack_res <- blend_predictions(chi_stack)\n\nchi_stack_res\n#> # A tibble: 4 × 3\n#>   member           type         weight\n#>   <chr>            <chr>         <dbl>\n#> 1 pca_cubist_1_1   cubist_rules  0.410\n#> 2 basic_cubist_1_4 cubist_rules  0.266\n#> 3 pca_cubist_3_2   cubist_rules  0.193\n#> 4 pca_lm_4_1       linear_reg    0.171\n```\n:::\n\n\n\n## How did it do? ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/ggplot2.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\nThe overall results of the penalized model: \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(chi_stack_res)\n```\n\n::: {.cell-output-display}\n![](figures/stack-autoplot-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n\n## What does it use?  ![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/ggplot2.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(chi_stack_res, type = \"weights\")\n```\n\n::: {.cell-output-display}\n![](figures/stack-members-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Fit the required candidate models![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nFor each model we retain in the stack, we need their model fit on the entire training set. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_stack_res <- fit_members(chi_stack_res)\n```\n:::\n\n\n\n\n## The test set: best Cubist model ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/tune.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\nWe can pull out the results and the workflow to fit the single best cubist model. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_cubist <- \n  chi_res %>% \n  extract_workflow_set_result(\"pca_cubist\") %>% \n  select_best()\n\ncubist_res <- \n  chi_res %>% \n  extract_workflow(\"pca_cubist\") %>% \n  finalize_workflow(best_cubist) %>% \n  last_fit(split = chi_split, metrics = metric_set(mae))\n```\n:::\n\n\n\n## The test set: stack ensemble![](hexes/stacks.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWe don't have `last_fit()` for stacks (yet) so we manually make predictions. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstack_pred <- \n  predict(chi_stack_res, chi_test) %>% \n  bind_cols(chi_test)\n```\n:::\n\n\n\n## Compare the results ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/stacks.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\nSingle best versus the stack:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(cubist_res)\n#> # A tibble: 1 × 4\n#>   .metric .estimator .estimate .config             \n#>   <chr>   <chr>          <dbl> <chr>               \n#> 1 mae     standard       0.670 Preprocessor1_Model1\n\nstack_pred %>% mae(ridership, .pred)\n#> # A tibble: 1 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 mae     standard       0.687\n```\n:::\n\n\n\n\n## Plot the test set ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/ggplot2.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell layout-align=\"center\" output-location='column-fragment'}\n\n```{.r .cell-code}\nlibrary(probably)\ncubist_res %>% \n  collect_predictions() %>% \n  ggplot(aes(ridership, .pred)) + \n  geom_point(alpha = 1 / 2) + \n  geom_abline(lty = 2, col = \"green\") + \n  coord_obs_pred()\n```\n\n::: {.cell-output-display}\n![](figures/obs-pred-1.svg){fig-align='center'}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/htmlwidgets-1.6.2/htmlwidgets.js\"></script>\n<script src=\"../../../site_libs/jquery-1.12.4/jquery.min.js\"></script>\n<link href=\"../../../site_libs/leaflet-1.3.1/leaflet.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/leaflet-1.3.1/leaflet.js\"></script>\n<link href=\"../../../site_libs/leafletfix-1.0.0/leafletfix.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/proj4-2.6.2/proj4.min.js\"></script>\n<script src=\"../../../site_libs/Proj4Leaflet-1.0.1/proj4leaflet.js\"></script>\n<link href=\"../../../site_libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/leaflet-binding-2.1.2/leaflet.js\"></script>\n<script src=\"../../../site_libs/leaflet-providers-1.9.0/leaflet-providers_1.9.0.js\"></script>\n<script src=\"../../../site_libs/leaflet-providers-plugin-2.1.2/leaflet-providers-plugin.js\"></script>\n<link href=\"../../../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}