{
  "hash": "bd852d4b68b80ce2af5b3101373e384c",
  "result": {
    "markdown": "---\ntitle: \"4 - Evaluating models\"\nsubtitle: \"Machine learning with tidymodels\"\nformat:\n  revealjs: \n    slide-number: true\n    footer: <https://workshops.tidymodels.org>\n    include-before-body: header.html\n    include-after-body: footer-annotations.html\n    theme: [default, tidymodels.scss]\n    width: 1280\n    height: 720\nknitr:\n  opts_chunk: \n    echo: true\n    collapse: true\n    comment: \"#>\"\n---\n\n\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(tree_fit, new_data = frog_test) %>%\n  metrics(latency, .pred)\n#> # A tibble: 3 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard      59.2  \n#> 2 rsq     standard       0.380\n#> 3 mae     standard      40.2\n```\n:::\n\n\n. . .\n\n-   RMSE: difference between the predicted and observed values â¬‡ï¸\n-   $R^2$: squared correlation between the predicted and observed values â¬†ï¸\n-   MAE: similar to RMSE, but mean absolute error â¬‡ï¸\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(tree_fit, new_data = frog_test) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        59.2\n```\n:::\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(tree_fit, new_data = frog_test) %>%\n  group_by(reflex) %>%\n  rmse(latency, .pred)\n#> # A tibble: 3 Ã— 4\n#>   reflex .metric .estimator .estimate\n#>   <fct>  <chr>   <chr>          <dbl>\n#> 1 low    rmse    standard        94.3\n#> 2 mid    rmse    standard       101. \n#> 3 full   rmse    standard        51.2\n```\n:::\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrog_metrics <- metric_set(rmse, msd)\naugment(tree_fit, new_data = frog_test) %>%\n  frog_metrics(latency, .pred)\n#> # A tibble: 2 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard      59.2  \n#> 2 msd     standard      -0.908\n```\n:::\n\n\n##  {background-iframe=\"https://yardstick.tidymodels.org/reference/index.html\"}\n\n::: footer\n:::\n\n# We'll talk about classification metrics tomorrow!\n\n# âš ï¸ DANGERS OF OVERFITTING âš ï¸\n\n## Dangers of overfitting âš ï¸\n\n![](https://raw.githubusercontent.com/topepo/2022-nyr-workshop/main/images/tuning-overfitting-train-1.svg)\n\n## Dangers of overfitting âš ï¸\n\n![](https://raw.githubusercontent.com/topepo/2022-nyr-workshop/main/images/tuning-overfitting-test-1.svg)\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit %>%\n  augment(frog_train)\n#> # A tibble: 456 Ã— 6\n#>    treatment  reflex   age t_o_d     latency .pred\n#>    <fct>      <fct>  <dbl> <fct>       <dbl> <dbl>\n#>  1 control    full    5.42 morning        33  39.8\n#>  2 control    full    5.38 morning        19  66.7\n#>  3 control    full    5.38 morning         2  66.7\n#>  4 control    full    5.44 morning        39  39.8\n#>  5 control    full    5.41 morning        42  39.8\n#>  6 control    full    4.75 afternoon      20  59.8\n#>  7 control    full    4.95 night          31  83.1\n#>  8 control    full    5.42 morning        21  39.8\n#>  9 gentamicin full    5.39 morning        30  64.6\n#> 10 control    full    4.55 afternoon      43 174. \n#> # â„¹ 446 more rows\n```\n:::\n\n\nWe call this \"resubstitution\" or \"repredicting the training set\"\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit %>%\n  augment(frog_train) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        49.4\n```\n:::\n\n\nWe call this a \"resubstitution estimate\"\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit %>%\n  augment(frog_train) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        49.4\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n:::\n:::\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit %>%\n  augment(frog_train) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        49.4\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit %>%\n  augment(frog_test) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        59.2\n```\n:::\n\n:::\n:::\n\n. . .\n\nâš ï¸ Remember that we're demonstrating overfitting \n\n. . .\n\nâš ï¸ Don't use the test set until the *end* of your modeling analysis\n\n\n##  {background-image=\"https://media.giphy.com/media/55itGuoAJiZEEen9gg/giphy.gif\" background-size=\"70%\"}\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Use `augment()` and `metrics()` to compute a regression metric like `mae()`.*\n\n*Compute the metrics for both training and testing data.*\n\n*Notice the evidence of overfitting!* âš ï¸\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"augment-metrics\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit %>%\n  augment(frog_train) %>%\n  metrics(latency, .pred)\n#> # A tibble: 3 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard      49.4  \n#> 2 rsq     standard       0.494\n#> 3 mae     standard      33.4\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit %>%\n  augment(frog_test) %>%\n  metrics(latency, .pred)\n#> # A tibble: 3 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard      59.2  \n#> 2 rsq     standard       0.380\n#> 3 mae     standard      40.2\n```\n:::\n\n:::\n:::\n\n. . .\n\nWhat if we want to compare more models?\n\n. . .\n\nAnd/or more model configurations?\n\n. . .\n\nAnd we want to understand if these are important differences?\n\n# The testing data are precious ğŸ’\n\n# How can we use the *training* data to compare and evaluate different models? ğŸ¤”\n\n##  {background-color=\"white\" background-image=\"https://www.tmwr.org/premade/resampling.svg\" background-size=\"80%\"}\n\n## Cross-validation\n\n![](https://www.tmwr.org/premade/three-CV.svg)\n\n## Cross-validation\n\n![](https://www.tmwr.org/premade/three-CV-iter.svg)\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*If we use 10 folds, what percent of the training data*\n\n-   *ends up in analysis*\n-   *ends up in assessment*\n\n*for* **each** *fold?*\n\n![](images/snake.png){width=\"300\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"percent-in-folds\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvfold_cv(frog_train) # v = 10 is default\n#> #  10-fold cross-validation \n#> # A tibble: 10 Ã— 2\n#>    splits           id    \n#>    <list>           <chr> \n#>  1 <split [410/46]> Fold01\n#>  2 <split [410/46]> Fold02\n#>  3 <split [410/46]> Fold03\n#>  4 <split [410/46]> Fold04\n#>  5 <split [410/46]> Fold05\n#>  6 <split [410/46]> Fold06\n#>  7 <split [411/45]> Fold07\n#>  8 <split [411/45]> Fold08\n#>  9 <split [411/45]> Fold09\n#> 10 <split [411/45]> Fold10\n```\n:::\n\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWhat is in this?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrog_folds <- vfold_cv(frog_train)\nfrog_folds$splits[1:3]\n#> [[1]]\n#> <Analysis/Assess/Total>\n#> <410/46/456>\n#> \n#> [[2]]\n#> <Analysis/Assess/Total>\n#> <410/46/456>\n#> \n#> [[3]]\n#> <Analysis/Assess/Total>\n#> <410/46/456>\n```\n:::\n\n\n::: notes\nTalk about a list column, storing non-atomic types in dataframe\n:::\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvfold_cv(frog_train, v = 5)\n#> #  5-fold cross-validation \n#> # A tibble: 5 Ã— 2\n#>   splits           id   \n#>   <list>           <chr>\n#> 1 <split [364/92]> Fold1\n#> 2 <split [365/91]> Fold2\n#> 3 <split [365/91]> Fold3\n#> 4 <split [365/91]> Fold4\n#> 5 <split [365/91]> Fold5\n```\n:::\n\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvfold_cv(frog_train, strata = latency)\n#> #  10-fold cross-validation using stratification \n#> # A tibble: 10 Ã— 2\n#>    splits           id    \n#>    <list>           <chr> \n#>  1 <split [408/48]> Fold01\n#>  2 <split [408/48]> Fold02\n#>  3 <split [408/48]> Fold03\n#>  4 <split [409/47]> Fold04\n#>  5 <split [411/45]> Fold05\n#>  6 <split [412/44]> Fold06\n#>  7 <split [412/44]> Fold07\n#>  8 <split [412/44]> Fold08\n#>  9 <split [412/44]> Fold09\n#> 10 <split [412/44]> Fold10\n```\n:::\n\n\n. . .\n\nStratification often helps, with very little downside\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWe'll use this setup:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nfrog_folds <- vfold_cv(frog_train, v = 10, strata = latency)\nfrog_folds\n#> #  10-fold cross-validation using stratification \n#> # A tibble: 10 Ã— 2\n#>    splits           id    \n#>    <list>           <chr> \n#>  1 <split [408/48]> Fold01\n#>  2 <split [408/48]> Fold02\n#>  3 <split [408/48]> Fold03\n#>  4 <split [409/47]> Fold04\n#>  5 <split [411/45]> Fold05\n#>  6 <split [412/44]> Fold06\n#>  7 <split [412/44]> Fold07\n#>  8 <split [412/44]> Fold08\n#>  9 <split [412/44]> Fold09\n#> 10 <split [412/44]> Fold10\n```\n:::\n\n\n. . .\n\nSet the seed when creating resamples\n\n# We are equipped with metrics and resamples!\n\n## Fit our model to the resamples\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res <- fit_resamples(tree_wflow, frog_folds)\ntree_res\n#> # Resampling results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 Ã— 4\n#>    splits           id     .metrics         .notes          \n#>    <list>           <chr>  <list>           <list>          \n#>  1 <split [408/48]> Fold01 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  2 <split [408/48]> Fold02 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  3 <split [408/48]> Fold03 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  4 <split [409/47]> Fold04 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  5 <split [411/45]> Fold05 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  6 <split [412/44]> Fold06 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  7 <split [412/44]> Fold07 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  8 <split [412/44]> Fold08 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  9 <split [412/44]> Fold09 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#> 10 <split [412/44]> Fold10 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n```\n:::\n\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  collect_metrics()\n#> # A tibble: 2 Ã— 6\n#>   .metric .estimator   mean     n std_err .config             \n#>   <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 rmse    standard   59.6      10  2.31   Preprocessor1_Model1\n#> 2 rsq     standard    0.305    10  0.0342 Preprocessor1_Model1\n```\n:::\n\n\n. . .\n\nWe can reliably measure performance using only the **training** data ğŸ‰\n\n## Comparing metrics ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nHow do the metrics from resampling compare to the metrics from training and testing?\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  collect_metrics() %>% \n  select(.metric, mean, n)\n#> # A tibble: 2 Ã— 3\n#>   .metric   mean     n\n#>   <chr>    <dbl> <int>\n#> 1 rmse    59.6      10\n#> 2 rsq      0.305    10\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nThe RMSE previously was\n\n- 49.36 for the training set\n- 59.16 for test set\n:::\n:::\n\n. . .\n\nRemember that:\n\nâš ï¸ the training set gives you overly optimistic metrics\n\nâš ï¸ the test set is precious\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the assessment set results\nctrl_frog <- control_resamples(save_pred = TRUE)\ntree_res <- fit_resamples(tree_wflow, frog_folds, control = ctrl_frog)\n\ntree_preds <- collect_predictions(tree_res)\ntree_preds\n#> # A tibble: 456 Ã— 5\n#>    id     .pred  .row latency .config             \n#>    <chr>  <dbl> <int>   <dbl> <chr>               \n#>  1 Fold01  39.6     1      33 Preprocessor1_Model1\n#>  2 Fold01  72.1     3       2 Preprocessor1_Model1\n#>  3 Fold01  63.8     9      30 Preprocessor1_Model1\n#>  4 Fold01  72.1    13      46 Preprocessor1_Model1\n#>  5 Fold01  43.3    28      11 Preprocessor1_Model1\n#>  6 Fold01  61.7    35      41 Preprocessor1_Model1\n#>  7 Fold01  39.6    51      43 Preprocessor1_Model1\n#>  8 Fold01 134.     70      20 Preprocessor1_Model1\n#>  9 Fold01  70.6    74      21 Preprocessor1_Model1\n#> 10 Fold01  39.6   106      14 Preprocessor1_Model1\n#> # â„¹ 446 more rows\n```\n:::\n\n\n## \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_preds %>% \n  ggplot(aes(latency, .pred, color = id)) + \n  geom_abline(lty = 2, col = \"gray\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  coord_obs_pred()\n```\n\n::: {.cell-output-display}\n![](04-evaluating-models_files/figure-revealjs/unnamed-chunk-26-1.svg)\n:::\n:::\n\n\n## Where are the fitted models? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}  {.annotation}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res\n#> # Resampling results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 Ã— 5\n#>    splits           id     .metrics         .notes           .predictions     \n#>    <list>           <chr>  <list>           <list>           <list>           \n#>  1 <split [408/48]> Fold01 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [48 Ã— 4]>\n#>  2 <split [408/48]> Fold02 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [48 Ã— 4]>\n#>  3 <split [408/48]> Fold03 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [48 Ã— 4]>\n#>  4 <split [409/47]> Fold04 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [47 Ã— 4]>\n#>  5 <split [411/45]> Fold05 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [45 Ã— 4]>\n#>  6 <split [412/44]> Fold06 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [44 Ã— 4]>\n#>  7 <split [412/44]> Fold07 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [44 Ã— 4]>\n#>  8 <split [412/44]> Fold08 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [44 Ã— 4]>\n#>  9 <split [412/44]> Fold09 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [44 Ã— 4]>\n#> 10 <split [412/44]> Fold10 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [44 Ã— 4]>\n```\n:::\n\n\n. . .\n\nğŸ—‘ï¸\n\n# Alternate resampling schemes\n\n## Bootstrapping\n\n![](https://www.tmwr.org/premade/bootstraps.svg)\n\n## Bootstrapping ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3214)\nbootstraps(frog_train)\n#> # Bootstrap sampling \n#> # A tibble: 25 Ã— 2\n#>    splits            id         \n#>    <list>            <chr>      \n#>  1 <split [456/163]> Bootstrap01\n#>  2 <split [456/166]> Bootstrap02\n#>  3 <split [456/173]> Bootstrap03\n#>  4 <split [456/177]> Bootstrap04\n#>  5 <split [456/166]> Bootstrap05\n#>  6 <split [456/163]> Bootstrap06\n#>  7 <split [456/164]> Bootstrap07\n#>  8 <split [456/165]> Bootstrap08\n#>  9 <split [456/170]> Bootstrap09\n#> 10 <split [456/177]> Bootstrap10\n#> # â„¹ 15 more rows\n```\n:::\n\n\n##  {background-iframe=\"https://rsample.tidymodels.org/reference/index.html\"}\n\n::: footer\n:::\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Create:*\n\n-   *bootstrap folds (change `times` from the default)*\n-   *validation set (use the reference guide to find the function)*\n\n*Don't forget to set a seed when you resample!*\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"try-rsample\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Bootstrapping ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(322)\nbootstraps(frog_train, times = 10)\n#> # Bootstrap sampling \n#> # A tibble: 10 Ã— 2\n#>    splits            id         \n#>    <list>            <chr>      \n#>  1 <split [456/173]> Bootstrap01\n#>  2 <split [456/168]> Bootstrap02\n#>  3 <split [456/170]> Bootstrap03\n#>  4 <split [456/164]> Bootstrap04\n#>  5 <split [456/176]> Bootstrap05\n#>  6 <split [456/156]> Bootstrap06\n#>  7 <split [456/166]> Bootstrap07\n#>  8 <split [456/168]> Bootstrap08\n#>  9 <split [456/167]> Bootstrap09\n#> 10 <split [456/170]> Bootstrap10\n```\n:::\n\n\n## Validation set ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(853)\nvalidation_split(frog_train, strata = latency)\n#> # Validation Set Split (0.75/0.25)  using stratification \n#> # A tibble: 1 Ã— 2\n#>   splits            id        \n#>   <list>            <chr>     \n#> 1 <split [340/116]> validation\n```\n:::\n\n\n. . .\n\nA validation set is just another type of resample\n\n# Decision tree ğŸŒ³\n\n# Random forest ğŸŒ³ğŸŒ²ğŸŒ´ğŸŒµğŸŒ´ğŸŒ³ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒµğŸŒ´ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒ³ğŸŒµğŸŒµğŸŒ´ğŸŒ²ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒ´ğŸŒµğŸŒ´ğŸŒ²ğŸŒ´ğŸŒµğŸŒ²ğŸŒµğŸŒ´ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒµğŸŒ³ğŸŒ´ğŸŒ³\n\n## Random forest ğŸŒ³ğŸŒ²ğŸŒ´ğŸŒµğŸŒ³ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒµğŸŒ´ğŸŒ³ğŸŒµ\n\n- Ensemble many decision tree models\n\n- All the trees vote! ğŸ—³ï¸\n\n- Bootstrap aggregating + random predictor sampling\n\n. . .\n\n- Often works well without tuning hyperparameters (more on this tomorrow!), as long as there are enough trees\n\n## Create a random forest model ![](hexes/parsnip.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_spec <- rand_forest(trees = 1000, mode = \"regression\")\nrf_spec\n#> Random Forest Model Specification (regression)\n#> \n#> Main Arguments:\n#>   trees = 1000\n#> \n#> Computational engine: ranger\n```\n:::\n\n\n## Create a random forest model ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_wflow <- workflow(latency ~ ., rf_spec)\nrf_wflow\n#> â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#> Preprocessor: Formula\n#> Model: rand_forest()\n#> \n#> â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> latency ~ .\n#> \n#> â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> Random Forest Model Specification (regression)\n#> \n#> Main Arguments:\n#>   trees = 1000\n#> \n#> Computational engine: ranger\n```\n:::\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Use `fit_resamples()` and `rf_wflow` to:*\n\n-   *keep predictions*\n-   *compute metrics*\n-   *plot true vs. predicted values*\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"try-fit-resamples\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">08</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nctrl_frog <- control_resamples(save_pred = TRUE)\n\n# Random forest uses random numbers so set the seed first\n\nset.seed(2)\nrf_res <- fit_resamples(rf_wflow, frog_folds, control = ctrl_frog)\ncollect_metrics(rf_res)\n#> # A tibble: 2 Ã— 6\n#>   .metric .estimator   mean     n std_err .config             \n#>   <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 rmse    standard   55.9      10  1.76   Preprocessor1_Model1\n#> 2 rsq     standard    0.372    10  0.0312 Preprocessor1_Model1\n```\n:::\n\n\n## \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_predictions(rf_res) %>% \n  ggplot(aes(latency, .pred, color = id)) + \n  geom_abline(lty = 2, col = \"gray\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  coord_obs_pred()\n```\n\n::: {.cell-output-display}\n![](04-evaluating-models_files/figure-revealjs/unnamed-chunk-36-1.svg)\n:::\n:::\n\n\n## How can we compare multiple model workflows at once? {background-image=\"images/Hatching-process.jpg\"}\n\n\n## Evaluate a workflow set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkflow_set(list(latency ~ .), list(tree_spec, rf_spec))\n#> # A workflow set/tibble: 2 Ã— 4\n#>   wflow_id              info             option    result    \n#>   <chr>                 <list>           <list>    <list>    \n#> 1 formula_decision_tree <tibble [1 Ã— 4]> <opts[0]> <list [0]>\n#> 2 formula_rand_forest   <tibble [1 Ã— 4]> <opts[0]> <list [0]>\n```\n:::\n\n\n## Evaluate a workflow set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkflow_set(list(latency ~ .), list(tree_spec, rf_spec)) %>%\n  workflow_map(\"fit_resamples\", resamples = frog_folds)\n#> # A workflow set/tibble: 2 Ã— 4\n#>   wflow_id              info             option    result   \n#>   <chr>                 <list>           <list>    <list>   \n#> 1 formula_decision_tree <tibble [1 Ã— 4]> <opts[1]> <rsmp[+]>\n#> 2 formula_rand_forest   <tibble [1 Ã— 4]> <opts[1]> <rsmp[+]>\n```\n:::\n\n\n## Evaluate a workflow set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkflow_set(list(latency ~ .), list(tree_spec, rf_spec)) %>%\n  workflow_map(\"fit_resamples\", resamples = frog_folds) %>%\n  rank_results()\n#> # A tibble: 4 Ã— 9\n#>   wflow_id         .config .metric   mean std_err     n preprocessor model  rank\n#>   <chr>            <chr>   <chr>    <dbl>   <dbl> <int> <chr>        <chr> <int>\n#> 1 formula_rand_foâ€¦ Preproâ€¦ rmse    55.7    1.81      10 formula      randâ€¦     1\n#> 2 formula_rand_foâ€¦ Preproâ€¦ rsq      0.375  0.0309    10 formula      randâ€¦     1\n#> 3 formula_decisioâ€¦ Preproâ€¦ rmse    59.6    2.31      10 formula      deciâ€¦     2\n#> 4 formula_decisioâ€¦ Preproâ€¦ rsq      0.305  0.0342    10 formula      deciâ€¦     2\n```\n:::\n\n\nThe first metric of the metric set is used for ranking. Use `rank_metric` to change that.\n\n. . .\n\nLots more available with workflow sets, like `collect_metrics()`, `autoplot()` methods, and more!\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*When do you think a workflow set would be useful?*\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"discuss-workflow-sets\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## The final fit ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}  {.annotation}\n\nSuppose that we are happy with our random forest model.\n\nLet's fit the model on the training set and verify our performance using the test set.\n\n. . .\n\nWe've shown you `fit()` and `predict()` (+ `augment()`) but there is a shortcut:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# frog_split has train + test info\nfinal_fit <- last_fit(rf_wflow, frog_split) \n\nfinal_fit\n#> # Resampling results\n#> # Manual resampling \n#> # A tibble: 1 Ã— 6\n#>   splits            id               .metrics .notes   .predictions .workflow \n#>   <list>            <chr>            <list>   <list>   <list>       <list>    \n#> 1 <split [456/116]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n\n\n## What is in `final_fit`? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(final_fit)\n#> # A tibble: 2 Ã— 4\n#>   .metric .estimator .estimate .config             \n#>   <chr>   <chr>          <dbl> <chr>               \n#> 1 rmse    standard      57.3   Preprocessor1_Model1\n#> 2 rsq     standard       0.415 Preprocessor1_Model1\n```\n:::\n\n\n. . .\n\nThese are metrics computed with the **test** set\n\n## What is in `final_fit`? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_predictions(final_fit)\n#> # A tibble: 116 Ã— 5\n#>    id               .pred  .row latency .config             \n#>    <chr>            <dbl> <int>   <dbl> <chr>               \n#>  1 train/test split  44.1     1      22 Preprocessor1_Model1\n#>  2 train/test split 101.      3     106 Preprocessor1_Model1\n#>  3 train/test split  75.7     6      39 Preprocessor1_Model1\n#>  4 train/test split  43.1     8      50 Preprocessor1_Model1\n#>  5 train/test split  43.5    10      63 Preprocessor1_Model1\n#>  6 train/test split  43.8    14      25 Preprocessor1_Model1\n#>  7 train/test split  51.2    16      48 Preprocessor1_Model1\n#>  8 train/test split 161.     17      91 Preprocessor1_Model1\n#>  9 train/test split  50.9    32      11 Preprocessor1_Model1\n#> 10 train/test split 177.     33     109 Preprocessor1_Model1\n#> # â„¹ 106 more rows\n```\n:::\n\n\n. . .\n\nThese are predictions for the **test** set\n\n## \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_predictions(final_fit) %>%\n  ggplot(aes(latency, .pred)) + \n  geom_abline(lty = 2, col = \"deeppink4\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  coord_obs_pred()\n```\n\n::: {.cell-output-display}\n![](04-evaluating-models_files/figure-revealjs/unnamed-chunk-44-1.svg)\n:::\n:::\n\n\n## What is in `final_fit`? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_workflow(final_fit)\n#> â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#> Preprocessor: Formula\n#> Model: rand_forest()\n#> \n#> â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> latency ~ .\n#> \n#> â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> Ranger result\n#> \n#> Call:\n#>  ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) \n#> \n#> Type:                             Regression \n#> Number of trees:                  1000 \n#> Sample size:                      456 \n#> Number of independent variables:  4 \n#> Mtry:                             2 \n#> Target node size:                 5 \n#> Variable importance mode:         none \n#> Splitrule:                        variance \n#> OOB prediction error (MSE):       3113.532 \n#> R squared (OOB):                  0.355469\n```\n:::\n\n\n. . .\n\nUse this for **prediction** on new data, like for deploying\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*End of the day discussion!*\n\n*Which model do you think you would decide to use?*\n\n*What surprised you the most?*\n\n*What is one thing you are looking forward to for tomorrow?*\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"discuss-which-model\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n",
    "supporting": [
      "04-evaluating-models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/countdown-0.3.5/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/countdown-0.3.5/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}