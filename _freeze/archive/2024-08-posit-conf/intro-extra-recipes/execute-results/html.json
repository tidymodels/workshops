{
  "hash": "2cb3bf66508e854dd800fe01c5820fed",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Extras - Recipes\"\nsubtitle: \"Introduction to tidymodels\"\nformat:\n  revealjs: \n    slide-number: true\n    footer: <https://workshops.tidymodels.org>\n    include-before-body: header.html\n    include-after-body: footer-annotations.html\n    theme: [default, tidymodels.scss]\n    width: 1280\n    height: 720\nknitr:\n  opts_chunk: \n    echo: true\n    collapse: true\n    comment: \"#>\"\n    fig.path: \"figures/\"\n---\n\n\n\n\n\n## Looking at the predictors\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_train\n#> # A tibble: 5,685 × 19\n#>    forested  year elevation eastness northness roughness tree_no_tree dew_temp precip_annual temp_annual_mean temp_annual_min temp_annual_max temp_january_min vapor_min vapor_max canopy_cover   lon\n#>    <fct>    <dbl>     <dbl>    <dbl>     <dbl>     <dbl> <fct>           <dbl>         <dbl>            <dbl>           <dbl>           <dbl>            <dbl>     <dbl>     <dbl>        <dbl> <dbl>\n#>  1 No        2016       464       -5       -99         7 No tree          1.71           282             9.76           -4.44           16.6              2.96       191      1534            4 -121.\n#>  2 Yes       2016       166       92        37         7 Tree             6             1298            10.2             0.72           14.3              6.12        60       747           33 -122.\n#>  3 No        2016       644      -85       -52        24 No tree          0.67           288             8.77           -6.32           14.6              2.98       219      1396            0 -120.\n#>  4 Yes       2014      1285        4        99        79 Tree             1.91          1621             5.61           -2.48            9.48             1.73        88       545           74 -123.\n#>  5 Yes       2013       822       87        48        68 Tree             1.95          2200             8.62           -0.68           12.9              4.35       147       861           48 -121.\n#>  6 Yes       2017         3        6       -99         5 Tree             7.93          2211            10.6             3.77           14.2              7.02        34       578           79 -124.\n#>  7 Yes       2014      2041      -95        28        49 Tree            -4.22          1551             0.75           -9.47            5.17            -3.66        73       481           48 -120.\n#>  8 Yes       2015      1009       -8        99        72 Tree             1.72          2396             6.59           -2.98           11.3              1.88        92       781           76 -122.\n#>  9 No        2017       436      -98        19        10 No tree          1.8            234             9.8            -4.23           16.3              3.32       178      1527            0 -119.\n#> 10 No        2018       775       63        76       103 No tree          0.62           432             8.51           -5.5            13.7              3.32       241      1237            7 -120.\n#> # ℹ 5,675 more rows\n#> # ℹ 2 more variables: lat <dbl>, land_type <fct>\n```\n:::\n\n\n\n## Working with other models\n\nSome models can't handle non-numeric data\n\n-   Linear Regression\n-   K Nearest Neighbors\n\n<br>\n\n::: fragment\nSome models struggle if numeric predictors aren't scaled\n\n-   K Nearest Neighbors\n-   Anything using gradient descent\n:::\n\n## Types of needed preprocessing\n\n-   Do qualitative predictors require a numeric encoding?\n\n-   Should columns with a single unique value be removed?\n\n-   Does the model struggle with missing data?\n\n-   Does the model struggle with correlated predictors?\n\n-   Should predictors be centered and scaled?\n\n-   Is it helpful to transform predictors to be more symmetric?\n\n::: footer\n<https://www.tmwr.org/pre-proc-table.html>\n:::\n\n## Two types of preprocessing\n\n![](images/fe_venn.svg){fig-align=\"center\"}\n\n## Two types of preprocessing\n\n![](images/fe_venn_info.svg){fig-align=\"center\"}\n\n## General definitions\n\n* _Data preprocessing_ is what you do to make your model **successful**.\n* _Feature engineering_ is what you do to the original predictors to make the model do the **least work** to perform great.\n\n## Working with dates\n\nDatetime variables are automatically converted to an integer if given as a raw predictor. To avoid this, it can be re-encoded as:\n\n* Days since a reference date\n* Day of the week\n* Month\n* Year\n* Leap year\n* Indicators for holidays\n\n## Two types of transformations\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\n### Static\n\n- Square root, log, inverse\n- Dummies for known levels\n- Date time extractions\n\n:::\n\n::: {.column width=\"50%\"}\n\n### Trained\n\n- Centering & scaling\n- Imputation\n- PCA\n- Anything for unknown factor levels\n\n:::\n\n:::\n\n::: fragment\nTrained methods need to calculate **sufficient information** to be applied again.\n:::\n\n## The recipes package\n\n::: {.incremental .highlight-last}\n- Modular + extensible\n- Works well with pipes ,`|>` and `%>%`\n- Deferred evaluation\n- Isolates test data from training data\n- Can do things formulas can't\n:::\n\n\n## How to write a recipe\n\n:::{style=\"font-family: 'Source Code Pro', monospace; font-size: 0.8em;\"}\nforested_rec <- recipe(forested ~ ., data = forested_train) %>%  \n\\ \\ step_dummy(all_nominal_predictors()) %>%  \n\\ \\ step_zv(all_predictors()) %>%  \n\\ \\ step_log(canopy_cover, offset = 0.5) %>%  \n\\ \\ step_normalize(all_numeric_predictors())\n:::\n\n## How to write a recipe\n\n:::{style=\"font-family: 'Source Code Pro', monospace; font-size: 0.8em;\"}\nforested_rec <- [recipe(forested ~ ., data = forested_train)]{style=\"color: #CA225E;\"} %>%  \n\\ \\ step_dummy(all_nominal_predictors()) %>%  \n\\ \\ step_zv(all_predictors()) %>%  \n\\ \\ step_log(canopy_cover, offset = 0.5) %>%  \n\\ \\ step_normalize(all_numeric_predictors())\n:::\n\n<br>\n\nStart by calling `recipe()` to denote the data source and variables used.\n\n## How to write a recipe\n\n:::{style=\"font-family: 'Source Code Pro', monospace; font-size: 0.8em;\"}\nforested_rec <- recipe(forested ~ ., data = forested_train) %>%  \n\\ \\ [step_dummy]{style=\"color: #CA225E;\"}(all_nominal_predictors()) %>%  \n\\ \\ [step_zv]{style=\"color: #CA225E;\"}(all_predictors()) %>%  \n\\ \\ [step_log]{style=\"color: #CA225E;\"}(canopy_cover, offset = 0.5) %>%  \n\\ \\ [step_normalize]{style=\"color: #CA225E;\"}(all_numeric_predictors())\n:::\n\n<br>\n\nSpecify what actions to take by adding `step_*()`s.\n\n## How to write a recipe\n\n:::{style=\"font-family: 'Source Code Pro', monospace; font-size: 0.8em;\"}\nforested_rec <- recipe(forested ~ ., data = forested_train) %>%  \n\\ \\ step_dummy([all_nominal_predictors()]{style=\"color: #CA225E;\"}) %>%  \n\\ \\ step_zv([all_predictors()]{style=\"color: #CA225E;\"}) %>%  \n\\ \\ step_log([canopy_cover]{style=\"color: #CA225E;\"}, offset = 0.5) %>% \n\\ \\ step_normalize([all_numeric_predictors()]{style=\"color: #CA225E;\"})\n:::\n<br>\n\nUse {tidyselect} and recipes-specific selectors to denote affected variables.\n\n## Using a recipe\n\n:::{style=\"font-family: 'Source Code Pro', monospace; font-size: 0.8em;\"}\nforested_rec <- recipe(forested ~ ., data = forested_train) %>%  \n\\ \\ step_dummy(all_nominal_predictors()) %>%  \n\\ \\ step_zv(all_predictors()) %>%  \n\\ \\ step_log(canopy_cover, offset = 0.5) %>% \n\\ \\ step_normalize(all_numeric_predictors())\n:::\n\n<br>\n\nSave the recipe we like so that we can use it in various places, e.g., with different models.\n\n<br>\n\n## Using a recipe with workflows\n\nRecipes are typically combined with a model in a `workflow()` object:\n\n<br>\n\n:::{style=\"font-family: 'Source Code Pro', monospace; font-size: 0.8em;\"}\nforested_wflow <- workflow() %>%  \n\\ \\ [add_recipe(forested_rec)]{style=\"color: #CA225E;\"} %>%  \n\\ \\ add_model(linear_reg())\n:::\n\n## Recipes are estimated\n\nEvery preprocessing step in a recipe that involved calculations uses the *training* set. For example:\n\n- Levels of a factor\n- Determination of zero-variance\n- Normalization\n- Feature extraction\n\nOnce a recipe is added to a workflow, this occurs when `fit()` is called.\n\n\n## Debugging a recipe\n\n- Typically, you will want to use a workflow to estimate and apply a recipe.\n\n. . .\n\n- If you have an error and need to debug your recipe, the original recipe object (e.g. `forested_rec`) can be estimated manually with a function called `prep()`. It is analogous to `fit()`. See [TMwR section 16.4](https://www.tmwr.org/dimensionality.html#recipe-functions).\n\n. . .\n\n- Another function, `bake()`, is analogous to `predict()`, and gives you the processed data back.\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n<br>\n\n*Take the recipe and `prep()` then `bake()` it to see what the resulting data set looks like.*\n\n*Try removing steps to see how the result changes.*\n\n<br>\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"recipes-prep\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n## Printing a recipe\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_rec\n#> \n#> ── Recipe ────────────────────────────────────────────────────────────\n#> \n#> ── Inputs\n#> Number of variables by role\n#> outcome:    1\n#> predictor: 18\n#> \n#> ── Operations\n#> • Dummy variables from: all_nominal_predictors()\n#> • Zero variance filter on: all_predictors()\n#> • Log transformation on: canopy_cover\n#> • Centering and scaling for: all_numeric_predictors()\n```\n:::\n\n\n\n## Prepping a recipe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep(forested_rec)\n#> \n#> ── Recipe ────────────────────────────────────────────────────────────\n#> \n#> ── Inputs\n#> Number of variables by role\n#> outcome:    1\n#> predictor: 18\n#> \n#> ── Training information\n#> Training data contained 5685 data points and no incomplete rows.\n#> \n#> ── Operations\n#> • Dummy variables from: tree_no_tree and land_type | Trained\n#> • Zero variance filter removed: <none> | Trained\n#> • Log transformation on: canopy_cover | Trained\n#> • Centering and scaling for: year and elevation, ... | Trained\n```\n:::\n\n\n\n## Baking a recipe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep(forested_rec) %>%\n  bake(new_data = forested_train)\n#> # A tibble: 5,685 × 20\n#>      year elevation eastness northness roughness dew_temp precip_annual temp_annual_mean temp_annual_min temp_annual_max temp_january_min vapor_min vapor_max canopy_cover     lon    lat forested\n#>     <dbl>     <dbl>    <dbl>     <dbl>     <dbl>    <dbl>         <dbl>            <dbl>           <dbl>           <dbl>            <dbl>     <dbl>     <dbl>        <dbl>   <dbl>  <dbl> <fct>   \n#>  1  0.206   -0.450   -0.0203    -1.38    -0.874   -0.169         -0.864          0.532           -0.403           0.959           -0.0702     0.755     1.21        -0.566 -0.175  -0.988 No      \n#>  2  0.206   -1.07     1.38       0.563   -0.874    1.33           0.132          0.726            1.24            0.159            1.34      -1.00     -1.00         0.494 -0.856   1.10  Yes     \n#>  3  0.206   -0.0762  -1.17      -0.711   -0.506   -0.533         -0.858          0.116           -1.00            0.248           -0.0613     1.13      0.820       -1.73   0.270   0.175 No      \n#>  4 -0.413    1.26     0.109      1.45     0.683   -0.0987         0.448         -1.21             0.221          -1.56            -0.621     -0.625    -1.57         0.917 -1.52    0.654 Yes     \n#>  5 -0.723    0.294    1.31       0.721    0.445   -0.0847         1.02           0.0529           0.795          -0.346            0.552      0.166    -0.683        0.690 -0.419   1.32  Yes     \n#>  6  0.516   -1.41     0.138     -1.38    -0.917    2.01           1.03           0.894            2.21            0.127            1.75      -1.35     -1.48         0.951 -1.84   -0.338 Yes     \n#>  7 -0.413    2.83    -1.32       0.435    0.0343  -2.25           0.380         -3.26            -2.01           -3.09            -3.03      -0.826    -1.75         0.690 -0.0159  1.65  Yes     \n#>  8 -0.103    0.682   -0.0636     1.45     0.532   -0.165          1.21          -0.801            0.0620         -0.915           -0.554     -0.571    -0.908        0.931 -0.636  -1.33  Yes     \n#>  9  0.516   -0.508   -1.36       0.306   -0.809   -0.137         -0.911          0.549           -0.336           0.856            0.0909     0.581     1.19        -1.73   0.760  -0.209 No      \n#> 10  0.826    0.196    0.960      1.12     1.20    -0.550         -0.717          0.00667         -0.741          -0.0616           0.0909     1.43      0.373       -0.296  0.155  -0.204 No      \n#> # ℹ 5,675 more rows\n#> # ℹ 3 more variables: tree_no_tree_No.tree <dbl>, land_type_Non.tree.vegetation <dbl>, land_type_Tree <dbl>\n```\n:::\n\n\n\n## Tidying a recipe\n\nOnce a recipe as been estimated, there are various bits of information saved in it.\n\n- The `tidy()` function can be used to get specific results from the recipe.\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Take a prepped recipe and use the `tidy()` function on it.*\n\n*Use the `number` argument to inspect different steps.*\n\n<br>\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"recipes-tidy\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n## Tidying a recipe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep(forested_rec) %>%\n  tidy()\n#> # A tibble: 4 × 6\n#>   number operation type      trained skip  id             \n#>    <int> <chr>     <chr>     <lgl>   <lgl> <chr>          \n#> 1      1 step      dummy     TRUE    FALSE dummy_jlmcG    \n#> 2      2 step      zv        TRUE    FALSE zv_mYCvS       \n#> 3      3 step      log       TRUE    FALSE log_eme6b      \n#> 4      4 step      normalize TRUE    FALSE normalize_ScVef\n```\n:::\n\n\n\n## Tidying a recipe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep(forested_rec) %>%\n  tidy(number = 1)\n#> # A tibble: 3 × 3\n#>   terms        columns             id         \n#>   <chr>        <chr>               <chr>      \n#> 1 tree_no_tree No tree             dummy_jlmcG\n#> 2 land_type    Non-tree vegetation dummy_jlmcG\n#> 3 land_type    Tree                dummy_jlmcG\n```\n:::\n\n\n\n\n## Using a recipe in tidymodels\n\nThe recommended way to use a recipe in tidymodels is to use it as part of a `workflow()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_wflow <- workflow() %>%  \n  add_recipe(forested_rec) %>%  \n  add_model(linear_reg())\n```\n:::\n\n\n\nWhen used in this way, you don't need to worry about `prep()` and `bake()` as it is handled for you.\n\n## More information\n\n- <https://recipes.tidymodels.org/>\n- <https://www.tmwr.org/recipes.html>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}