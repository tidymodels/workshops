{
  "hash": "9f87893fbe4d9092faf912c095fda0b4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"4 - Evaluating models\"\nsubtitle: \"Introduction to tidymodels\"\nformat:\n  revealjs: \n    slide-number: true\n    footer: <https://workshops.tidymodels.org>\n    include-before-body: header.html\n    include-after-body: footer-annotations.html\n    theme: [default, tidymodels.scss]\n    width: 1280\n    height: 720\nknitr:\n  opts_chunk: \n    echo: true\n    collapse: true\n    comment: \"#>\"\n    fig.path: \"figures/\"\n---\n\n\n\n\n\n## Looking at predictions\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(forested_fit, new_data = forested_train)\n#> # A tibble: 5,685 Ã— 22\n#>    .pred_class .pred_Yes .pred_No forested  year elevation eastness northness\n#>    <fct>           <dbl>    <dbl> <fct>    <dbl>     <dbl>    <dbl>     <dbl>\n#>  1 No             0.0114   0.989  No        2016       464       -5       -99\n#>  2 Yes            0.636    0.364  Yes       2016       166       92        37\n#>  3 No             0.0114   0.989  No        2016       644      -85       -52\n#>  4 Yes            0.977    0.0226 Yes       2014      1285        4        99\n#>  5 Yes            0.977    0.0226 Yes       2013       822       87        48\n#>  6 Yes            0.808    0.192  Yes       2017         3        6       -99\n#>  7 Yes            0.977    0.0226 Yes       2014      2041      -95        28\n#>  8 Yes            0.977    0.0226 Yes       2015      1009       -8        99\n#>  9 No             0.0114   0.989  No        2017       436      -98        19\n#> 10 No             0.0114   0.989  No        2018       775       63        76\n#> # â„¹ 5,675 more rows\n#> # â„¹ 14 more variables: roughness <dbl>, tree_no_tree <fct>, dew_temp <dbl>,\n#> #   precip_annual <dbl>, temp_annual_mean <dbl>, temp_annual_min <dbl>,\n#> #   temp_annual_max <dbl>, temp_january_min <dbl>, vapor_min <dbl>,\n#> #   vapor_max <dbl>, canopy_cover <dbl>, lon <dbl>, lat <dbl>, land_type <fct>\n```\n:::\n\n\n\n## Confusion matrix ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n![](images/confusion-matrix.png)\n\n## Confusion matrix ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(forested_fit, new_data = forested_train) %>%\n  conf_mat(truth = forested, estimate = .pred_class)\n#>           Truth\n#> Prediction  Yes   No\n#>        Yes 2991  176\n#>        No   144 2374\n```\n:::\n\n\n\n## Confusion matrix ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(forested_fit, new_data = forested_train) %>%\n  conf_mat(truth = forested, estimate = .pred_class) %>%\n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](figures/conf-mat-plot-1.svg)\n:::\n:::\n\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"60%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(forested_fit, new_data = forested_train) %>%\n  accuracy(truth = forested, estimate = .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.944\n```\n:::\n\n\n:::\n\n::: {.column width=\"40%\"}\n![](images/confusion-matrix-accuracy.png)\n:::\n:::\n\n::: notes\nThere used to be a slide here calling out the pitfalls of accuracy when classes are imbalanced.\n:::\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"60%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(forested_fit, new_data = forested_train) %>%\n  sensitivity(truth = forested, estimate = .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 sensitivity binary         0.954\n```\n:::\n\n\n:::\n\n::: {.column width=\"40%\"}\n![](images/confusion-matrix-sensitivity.png)\n:::\n:::\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"60%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"3-6\"}\naugment(forested_fit, new_data = forested_train) %>%\n  sensitivity(truth = forested, estimate = .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 sensitivity binary         0.954\n```\n:::\n\n\n\n<br>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(forested_fit, new_data = forested_train) %>%\n  specificity(truth = forested, estimate = .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 specificity binary         0.931\n```\n:::\n\n\n:::\n\n::: {.column width=\"40%\"}\n![](images/confusion-matrix-specificity.png)\n:::\n:::\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWe can use `metric_set()` to combine multiple calculations into one\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_metrics <- metric_set(accuracy, specificity, sensitivity)\n\naugment(forested_fit, new_data = forested_train) %>%\n  forested_metrics(truth = forested, estimate = .pred_class)\n#> # A tibble: 3 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 accuracy    binary         0.944\n#> 2 specificity binary         0.931\n#> 3 sensitivity binary         0.954\n```\n:::\n\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nMetrics and metric sets work with grouped data frames!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(forested_fit, new_data = forested_train) %>%\n  group_by(tree_no_tree) %>%\n  accuracy(truth = forested, estimate = .pred_class)\n#> # A tibble: 2 Ã— 4\n#>   tree_no_tree .metric  .estimator .estimate\n#>   <fct>        <chr>    <chr>          <dbl>\n#> 1 Tree         accuracy binary         0.946\n#> 2 No tree      accuracy binary         0.941\n```\n:::\n\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Apply the `forested_metrics` metric set to `augment()` \\\noutput grouped by `tree_no_tree`.*\n\n*Do any metrics differ substantially between groups?*\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"forested-grouped-metrics\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n:::notes\nThe specificity for `\"Tree\"` is a good bit lower than it is for `\"No tree\"`.\n\nSpecificity is the proportion of negatives that are correctly identified as negatives.\n\"Negative\" is the non-event level of the outcome, i.e. \"non-forested.\"\nSo, when this index classifies the plot as having a tree, the model does not do well at correctly identifying the plot as non-forested when it is indeed non-forested.\n:::\n\n## Two class data\n\nThese metrics assume that we know the threshold for converting \"soft\" probability predictions into \"hard\" class predictions.\n\n. . .\n\nIs a 50% threshold good? \n\nWhat happens if we say that we need to be 80% sure to declare an event?\n\n-   sensitivity â¬‡ï¸, specificity â¬†ï¸\n\n. . .\n\nWhat happens for a 20% threshold?\n\n-   sensitivity â¬†ï¸, specificity â¬‡ï¸\n\n## Varying the threshold\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](figures/thresholds-1.svg)\n:::\n:::\n\n\n\n## ROC curves\n\n::: columns\n::: {.column width=\"50%\"}\nFor an ROC (receiver operator characteristic) curve, we plot\n\n- the false positive rate (1 - specificity) on the x-axis\n- the true positive rate (sensitivity) on the y-axis\n\nwith sensitivity and specificity calculated at all possible thresholds.\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](figures/roc-curve-1-1.svg){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n:::notes\nROC curves are insensitive to class imbalance.\n:::\n\n## ROC curves\n\n::: columns\n::: {.column width=\"50%\"}\nWe can use the area under the ROC curve as a classification metric: \n\n- ROC AUC = 1 ğŸ’¯ \n- ROC AUC = 1/2 ğŸ˜¢\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](figures/roc-curve-2-1.svg){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n## ROC curves ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assumes _first_ factor level is event; there are options to change that\naugment(forested_fit, new_data = forested_train) %>% \n  roc_curve(truth = forested, .pred_Yes) %>%\n  slice(1, 20, 50)\n#> # A tibble: 3 Ã— 3\n#>   .threshold specificity sensitivity\n#>        <dbl>       <dbl>       <dbl>\n#> 1   -Inf           0           1    \n#> 2      0.235       0.885       0.972\n#> 3      0.909       0.969       0.826\n\naugment(forested_fit, new_data = forested_train) %>% \n  roc_auc(truth = forested, .pred_Yes)\n#> # A tibble: 1 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 roc_auc binary         0.975\n```\n:::\n\n\n\n## ROC curve plot ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\naugment(forested_fit, \n        new_data = forested_train) %>% \n  roc_curve(truth = forested, \n            .pred_Yes) %>%\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](figures/roc-curve-code-1.svg){width=100%}\n:::\n:::\n\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Compute and plot an ROC curve for your current model.*\n\n*What data are being used for this ROC curve plot?*\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"roc-curve\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n## Brier score\n\nWhat if we don't turn predicted probabilities into class predictions?\n\n. . .\n\nThe Brier score is analogous to the mean squared error in regression models:\n\n$$\nBrier_{class} = \\frac{1}{N}\\sum_{i=1}^N\\sum_{k=1}^C (y_{ik} - \\hat{p}_{ik})^2\n$$\n\n## Brier score  {.annotation}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(forested_fit, new_data = forested_train) %>% \n  brier_class(truth = forested, .pred_Yes) \n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 brier_class binary        0.0469\n```\n:::\n\n\n\n. . .\n\nSmaller values are better, for binary classification the \"bad model threshold\" is about 0.25.\n\n\n## Separation vs calibration\n\n::: columns\n::: {.column width=\"50%\"}\nThe ROC captures separation.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](figures/separation-forested-1.svg){width=100%}\n:::\n:::\n\n\n:::\n::: {.column width=\"50%\"}\nThe Brier score captures calibration.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](figures/calibration-forested-1.svg){width=100%}\n:::\n:::\n\n\n:::\n:::\n\n::: notes\n- Good separation: the densities don't overlap.\n- Good calibration: the calibration line follows the diagonal.\n\nCalibration plot: We bin observations according to predicted probability. In the bin for 20%-30% predicted prob, we should see an event rate of ~25% if the model is well-calibrated.\n:::\n\n##  {background-iframe=\"https://yardstick.tidymodels.org/reference/index.html\"}\n\n::: footer\n:::\n\n# âš ï¸ DANGERS OF OVERFITTING âš ï¸\n\n## Dangers of overfitting  {.annotation}\n\n![](https://raw.githubusercontent.com/topepo/2022-nyr-workshop/main/images/tuning-overfitting-train-1.svg)\n\n## Dangers of overfitting âš ï¸\n\n![](https://raw.githubusercontent.com/topepo/2022-nyr-workshop/main/images/tuning-overfitting-test-1.svg)\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_fit %>%\n  augment(forested_train)\n#> # A tibble: 5,685 Ã— 22\n#>    .pred_class .pred_Yes .pred_No forested  year elevation eastness northness\n#>    <fct>           <dbl>    <dbl> <fct>    <dbl>     <dbl>    <dbl>     <dbl>\n#>  1 No             0.0114   0.989  No        2016       464       -5       -99\n#>  2 Yes            0.636    0.364  Yes       2016       166       92        37\n#>  3 No             0.0114   0.989  No        2016       644      -85       -52\n#>  4 Yes            0.977    0.0226 Yes       2014      1285        4        99\n#>  5 Yes            0.977    0.0226 Yes       2013       822       87        48\n#>  6 Yes            0.808    0.192  Yes       2017         3        6       -99\n#>  7 Yes            0.977    0.0226 Yes       2014      2041      -95        28\n#>  8 Yes            0.977    0.0226 Yes       2015      1009       -8        99\n#>  9 No             0.0114   0.989  No        2017       436      -98        19\n#> 10 No             0.0114   0.989  No        2018       775       63        76\n#> # â„¹ 5,675 more rows\n#> # â„¹ 14 more variables: roughness <dbl>, tree_no_tree <fct>, dew_temp <dbl>,\n#> #   precip_annual <dbl>, temp_annual_mean <dbl>, temp_annual_min <dbl>,\n#> #   temp_annual_max <dbl>, temp_january_min <dbl>, vapor_min <dbl>,\n#> #   vapor_max <dbl>, canopy_cover <dbl>, lon <dbl>, lat <dbl>, land_type <fct>\n```\n:::\n\n\n\nWe call this \"resubstitution\" or \"repredicting the training set\"\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_fit %>%\n  augment(forested_train) %>%\n  accuracy(forested, .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.944\n```\n:::\n\n\n\nWe call this a \"resubstitution estimate\"\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_fit %>%\n  augment(forested_train) %>%\n  accuracy(forested, .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.944\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n:::\n:::\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_fit %>%\n  augment(forested_train) %>%\n  accuracy(forested, .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.944\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_fit %>%\n  augment(forested_test) %>%\n  accuracy(forested, .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.886\n```\n:::\n\n\n:::\n:::\n\n. . .\n\nâš ï¸ Remember that we're demonstrating overfitting \n\n. . .\n\nâš ï¸ Don't use the test set until the *end* of your modeling analysis\n\n\n##  {background-image=\"https://media.giphy.com/media/55itGuoAJiZEEen9gg/giphy.gif\" background-size=\"70%\"}\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute bottom=\"0\" left=\"0\" width=\"150\" height=\"150\"}\n\n*Use `augment()` and a metric function to compute a classification metric like `brier_class()`.*\n\n*Compute the metrics for both training and testing data to demonstrate overfitting!*\n\n*Notice the evidence of overfitting!* âš ï¸\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"augment-metrics\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_fit %>%\n  augment(forested_train) %>%\n  brier_class(forested, .pred_Yes)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 brier_class binary        0.0469\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_fit %>%\n  augment(forested_test) %>%\n  brier_class(forested, .pred_Yes)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 brier_class binary        0.0888\n```\n:::\n\n\n:::\n:::\n\n. . .\n\nWhat if we want to compare more models?\n\n. . .\n\nAnd/or more model configurations?\n\n. . .\n\nAnd we want to understand if these are important differences?\n\n# The testing data are precious ğŸ’\n\n# How can we use the *training* data to compare and evaluate different models? ğŸ¤”\n\n##  {background-color=\"white\" background-image=\"https://www.tmwr.org/premade/resampling.svg\" background-size=\"80%\"}\n\n## Cross-validation\n\n![](https://www.tmwr.org/premade/three-CV.svg)\n\n## Cross-validation\n\n![](https://www.tmwr.org/premade/three-CV-iter.svg)\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*If we use 10 folds, what percent of the training data*\n\n-   *ends up in analysis*\n-   *ends up in assessment*\n\n*for* **each** *fold?*\n\n![](images/forest_mountain.svg){width=\"200\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"percent-in-folds\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvfold_cv(forested_train) # v = 10 is default\n#> #  10-fold cross-validation \n#> # A tibble: 10 Ã— 2\n#>    splits             id    \n#>    <list>             <chr> \n#>  1 <split [5116/569]> Fold01\n#>  2 <split [5116/569]> Fold02\n#>  3 <split [5116/569]> Fold03\n#>  4 <split [5116/569]> Fold04\n#>  5 <split [5116/569]> Fold05\n#>  6 <split [5117/568]> Fold06\n#>  7 <split [5117/568]> Fold07\n#>  8 <split [5117/568]> Fold08\n#>  9 <split [5117/568]> Fold09\n#> 10 <split [5117/568]> Fold10\n```\n:::\n\n\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWhat is in this?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_folds <- vfold_cv(forested_train)\nforested_folds$splits[1:3]\n#> [[1]]\n#> <Analysis/Assess/Total>\n#> <5116/569/5685>\n#> \n#> [[2]]\n#> <Analysis/Assess/Total>\n#> <5116/569/5685>\n#> \n#> [[3]]\n#> <Analysis/Assess/Total>\n#> <5116/569/5685>\n```\n:::\n\n\n\n::: notes\nTalk about a list column, storing non-atomic types in dataframe\n:::\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvfold_cv(forested_train, v = 5)\n#> #  5-fold cross-validation \n#> # A tibble: 5 Ã— 2\n#>   splits              id   \n#>   <list>              <chr>\n#> 1 <split [4548/1137]> Fold1\n#> 2 <split [4548/1137]> Fold2\n#> 3 <split [4548/1137]> Fold3\n#> 4 <split [4548/1137]> Fold4\n#> 5 <split [4548/1137]> Fold5\n```\n:::\n\n\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWe'll use this setup:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nforested_folds <- vfold_cv(forested_train, v = 10)\nforested_folds\n#> #  10-fold cross-validation \n#> # A tibble: 10 Ã— 2\n#>    splits             id    \n#>    <list>             <chr> \n#>  1 <split [5116/569]> Fold01\n#>  2 <split [5116/569]> Fold02\n#>  3 <split [5116/569]> Fold03\n#>  4 <split [5116/569]> Fold04\n#>  5 <split [5116/569]> Fold05\n#>  6 <split [5117/568]> Fold06\n#>  7 <split [5117/568]> Fold07\n#>  8 <split [5117/568]> Fold08\n#>  9 <split [5117/568]> Fold09\n#> 10 <split [5117/568]> Fold10\n```\n:::\n\n\n\n. . .\n\nSet the seed when creating resamples\n\n# We are equipped with metrics and resamples!\n\n## Fit our model to the resamples\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_res <- fit_resamples(forested_wflow, forested_folds)\nforested_res\n#> # Resampling results\n#> # 10-fold cross-validation \n#> # A tibble: 10 Ã— 4\n#>    splits             id     .metrics         .notes          \n#>    <list>             <chr>  <list>           <list>          \n#>  1 <split [5116/569]> Fold01 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n#>  2 <split [5116/569]> Fold02 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n#>  3 <split [5116/569]> Fold03 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n#>  4 <split [5116/569]> Fold04 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n#>  5 <split [5116/569]> Fold05 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n#>  6 <split [5117/568]> Fold06 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n#>  7 <split [5117/568]> Fold07 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n#>  8 <split [5117/568]> Fold08 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n#>  9 <split [5117/568]> Fold09 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n#> 10 <split [5117/568]> Fold10 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]>\n```\n:::\n\n\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_res %>%\n  collect_metrics()\n#> # A tibble: 3 Ã— 6\n#>   .metric     .estimator   mean     n std_err .config             \n#>   <chr>       <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 accuracy    binary     0.894     10 0.00562 Preprocessor1_Model1\n#> 2 brier_class binary     0.0817    10 0.00434 Preprocessor1_Model1\n#> 3 roc_auc     binary     0.951     10 0.00378 Preprocessor1_Model1\n```\n:::\n\n\n\n::: notes\n`collect_metrics()` is one of a suite of `collect_*()` functions that can be used to work with columns of tuning results. Most columns in a tuning result prefixed with `.` have a corresponding `collect_*()` function with options for common summaries.\n:::\n\n. . .\n\nWe can reliably measure performance using only the **training** data ğŸ‰\n\n## Comparing metrics ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nHow do the metrics from resampling compare to the metrics from training and testing?\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_res %>%\n  collect_metrics() %>% \n  select(.metric, mean, n)\n#> # A tibble: 3 Ã— 3\n#>   .metric       mean     n\n#>   <chr>        <dbl> <int>\n#> 1 accuracy    0.894     10\n#> 2 brier_class 0.0817    10\n#> 3 roc_auc     0.951     10\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\nThe ROC AUC previously was\n\n- 0.97 for the training set\n- 0.95 for test set\n:::\n:::\n\n. . .\n\nRemember that:\n\nâš ï¸ the training set gives you overly optimistic metrics\n\nâš ï¸ the test set is precious\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the assessment set results\nctrl_forested <- control_resamples(save_pred = TRUE)\nforested_res <- fit_resamples(forested_wflow, forested_folds, control = ctrl_forested)\n\nforested_res\n#> # Resampling results\n#> # 10-fold cross-validation \n#> # A tibble: 10 Ã— 5\n#>    splits             id     .metrics         .notes           .predictions\n#>    <list>             <chr>  <list>           <list>           <list>      \n#>  1 <split [5116/569]> Fold01 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  2 <split [5116/569]> Fold02 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  3 <split [5116/569]> Fold03 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  4 <split [5116/569]> Fold04 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  5 <split [5116/569]> Fold05 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  6 <split [5117/568]> Fold06 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  7 <split [5117/568]> Fold07 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  8 <split [5117/568]> Fold08 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  9 <split [5117/568]> Fold09 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#> 10 <split [5117/568]> Fold10 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>\n```\n:::\n\n\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the assessment set results\nforested_preds <- collect_predictions(forested_res)\nforested_preds\n#> # A tibble: 5,685 Ã— 7\n#>    .pred_class .pred_Yes .pred_No id      .row forested .config             \n#>    <fct>           <dbl>    <dbl> <chr>  <int> <fct>    <chr>               \n#>  1 Yes           0.5       0.5    Fold01     2 Yes      Preprocessor1_Model1\n#>  2 Yes           0.982     0.0178 Fold01     5 Yes      Preprocessor1_Model1\n#>  3 No            0.00790   0.992  Fold01     9 No       Preprocessor1_Model1\n#>  4 No            0.4       0.6    Fold01    14 No       Preprocessor1_Model1\n#>  5 Yes           0.870     0.130  Fold01    18 Yes      Preprocessor1_Model1\n#>  6 Yes           0.982     0.0178 Fold01    59 Yes      Preprocessor1_Model1\n#>  7 No            0.00790   0.992  Fold01    67 No       Preprocessor1_Model1\n#>  8 Yes           0.982     0.0178 Fold01    89 Yes      Preprocessor1_Model1\n#>  9 No            0.00790   0.992  Fold01    94 No       Preprocessor1_Model1\n#> 10 Yes           0.982     0.0178 Fold01   111 Yes      Preprocessor1_Model1\n#> # â„¹ 5,675 more rows\n```\n:::\n\n\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_preds %>% \n  group_by(id) %>%\n  forested_metrics(truth = forested, estimate = .pred_class)\n#> # A tibble: 30 Ã— 4\n#>    id     .metric  .estimator .estimate\n#>    <chr>  <chr>    <chr>          <dbl>\n#>  1 Fold01 accuracy binary         0.896\n#>  2 Fold02 accuracy binary         0.859\n#>  3 Fold03 accuracy binary         0.868\n#>  4 Fold04 accuracy binary         0.921\n#>  5 Fold05 accuracy binary         0.900\n#>  6 Fold06 accuracy binary         0.891\n#>  7 Fold07 accuracy binary         0.896\n#>  8 Fold08 accuracy binary         0.903\n#>  9 Fold09 accuracy binary         0.896\n#> 10 Fold10 accuracy binary         0.905\n#> # â„¹ 20 more rows\n```\n:::\n\n\n\n## Where are the fitted models? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}  {.annotation}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_res\n#> # Resampling results\n#> # 10-fold cross-validation \n#> # A tibble: 10 Ã— 5\n#>    splits             id     .metrics         .notes           .predictions\n#>    <list>             <chr>  <list>           <list>           <list>      \n#>  1 <split [5116/569]> Fold01 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  2 <split [5116/569]> Fold02 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  3 <split [5116/569]> Fold03 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  4 <split [5116/569]> Fold04 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  5 <split [5116/569]> Fold05 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  6 <split [5117/568]> Fold06 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  7 <split [5117/568]> Fold07 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  8 <split [5117/568]> Fold08 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  9 <split [5117/568]> Fold09 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#> 10 <split [5117/568]> Fold10 <tibble [3 Ã— 4]> <tibble [0 Ã— 3]> <tibble>\n```\n:::\n\n\n\n. . .\n\nğŸ—‘ï¸\n\n# Alternate resampling schemes\n\n## Bootstrapping\n\n![](https://www.tmwr.org/premade/bootstraps.svg)\n\n## Bootstrapping ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3214)\nbootstraps(forested_train)\n#> # Bootstrap sampling \n#> # A tibble: 25 Ã— 2\n#>    splits              id         \n#>    <list>              <chr>      \n#>  1 <split [5685/2075]> Bootstrap01\n#>  2 <split [5685/2093]> Bootstrap02\n#>  3 <split [5685/2129]> Bootstrap03\n#>  4 <split [5685/2093]> Bootstrap04\n#>  5 <split [5685/2111]> Bootstrap05\n#>  6 <split [5685/2105]> Bootstrap06\n#>  7 <split [5685/2139]> Bootstrap07\n#>  8 <split [5685/2079]> Bootstrap08\n#>  9 <split [5685/2113]> Bootstrap09\n#> 10 <split [5685/2101]> Bootstrap10\n#> # â„¹ 15 more rows\n```\n:::\n\n\n\n##  {background-iframe=\"https://rsample.tidymodels.org/reference/index.html\"}\n\n::: footer\n:::\n\n## The whole game - status update\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/whole-game-transparent-resamples.jpg){fig-align='center'}\n:::\n:::\n\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Create:*\n\n-   *Monte Carlo Cross-Validation sets*\n-   *validation set*\n\n(use the reference guide to find the functions)\n\n*Don't forget to set a seed when you resample!*\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"try-rsample\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n## Monte Carlo Cross-Validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(322)\nmc_cv(forested_train, times = 10)\n#> # Monte Carlo cross-validation (0.75/0.25) with 10 resamples  \n#> # A tibble: 10 Ã— 2\n#>    splits              id        \n#>    <list>              <chr>     \n#>  1 <split [4263/1422]> Resample01\n#>  2 <split [4263/1422]> Resample02\n#>  3 <split [4263/1422]> Resample03\n#>  4 <split [4263/1422]> Resample04\n#>  5 <split [4263/1422]> Resample05\n#>  6 <split [4263/1422]> Resample06\n#>  7 <split [4263/1422]> Resample07\n#>  8 <split [4263/1422]> Resample08\n#>  9 <split [4263/1422]> Resample09\n#> 10 <split [4263/1422]> Resample10\n```\n:::\n\n\n\n## Validation set ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(853)\nforested_val_split <- initial_validation_split(forested)\nvalidation_set(forested_val_split)\n#> # A tibble: 1 Ã— 2\n#>   splits              id        \n#>   <list>              <chr>     \n#> 1 <split [4264/1421]> validation\n```\n:::\n\n\n\n. . .\n\nA validation set is just another type of resample\n\n# Decision tree ğŸŒ³\n\n# Random forest ğŸŒ³ğŸŒ²ğŸŒ´ğŸŒµğŸŒ´ğŸŒ³ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒµğŸŒ´ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒ³ğŸŒµğŸŒµğŸŒ´ğŸŒ²ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒ´ğŸŒµğŸŒ´ğŸŒ²ğŸŒ´ğŸŒµğŸŒ²ğŸŒµğŸŒ´ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒµğŸŒ³ğŸŒ´ğŸŒ³\n\n## Random forest ğŸŒ³ğŸŒ²ğŸŒ´ğŸŒµğŸŒ³ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒµğŸŒ´ğŸŒ³ğŸŒµ\n\n- Ensemble many decision tree models\n\n- All the trees vote! ğŸ—³ï¸\n\n- Bootstrap aggregating + random predictor sampling\n\n. . .\n\n- Often works well without tuning hyperparameters (more on this later!), as long as there are enough trees\n\n## Create a random forest model ![](hexes/parsnip.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_spec <- rand_forest(trees = 1000, mode = \"classification\")\nrf_spec\n#> Random Forest Model Specification (classification)\n#> \n#> Main Arguments:\n#>   trees = 1000\n#> \n#> Computational engine: ranger\n```\n:::\n\n\n\n## Create a random forest model ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_wflow <- workflow(forested ~ ., rf_spec)\nrf_wflow\n#> â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#> Preprocessor: Formula\n#> Model: rand_forest()\n#> \n#> â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> forested ~ .\n#> \n#> â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> Random Forest Model Specification (classification)\n#> \n#> Main Arguments:\n#>   trees = 1000\n#> \n#> Computational engine: ranger\n```\n:::\n\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Use `fit_resamples()` and `rf_wflow` to:*\n\n-   *keep predictions*\n-   *compute metrics*\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"try-fit-resamples\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">08</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nctrl_forested <- control_resamples(save_pred = TRUE)\n\n# Random forest uses random numbers so set the seed first\n\nset.seed(2)\nrf_res <- fit_resamples(rf_wflow, forested_folds, control = ctrl_forested)\ncollect_metrics(rf_res)\n#> # A tibble: 3 Ã— 6\n#>   .metric     .estimator   mean     n std_err .config             \n#>   <chr>       <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 accuracy    binary     0.918     10 0.00585 Preprocessor1_Model1\n#> 2 brier_class binary     0.0618    10 0.00337 Preprocessor1_Model1\n#> 3 roc_auc     binary     0.972     10 0.00309 Preprocessor1_Model1\n```\n:::\n\n\n\n## The whole game - status update\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/whole-game-transparent-select.jpg){fig-align='center'}\n:::\n:::\n\n\n\n## The final fit ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} \n\nSuppose that we are happy with our random forest model.\n\nLet's fit the model on the training set and verify our performance using the test set.\n\n. . .\n\nWe've shown you `fit()` and `predict()` (+ `augment()`) but there is a shortcut:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# forested_split has train + test info\nfinal_fit <- last_fit(rf_wflow, forested_split) \n\nfinal_fit\n#> # Resampling results\n#> # Manual resampling \n#> # A tibble: 1 Ã— 6\n#>   splits              id               .metrics .notes   .predictions .workflow \n#>   <list>              <chr>            <list>   <list>   <list>       <list>    \n#> 1 <split [5685/1422]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n\n\n\n## What is in `final_fit`? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(final_fit)\n#> # A tibble: 3 Ã— 4\n#>   .metric     .estimator .estimate .config             \n#>   <chr>       <chr>          <dbl> <chr>               \n#> 1 accuracy    binary        0.911  Preprocessor1_Model1\n#> 2 roc_auc     binary        0.970  Preprocessor1_Model1\n#> 3 brier_class binary        0.0652 Preprocessor1_Model1\n```\n:::\n\n\n\n. . .\n\nThese are metrics computed with the **test** set\n\n## What is in `final_fit`? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_predictions(final_fit)\n#> # A tibble: 1,422 Ã— 7\n#>    .pred_class .pred_Yes .pred_No id                .row forested .config       \n#>    <fct>           <dbl>    <dbl> <chr>            <int> <fct>    <chr>         \n#>  1 Yes             0.822   0.178  train/test split     3 No       Preprocessor1â€¦\n#>  2 Yes             0.707   0.293  train/test split     4 Yes      Preprocessor1â€¦\n#>  3 No              0.270   0.730  train/test split     7 Yes      Preprocessor1â€¦\n#>  4 Yes             0.568   0.432  train/test split     8 Yes      Preprocessor1â€¦\n#>  5 Yes             0.554   0.446  train/test split    10 Yes      Preprocessor1â€¦\n#>  6 Yes             0.970   0.0297 train/test split    11 Yes      Preprocessor1â€¦\n#>  7 Yes             0.963   0.0367 train/test split    12 Yes      Preprocessor1â€¦\n#>  8 Yes             0.947   0.0528 train/test split    14 Yes      Preprocessor1â€¦\n#>  9 Yes             0.943   0.0573 train/test split    15 Yes      Preprocessor1â€¦\n#> 10 Yes             0.977   0.0227 train/test split    19 Yes      Preprocessor1â€¦\n#> # â„¹ 1,412 more rows\n```\n:::\n\n\n\n## What is in `final_fit`? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_workflow(final_fit)\n#> â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#> Preprocessor: Formula\n#> Model: rand_forest()\n#> \n#> â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> forested ~ .\n#> \n#> â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> Ranger result\n#> \n#> Call:\n#>  ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) \n#> \n#> Type:                             Probability estimation \n#> Number of trees:                  1000 \n#> Sample size:                      5685 \n#> Number of independent variables:  18 \n#> Mtry:                             4 \n#> Target node size:                 10 \n#> Variable importance mode:         none \n#> Splitrule:                        gini \n#> OOB prediction error (Brier s.):  0.06153207\n```\n:::\n\n\n\n. . .\n\nUse this for **prediction** on new data, like for deploying\n\n## The whole game\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/whole-game-final-performance.jpg){fig-align='center'}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}