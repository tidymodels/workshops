{
  "hash": "54311eb5fbe455ab7e952861b3c7c141",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"2 - Feature Engineering\"\nsubtitle: \"Advanced tidymodels\"\nformat:\n  revealjs: \n    slide-number: true\n    footer: <https://workshops.tidymodels.org>\n    include-before-body: header.html\n    include-after-body: footer-annotations.html\n    theme: [default, tidymodels.scss]\n    width: 1280\n    height: 720\nknitr:\n  opts_chunk: \n    echo: true\n    collapse: true\n    comment: \"#>\"\n    fig.path: \"figures/\"\n---\n\n\n\n\n\n\n## Working with our predictors\n\nWe might want to modify our predictors columns for a few reasons: \n\n::: {.incremental}\n- The model requires them in a different format (e.g. [dummy variables](https://aml4td.org/chapters/categorical-predictors.html#sec-indicators) for linear regression).\n- The model needs certain data qualities (e.g. same units for K-NN).\n- The outcome is better predicted when one or more columns are transformed in some way (a.k.a \"feature engineering\"). \n:::\n\n. . .\n\nThe first two reasons are fairly predictable ([next page](https://www.tmwr.org/pre-proc-table.html#tab:preprocessing)).\n\nThe last one depends on your modeling problem. \n\n\n##  {background-iframe=\"https://www.tmwr.org/pre-proc-table.html#tab:preprocessing\"}\n\n::: footer\n:::\n\n\n## What is feature engineering?\n\nThink of a feature as some *representation* of a predictor that will be used in a model.\n\n. . .\n\nExample representations:\n\n-   Interactions\n-   Polynomial expansions/splines\n-   Principal component analysis (PCA) feature extraction\n\nThere are a lot of examples in [_Feature Engineering and Selection_](https://bookdown.org/max/FES/) (FES) and [_Applied Machine Learning for Tabular Data_](https://aml4td.org/) (aml4td).\n\n\n\n## Example: Dates\n\nHow can we represent date columns for our model?\n\n. . .\n\nWhen we use a date column in its native format, most models in R convert it to an integer.\n\n. . .\n\nWe can re-engineer it as:\n\n-   Days since a reference date\n-   Day of the week\n-   Month\n-   Year\n-   Indicators for holidays\n\n::: notes\nThe main point is that we try to maximize performance with different versions of the predictors. \n\nMention that, for the Chicago data, the day or the week features are usually the most important ones in the model.\n:::\n\n## General definitions ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n-   *Data preprocessing* steps allow your model to fit.\n\n-   *Feature engineering* steps help the model do the least work to predict the outcome as well as possible.\n\nThe recipes package can handle both!\n\n::: notes\nThese terms are often used interchangeably in the ML community but we want to distinguish them.\n:::\n\n\n## Previously - Setup  ![](hexes/tidymodels.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n:::: {.columns}\n\n::: {.column width=\"40\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n\n# Add another package:\nlibrary(textrecipes)\n\n# Max's usual settings: \ntidymodels_prefer()\ntheme_set(theme_bw())\noptions(\n  pillar.advice = FALSE, \n  pillar.min_title_chars = Inf\n)\n```\n:::\n\n\n\n:::\n\n::: {.column width=\"60\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(hotel_rates)\nset.seed(295)\nhotel_rates <- \n  hotel_rates %>% \n  sample_n(5000) %>% \n  arrange(arrival_date) %>% \n  select(-arrival_date) %>% \n  mutate(\n    company = factor(as.character(company)),\n    country = factor(as.character(country)),\n    agent = factor(as.character(agent))\n  )\n```\n:::\n\n\n\n\n:::\n\n::::\n\n\n## Previously - Data Usage  ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(4028)\nhotel_split <- initial_split(hotel_rates, strata = avg_price_per_room)\n\nhotel_train <- training(hotel_split)\nhotel_test <- testing(hotel_split)\n```\n:::\n\n\n\n<br>\n\nWe'll go from here and create a set of resamples to use for model assessments. \n\n\n## Resampling Strategy\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/10-Fold-CV.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Resampling Strategy ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}  {.annotation}\n\nWe'll use simple 10-fold cross-validation (stratified sampling):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(472)\nhotel_rs <- vfold_cv(hotel_train, strata = avg_price_per_room)\nhotel_rs\n#> #  10-fold cross-validation using stratification \n#> # A tibble: 10 Ã— 2\n#>    splits             id    \n#>    <list>             <chr> \n#>  1 <split [3372/377]> Fold01\n#>  2 <split [3373/376]> Fold02\n#>  3 <split [3373/376]> Fold03\n#>  4 <split [3373/376]> Fold04\n#>  5 <split [3373/376]> Fold05\n#>  6 <split [3374/375]> Fold06\n#>  7 <split [3375/374]> Fold07\n#>  8 <split [3376/373]> Fold08\n#>  9 <split [3376/373]> Fold09\n#> 10 <split [3376/373]> Fold10\n```\n:::\n\n\n\n\n## Prepare your data for modeling ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n- The recipes package is an extensible framework for pipeable sequences of preprocessing and feature engineering steps.\n\n. . .\n\n- Statistical parameters for the steps can be _estimated_ from an initial data set and then _applied_ to other data sets.\n\n. . .\n\n- The resulting processed output can be used as inputs for statistical or machine learning models.\n\n## A first recipe ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhotel_rec <- \n  recipe(avg_price_per_room ~ ., data = hotel_train)\n```\n:::\n\n\n\n. . .\n\n- The `recipe()` function assigns columns to roles of \"outcome\" or \"predictor\" using the formula\n\n## A first recipe ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(hotel_rec)\n#> # A tibble: 27 Ã— 4\n#>    variable                type      role      source  \n#>    <chr>                   <list>    <chr>     <chr>   \n#>  1 lead_time               <chr [2]> predictor original\n#>  2 stays_in_weekend_nights <chr [2]> predictor original\n#>  3 stays_in_week_nights    <chr [2]> predictor original\n#>  4 adults                  <chr [2]> predictor original\n#>  5 children                <chr [2]> predictor original\n#>  6 babies                  <chr [2]> predictor original\n#>  7 meal                    <chr [3]> predictor original\n#>  8 country                 <chr [3]> predictor original\n#>  9 market_segment          <chr [3]> predictor original\n#> 10 distribution_channel    <chr [3]> predictor original\n#> # â„¹ 17 more rows\n```\n:::\n\n\n\nThe `type` column contains information on the variables\n\n\n## Your turn {transition=\"slide-in\"}\n\nWhat do you think are in the `type` vectors for the `lead_time` and `country` columns?\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"var-types\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">02</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\n## Create indicator variables ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"3\"}\nhotel_rec <- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %>% \n  step_dummy(all_nominal_predictors())\n```\n:::\n\n\n\n. . .\n\n- For any factor or character predictors, make binary indicators.\n\n- There are *many* recipe steps that can convert categorical predictors to numeric columns.\n\n- `step_dummy()` records the levels of the categorical predictors in the training set. \n\n## Filter out constant columns ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"4\"}\nhotel_rec <- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_zv(all_predictors())\n```\n:::\n\n\n\n. . .\n\nIn case there is a factor level that was never observed in the training data (resulting in a column of all `0`s), we can delete any *zero-variance* predictors that have a single unique value.\n\n:::notes\nNote that the selector chooses all columns with a role of \"predictor\"\n:::\n\n\n## Normalization ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"5\"}\nhotel_rec <- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_normalize(all_numeric_predictors())\n```\n:::\n\n\n\n. . .\n\n- This [centers and scales](https://aml4td.org/chapters/numeric-predictors.html#sec-common-scale) the numeric predictors.\n\n\n- The recipe will use the _training_ set to estimate the means and standard deviations of the data.\n\n. . .\n\n- All data the recipe is applied to will be normalized using those statistics (there is no re-estimation).\n\n## Reduce correlation ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"6\"}\nhotel_rec <- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_corr(all_numeric_predictors(), threshold = 0.9)\n```\n:::\n\n\n\n. . .\n\nTo deal with highly correlated predictors, find the minimum set of predictor columns that make the pairwise correlations less than the threshold.\n\n## Other possible steps ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"6\"}\nhotel_rec <- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_pca(all_numeric_predictors())\n```\n:::\n\n\n\n. . . \n\n[PCA](https://aml4td.org/chapters/embeddings.html#principal-component-analysis) feature extraction...\n\n## Other possible steps ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/embed.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"6\"}\nhotel_rec <- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  embed::step_umap(all_numeric_predictors(), outcome = vars(avg_price_per_room))\n```\n:::\n\n\n\n. . . \n\nA fancy machine learning supervised dimension reduction technique called [UMAP](https://aml4td.org/chapters/embeddings.html#sec-umap)...\n\n:::notes\nNote that this uses the outcome, and it is from an extension package\n:::\n\n\n## Other possible steps ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"6\"}\nhotel_rec <- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_spline_natural(arrival_date_num, deg_free = 10)\n```\n:::\n\n\n\n. . . \n\nNonlinear transforms like [natural splines](https://aml4td.org/chapters/interactions-nonlinear.html#sec-splines), and so on!\n\n##  {background-iframe=\"https://recipes.tidymodels.org/reference/index.html\"}\n\n::: footer\n:::\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Create a `recipe()` for the hotel data to:*\n\n-   *use a Yeo-Johnson (YJ) transformation on `lead_time`*\n-   *convert factors to indicator variables*\n-   *remove zero-variance variables*\n-   *add the spline technique shown above*\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"make-recipe\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n\n## Minimal recipe ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhotel_indicators <-\n  recipe(avg_price_per_room ~ ., data = hotel_train) %>% \n  step_YeoJohnson(lead_time) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_zv(all_predictors()) %>% \n  step_spline_natural(arrival_date_num, deg_free = 10)\n```\n:::\n\n\n\n\n## Measuring Performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWe'll compute two measures: mean absolute error and the coefficient of determination (a.k.a $R^2$). \n\n\\begin{align}\nMAE &= \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}_i| \\notag \\\\\nR^2 &= cor(y_i, \\hat{y}_i)^2\n\\end{align}\n\nThe focus will be on MAE for parameter optimization. We'll use a metric set to compute these: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreg_metrics <- metric_set(mae, rsq)\n```\n:::\n\n\n\n\n## Using a workflow ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/tune.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/recipes.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"} ![](hexes/parsnip.png){.absolute top=-20 right=192 width=\"64\" height=\"74.24\"} \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(9)\n\nhotel_lm_wflow <-\n  workflow() %>%\n  add_recipe(hotel_indicators) %>%\n  add_model(linear_reg())\n \nctrl <- control_resamples(save_pred = TRUE)\nhotel_lm_res <-\n  hotel_lm_wflow %>%\n  fit_resamples(hotel_rs, control = ctrl, metrics = reg_metrics)\n\ncollect_metrics(hotel_lm_res)\n#> # A tibble: 2 Ã— 6\n#>   .metric .estimator   mean     n std_err .config             \n#>   <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 mae     standard   16.6      10 0.214   Preprocessor1_Model1\n#> 2 rsq     standard    0.884    10 0.00339 Preprocessor1_Model1\n```\n:::\n\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Use `fit_resamples()` to fit your workflow with a recipe.*\n\n*Collect the predictions from the results.*\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"resample-recipe\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n\n## Holdout predictions ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/tune.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/recipes.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"} ![](hexes/parsnip.png){.absolute top=-20 right=192 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Since we used `save_pred = TRUE`\nlm_cv_pred <- collect_predictions(hotel_lm_res)\nlm_cv_pred %>% print(n = 7)\n#> # A tibble: 3,749 Ã— 5\n#>   .pred id      .row avg_price_per_room .config             \n#>   <dbl> <chr>  <int>              <dbl> <chr>               \n#> 1  75.1 Fold01    20                 40 Preprocessor1_Model1\n#> 2  49.3 Fold01    28                 54 Preprocessor1_Model1\n#> 3  64.9 Fold01    45                 50 Preprocessor1_Model1\n#> 4  52.8 Fold01    49                 42 Preprocessor1_Model1\n#> 5  48.6 Fold01    61                 49 Preprocessor1_Model1\n#> 6  29.8 Fold01    66                 40 Preprocessor1_Model1\n#> 7  36.9 Fold01    88                 49 Preprocessor1_Model1\n#> # â„¹ 3,742 more rows\n```\n:::\n\n\n\n\n## Calibration Plot ![](hexes/probably.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(probably)\n\ncal_plot_regression(hotel_lm_res)\n```\n\n::: {.cell-output-display}\n![](figures/lm-cal-plot-1.svg){fig-align='center' width=40%}\n:::\n:::\n\n\n\n\n\n## What do we do with the agent and company data? \n\nThere are 98 unique agent values and 100 unique companies in our training set. How can we include this information in our model?\n\n. . .\n\nWe could:\n\n-   make the full set of indicator variables ðŸ˜³\n\n-   lump agents and companies that rarely occur into an \"other\" group\n\n-   use [feature hashing](https://www.tmwr.org/categorical.html#feature-hashing) to create a smaller set of indicator variables\n\n-   use [effect encoding](https://aml4td.org/chapters/categorical-predictors.html#sec-effect-encodings) to replace the `agent` and `company` columns with the estimated effect of that predictor (in the extra materials)\n\n\n\n\n\n\n\n\n\n## Per-agent statistics \n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figures/effects-freq-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figures/effects-adr-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n:::\n:::\n\n## Collapsing factor levels ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nThere is a recipe step that will redefine factor levels based on their frequency in the training set: \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"4|\"}\nhotel_other_rec <-\n  recipe(avg_price_per_room ~ ., data = hotel_train) %>% \n  step_YeoJohnson(lead_time) %>%\n  step_other(agent, threshold = 0.001) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_zv(all_predictors()) %>% \n  step_spline_natural(arrival_date_num, deg_free = 10)\n```\n:::\n\n\n\n\n\nUsing this code, 34 agents (out of 98) were collapsed into \"other\" based on the training set.\n\nWe _could_ try to optimize the threshold for collapsing (see the next set of slides on model tuning).\n\n## Does othering help?  ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/recipes.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"3|\"}\nhotel_other_wflow <-\n  hotel_lm_wflow %>%\n  update_recipe(hotel_other_rec)\n\nhotel_other_res <-\n  hotel_other_wflow %>%\n  fit_resamples(hotel_rs, control = ctrl, metrics = reg_metrics)\n\ncollect_metrics(hotel_other_res)\n#> # A tibble: 2 Ã— 6\n#>   .metric .estimator   mean     n std_err .config             \n#>   <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 mae     standard   16.7      10 0.213   Preprocessor1_Model1\n#> 2 rsq     standard    0.884    10 0.00341 Preprocessor1_Model1\n```\n:::\n\n\n\nAbout the same MAE and much faster to complete.  \n\nNow let's look at a more sophisticated tool called effect feature hashing. \n\n## Feature Hashing\n\nBetween `agent` and `company`, simple dummy variables would create 198 new columns (that are mostly zeros).\n\nAnother option is to have a binary indicator that combines some levels of these variables.\n\nFeature hashing (for more see [_FES_](https://bookdown.org/max/FES/encoding-predictors-with-many-categories.html), [_SMLTAR_](https://smltar.com/mlregression.html#case-study-feature-hashing),  [_TMwR_](https://www.tmwr.org/categorical.html#feature-hashing), and [_aml4td_](https://aml4td.org/chapters/categorical-predictors.html#sec-feature-hashing)):  \n\n- uses the character values of the levels \n- converts them to integer hash values\n- uses the integers to assign them to a specific indicator column. \n\n## Feature Hashing\n\nSuppose we want to use 32 indicator variables for `agent`. \n\nFor a agent with value \"`Max_Kuhn`\", a hashing function converts it to an integer (say 210397726). \n\nTo assign it to one of the 32 columns, we would use modular arithmetic to assign it to a column: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# For \"Max_Kuhn\" put a '1' in column: \n210397726 %% 32\n#> [1] 30\n```\n:::\n\n\n\n[Hash functions](https://www.metamorphosite.com/one-way-hash-encryption-sha1-data-software) are meant to _emulate_ randomness. \n\n\n## Feature Hashing Pros\n\n\n- The procedure will automatically work on new values of the predictors.\n- It is fast. \n- \"Signed\" hashes add a sign to help avoid aliasing. \n\n## Feature Hashing Cons\n\n- There is no real logic behind which factor levels are combined. \n- We don't know how many columns to add (more in the next section).\n- Some columns may have all zeros. \n- If a indicator column is important to the model, we can't easily determine why. \n\n:::notes\nThe signed hash make it slightly more possible to differentiate between confounded levels\n:::\n\n\n## Feature Hashing in recipes ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/textrecipes.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/recipes.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"}\n\nThe textrecipes package has a step that can be added to the recipe: \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"6-8|\"}\nlibrary(textrecipes)\n\nhash_rec <-\n  recipe(avg_price_per_room ~ ., data = hotel_train) %>%\n  step_YeoJohnson(lead_time) %>%\n  # Defaults to 32 signed indicator columns\n  step_dummy_hash(agent) %>%\n  step_dummy_hash(company) %>%\n  # Regular indicators for the others\n  step_dummy(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_spline_natural(arrival_date_num, deg_free = 10)\n\nhotel_hash_wflow <-\n  hotel_lm_wflow %>%\n  update_recipe(hash_rec)\n```\n:::\n\n\n\n\n## Feature Hashing in recipes ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/textrecipes.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/recipes.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhotel_hash_res <-\n  hotel_hash_wflow %>%\n  fit_resamples(hotel_rs, control = ctrl, metrics = reg_metrics)\n\ncollect_metrics(hotel_hash_res)\n#> # A tibble: 2 Ã— 6\n#>   .metric .estimator   mean     n std_err .config             \n#>   <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 mae     standard   16.7      10 0.239   Preprocessor1_Model1\n#> 2 rsq     standard    0.884    10 0.00324 Preprocessor1_Model1\n```\n:::\n\n\n\nAbout the same performance but now we can handle new values. \n\n\n## Debugging a recipe\n\n- Typically, you will want to use a workflow to estimate and apply a recipe.\n\n. . .\n\n- If you have an error and need to debug your recipe, the original recipe object (e.g. `hash_rec`) can be estimated manually with a function called `prep()`. It is analogous to `fit()`. See [TMwR section 16.4](https://www.tmwr.org/dimensionality.html#recipe-functions)\n\n. . .\n\n- Another function (`bake()`) is analogous to `predict()`, and gives you the processed data back.\n\n. . .\n\n- The `tidy()` function can be used to get specific results from the recipe.\n\n## Example ![](hexes/recipes.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/broom.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhash_rec_fit <- prep(hash_rec)\n\n# Get the transformation coefficient\ntidy(hash_rec_fit, number = 1)\n\n# Get the processed data\nbake(hash_rec_fit, hotel_train %>% slice(1:3), contains(\"_agent_\"))\n```\n:::\n\n\n\n## More on recipes\n\n-   Once `fit()` is called on a workflow, changing the model does not re-fit the recipe.\n\n. . .\n\n-   A list of all known steps is at <https://www.tidymodels.org/find/recipes/>.\n\n. . .\n\n-   Some steps can be [skipped](https://recipes.tidymodels.org/articles/Skipping.html) when using `predict()`.\n\n. . .\n\n-   The [order](https://recipes.tidymodels.org/articles/Ordering.html) of the steps matters.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}