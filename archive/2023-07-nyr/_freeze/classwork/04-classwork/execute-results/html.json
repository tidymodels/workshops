{
  "hash": "78f18430960f94e2b17b90d193e77cf2",
  "result": {
    "markdown": "---\ntitle: \"4 - Evaluating models - Classwork\"\nsubtitle: \"Machine learning with tidymodels\"\neditor_options: \n  chunk_output_type: console\n---\n\n\nWe recommend restarting R between each slide deck!\n\n## Setup\n\nSetup from deck 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ broom        1.0.5          ✔ recipes      1.0.6     \n✔ dials        1.2.0          ✔ rsample      1.1.1.9000\n✔ dplyr        1.1.2          ✔ tibble       3.2.1     \n✔ ggplot2      3.4.2          ✔ tidyr        1.3.0     \n✔ infer        1.0.4          ✔ tune         1.1.1.9001\n✔ modeldata    1.1.0          ✔ workflows    1.1.3     \n✔ parsnip      1.1.0.9003     ✔ workflowsets 1.0.1     \n✔ purrr        1.0.1          ✔ yardstick    1.2.0.9001\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n```\n:::\n\n```{.r .cell-code}\nlibrary(modeldatatoo)\n\ntaxi <- data_taxi()\n\ntaxi <- taxi %>%\n  mutate(month = factor(month, levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"))) %>% \n  select(-c(id, duration, fare, tolls, extras, total_cost, payment_type)) %>% \n  drop_na()\n\nset.seed(123)\ntaxi_split <- initial_split(taxi, prop = 0.8, strata = tip)\ntaxi_train <- training(taxi_split)\ntaxi_test <- testing(taxi_split)\n\ntree_spec <- decision_tree(cost_complexity = 0.0001, mode = \"classification\")\ntaxi_wflow <- workflow(tip ~ ., tree_spec)\ntaxi_fit <- fit(taxi_wflow, taxi_train)\n```\n:::\n\n\n## Metrics for model performance\n\n`conf_mat()` can be used to see how well the model is doing at prediction\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  conf_mat(truth = tip, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Truth\nPrediction  yes   no\n       yes 4639  660\n       no   337 1409\n```\n:::\n:::\n\n\nand it has nice plotting features\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  conf_mat(truth = tip, estimate = .pred_class) %>%\n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](04-classwork_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nusing the same interface we can calculate metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  accuracy(truth = tip, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.858\n```\n:::\n:::\n\n\nAll yardstick metric functions work with grouped data frames!\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  group_by(local) %>%\n  accuracy(truth = tip, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  local .metric  .estimator .estimate\n  <fct> <chr>    <chr>          <dbl>\n1 yes   accuracy binary         0.840\n2 no    accuracy binary         0.862\n```\n:::\n:::\n\n\nMetric sets are a way to combine multiple similar metric functions together into a new function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_metrics <- metric_set(accuracy, specificity, sensitivity)\n\naugment(taxi_fit, new_data = taxi_train) %>%\n  taxi_metrics(truth = tip, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary         0.858\n2 specificity binary         0.681\n3 sensitivity binary         0.932\n```\n:::\n:::\n\n\n## Your turn\n\nCompute and plot an ROC curve for your current model.\n\nWhat data is being used for this ROC curve plot?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Your code here!\n```\n:::\n\n\n## Dangers of overfitting\n\nRepredicting the training set, bad!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7,045 × 10\n   tip   distance company local dow   month  hour .pred_class .pred_yes .pred_no\n   <fct>    <dbl> <fct>   <fct> <fct> <fct> <int> <fct>           <dbl>    <dbl>\n 1 no        5.39 Flash … no    Sat   Mar      12 no             0.0625   0.937 \n 2 no       18.4  Sun Ta… no    Sat   Apr       6 yes            0.924    0.0758\n 3 no        5.8  other   no    Tue   Jan      10 no             0.391    0.609 \n 4 no        6.85 Flash … no    Fri   Apr       8 no             0.112    0.888 \n 5 no        9.5  City S… no    Wed   Jan       7 no             0.129    0.871 \n 6 no       12    other   no    Fri   Apr      11 no             0.326    0.674 \n 7 no        8.9  Taxi A… no    Mon   Feb      14 no             0.0917   0.908 \n 8 no        1.38 other   no    Fri   Apr      16 yes            0.902    0.0980\n 9 no        9.12 Flash … no    Wed   Apr       9 no             0.0917   0.908 \n10 no        2.28 City S… no    Thu   Apr      16 yes            0.933    0.0668\n# ℹ 7,035 more rows\n```\n:::\n:::\n\n\n\"Resubstitution estimate\" - This should be the best possible performance that you could ever achieve, but it can be very misleading!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_train) %>%\n  accuracy(tip, .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.858\n```\n:::\n:::\n\n\nNow on the test set, see that it performs worse? This is closer to \"real\" performance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_test) %>%\n  accuracy(tip, .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.795\n```\n:::\n:::\n\n\n## Your turn\n\nUse `augment()` and and a metric function to compute a classification metric like `brier_class()`.\n\nCompute the metrics for both training and testing data to demonstrate overfitting!\n\nNotice the evidence of overfitting!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Your code here!\n\n# Use `augment()` and `brier_class()` with `taxi_fit`\ntaxi_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\ntip ~ .\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 7045 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n    1) root 7045 2069 yes (0.70631654 0.29368346)  \n      2) company=Chicago Independents,City Service,Sun Taxi,Taxicab Insurance Agency Llc,other 4328  744 yes (0.82809612 0.17190388)  \n        4) distance< 4.615 2365  254 yes (0.89260042 0.10739958)  \n          8) distance< 3.375 2101  211 yes (0.89957163 0.10042837)  \n           16) local=no 1469  130 yes (0.91150442 0.08849558)  \n             32) company=Chicago Independents,City Service,Taxicab Insurance Agency Llc 674   45 yes (0.93323442 0.06676558) *\n             33) company=Sun Taxi,other 795   85 yes (0.89308176 0.10691824)  \n               66) hour< 22.5 769   79 yes (0.89726918 0.10273082)  \n                132) hour>=20.5 42    1 yes (0.97619048 0.02380952) *\n                133) hour< 20.5 727   78 yes (0.89270977 0.10729023)  \n                  266) distance< 2.285 561   55 yes (0.90196078 0.09803922) *\n                  267) distance>=2.285 166   23 yes (0.86144578 0.13855422)  \n                    534) hour>=13.5 100    6 yes (0.94000000 0.06000000) *\n                    535) hour< 13.5 66   17 yes (0.74242424 0.25757576)  \n                     1070) distance>=2.685 41    7 yes (0.82926829 0.17073171) *\n                     1071) distance< 2.685 25   10 yes (0.60000000 0.40000000)  \n                       2142) hour< 10.5 13    3 yes (0.76923077 0.23076923) *\n                       2143) hour>=10.5 12    5 no (0.41666667 0.58333333) *\n               67) hour>=22.5 26    6 yes (0.76923077 0.23076923) *\n           17) local=yes 632   81 yes (0.87183544 0.12816456) *\n          9) distance>=3.375 264   43 yes (0.83712121 0.16287879)  \n           18) dow=Sun,Mon,Wed,Thu,Fri,Sat 230   30 yes (0.86956522 0.13043478) *\n           19) dow=Tue 34   13 yes (0.61764706 0.38235294)  \n             38) month=Jan,Mar,Apr 26    6 yes (0.76923077 0.23076923) *\n             39) month=Feb 8    1 no (0.12500000 0.87500000) *\n        5) distance>=4.615 1963  490 yes (0.75038207 0.24961793)  \n         10) distance>=12.565 1069   81 yes (0.92422825 0.07577175) *\n         11) distance< 12.565 894  409 yes (0.54250559 0.45749441)  \n           22) company=Chicago Independents,Sun Taxi,Taxicab Insurance Agency Llc 278   71 yes (0.74460432 0.25539568)  \n             44) distance< 8.105 136   22 yes (0.83823529 0.16176471)  \n               88) company=Chicago Independents 25    0 yes (1.00000000 0.00000000) *\n               89) company=Sun Taxi,Taxicab Insurance Agency Llc 111   22 yes (0.80180180 0.19819820)  \n                178) dow=Sun,Mon,Thu,Fri,Sat 74   10 yes (0.86486486 0.13513514) *\n                179) dow=Tue,Wed 37   12 yes (0.67567568 0.32432432)  \n                  358) hour>=16.5 16    2 yes (0.87500000 0.12500000) *\n                  359) hour< 16.5 21   10 yes (0.52380952 0.47619048)  \n                    718) hour< 9.5 9    2 yes (0.77777778 0.22222222) *\n                    719) hour>=9.5 12    4 no (0.33333333 0.66666667) *\n             45) distance>=8.105 142   49 yes (0.65492958 0.34507042)  \n               90) company=Chicago Independents,Taxicab Insurance Agency Llc 72   15 yes (0.79166667 0.20833333)  \n                180) distance>=10.855 29    0 yes (1.00000000 0.00000000) *\n                181) distance< 10.855 43   15 yes (0.65116279 0.34883721)  \n                  362) dow=Mon,Tue,Wed,Thu 27    4 yes (0.85185185 0.14814815) *\n                  363) dow=Sun,Fri,Sat 16    5 no (0.31250000 0.68750000) *\n               91) company=Sun Taxi 70   34 yes (0.51428571 0.48571429)  \n\n...\nand 232 more lines.\n```\n:::\n:::\n\n\n## Your turn\n\nIf we use 10 folds, what percent of the training data:\n\n- ends up in analysis?\n- ends up in assessment?\n\nfor each fold\n\n## Resampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# v = 10 is the default\nvfold_cv(taxi_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits             id    \n   <list>             <chr> \n 1 <split [6340/705]> Fold01\n 2 <split [6340/705]> Fold02\n 3 <split [6340/705]> Fold03\n 4 <split [6340/705]> Fold04\n 5 <split [6340/705]> Fold05\n 6 <split [6341/704]> Fold06\n 7 <split [6341/704]> Fold07\n 8 <split [6341/704]> Fold08\n 9 <split [6341/704]> Fold09\n10 <split [6341/704]> Fold10\n```\n:::\n:::\n\n\nWhat is in a resampling result?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_folds <- vfold_cv(taxi_train, v = 10)\n\n# Individual splits of analysis/assessment data\ntaxi_folds$splits[1:3]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n<Analysis/Assess/Total>\n<6340/705/7045>\n\n[[2]]\n<Analysis/Assess/Total>\n<6340/705/7045>\n\n[[3]]\n<Analysis/Assess/Total>\n<6340/705/7045>\n```\n:::\n:::\n\n\nStratification often helps, with very little downside\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvfold_cv(taxi_train, strata = tip)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#  10-fold cross-validation using stratification \n# A tibble: 10 × 2\n   splits             id    \n   <list>             <chr> \n 1 <split [6340/705]> Fold01\n 2 <split [6340/705]> Fold02\n 3 <split [6340/705]> Fold03\n 4 <split [6340/705]> Fold04\n 5 <split [6340/705]> Fold05\n 6 <split [6340/705]> Fold06\n 7 <split [6341/704]> Fold07\n 8 <split [6341/704]> Fold08\n 9 <split [6341/704]> Fold09\n10 <split [6342/703]> Fold10\n```\n:::\n:::\n\n\nWe'll use this setup:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ntaxi_folds <- vfold_cv(taxi_train, v = 10, strata = tip)\ntaxi_folds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#  10-fold cross-validation using stratification \n# A tibble: 10 × 2\n   splits             id    \n   <list>             <chr> \n 1 <split [6340/705]> Fold01\n 2 <split [6340/705]> Fold02\n 3 <split [6340/705]> Fold03\n 4 <split [6340/705]> Fold04\n 5 <split [6340/705]> Fold05\n 6 <split [6340/705]> Fold06\n 7 <split [6341/704]> Fold07\n 8 <split [6341/704]> Fold08\n 9 <split [6341/704]> Fold09\n10 <split [6342/703]> Fold10\n```\n:::\n:::\n\n\n## Evaluating model performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit the workflow on each analysis set,\n# then compute performance on each assessment set\ntaxi_res <- fit_resamples(taxi_wflow, taxi_folds)\ntaxi_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# 10-fold cross-validation using stratification \n# A tibble: 10 × 4\n   splits             id     .metrics         .notes          \n   <list>             <chr>  <list>           <list>          \n 1 <split [6340/705]> Fold01 <tibble [2 × 4]> <tibble [0 × 3]>\n 2 <split [6340/705]> Fold02 <tibble [2 × 4]> <tibble [0 × 3]>\n 3 <split [6340/705]> Fold03 <tibble [2 × 4]> <tibble [0 × 3]>\n 4 <split [6340/705]> Fold04 <tibble [2 × 4]> <tibble [0 × 3]>\n 5 <split [6340/705]> Fold05 <tibble [2 × 4]> <tibble [0 × 3]>\n 6 <split [6340/705]> Fold06 <tibble [2 × 4]> <tibble [0 × 3]>\n 7 <split [6341/704]> Fold07 <tibble [2 × 4]> <tibble [0 × 3]>\n 8 <split [6341/704]> Fold08 <tibble [2 × 4]> <tibble [0 × 3]>\n 9 <split [6341/704]> Fold09 <tibble [2 × 4]> <tibble [0 × 3]>\n10 <split [6342/703]> Fold10 <tibble [2 × 4]> <tibble [0 × 3]>\n```\n:::\n:::\n\n\nAggregate metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_res %>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.793    10 0.00293 Preprocessor1_Model1\n2 roc_auc  binary     0.809    10 0.00461 Preprocessor1_Model1\n```\n:::\n:::\n\n\nIf you want to analyze the assessment set (i.e. holdout) predictions, then you need to adjust the control object and tell it to save them:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the assessment set results\nctrl_taxi <- control_resamples(save_pred = TRUE)\n\ntaxi_res <- fit_resamples(taxi_wflow, taxi_folds, control = ctrl_taxi)\n\ntaxi_preds <- collect_predictions(taxi_res)\ntaxi_preds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7,045 × 7\n   id     .pred_yes .pred_no  .row .pred_class tip   .config             \n   <chr>      <dbl>    <dbl> <int> <fct>       <fct> <chr>               \n 1 Fold01    0.936    0.0638    10 yes         no    Preprocessor1_Model1\n 2 Fold01    0.898    0.102     20 yes         no    Preprocessor1_Model1\n 3 Fold01    0.898    0.102     47 yes         no    Preprocessor1_Model1\n 4 Fold01    0.101    0.899     51 no          no    Preprocessor1_Model1\n 5 Fold01    0.871    0.129     59 yes         no    Preprocessor1_Model1\n 6 Fold01    0.0815   0.918     60 no          no    Preprocessor1_Model1\n 7 Fold01    0.162    0.838     92 no          no    Preprocessor1_Model1\n 8 Fold01    0.26     0.74      97 no          no    Preprocessor1_Model1\n 9 Fold01    0.274    0.726     98 no          no    Preprocessor1_Model1\n10 Fold01    0.804    0.196    104 yes         no    Preprocessor1_Model1\n# ℹ 7,035 more rows\n```\n:::\n:::\n\n\n## Bootstrapping\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3214)\nbootstraps(taxi_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Bootstrap sampling \n# A tibble: 25 × 2\n   splits              id         \n   <list>              <chr>      \n 1 <split [7045/2561]> Bootstrap01\n 2 <split [7045/2577]> Bootstrap02\n 3 <split [7045/2648]> Bootstrap03\n 4 <split [7045/2616]> Bootstrap04\n 5 <split [7045/2616]> Bootstrap05\n 6 <split [7045/2599]> Bootstrap06\n 7 <split [7045/2654]> Bootstrap07\n 8 <split [7045/2593]> Bootstrap08\n 9 <split [7045/2624]> Bootstrap09\n10 <split [7045/2615]> Bootstrap10\n# ℹ 15 more rows\n```\n:::\n:::\n\n\n## Your turn\n\nCreate:\n\n- Monte Carlo Cross-Validation sets\n- validation set\n\n(use the reference guide to find the function)\n\nhttps://rsample.tidymodels.org/reference/index.html\n\nDon't forget to set a seed when you resample!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Your code here!\n```\n:::\n\n\n## Create a random forest model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_spec <- rand_forest(trees = 1000, mode = \"classification\")\nrf_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  trees = 1000\n\nComputational engine: ranger \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_wflow <- workflow(tip ~ ., rf_spec)\nrf_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\ntip ~ .\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  trees = 1000\n\nComputational engine: ranger \n```\n:::\n:::\n\n\n## Your turn\n\nUse `fit_resamples()` and `rf_wflow` to:\n\n- Keep predictions\n- Compute metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Your code here!\n```\n:::\n\n\n## Evaluate a workflow set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_set <- workflow_set(list(tip ~ .), list(tree_spec, rf_spec))\nwf_set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 2 × 4\n  wflow_id              info             option    result    \n  <chr>                 <list>           <list>    <list>    \n1 formula_decision_tree <tibble [1 × 4]> <opts[0]> <list [0]>\n2 formula_rand_forest   <tibble [1 × 4]> <opts[0]> <list [0]>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_set_fit <- wf_set %>%\n  workflow_map(\"fit_resamples\", resamples = taxi_folds)\n\nwf_set_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 2 × 4\n  wflow_id              info             option    result   \n  <chr>                 <list>           <list>    <list>   \n1 formula_decision_tree <tibble [1 × 4]> <opts[1]> <rsmp[+]>\n2 formula_rand_forest   <tibble [1 × 4]> <opts[1]> <rsmp[+]>\n```\n:::\n:::\n\n\nRank the sets of models by their aggregate metric performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_set_fit %>%\n  rank_results()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  <chr>             <chr>   <chr>   <dbl>   <dbl> <int> <chr>        <chr> <int>\n1 formula_rand_for… Prepro… accura… 0.812 0.00296    10 formula      rand…     1\n2 formula_rand_for… Prepro… roc_auc 0.832 0.00516    10 formula      rand…     1\n3 formula_decision… Prepro… accura… 0.793 0.00293    10 formula      deci…     2\n4 formula_decision… Prepro… roc_auc 0.809 0.00461    10 formula      deci…     2\n```\n:::\n:::\n\n\n## Your turn\n\nWhen do you think a workflow set would be useful?\n\nDiscuss with your neighbors!\n\n## The final fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# `taxi_split` has train + test info\nfinal_fit <- last_fit(rf_wflow, taxi_split) \n\nfinal_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits              id               .metrics .notes   .predictions .workflow \n  <list>              <chr>            <list>   <list>   <list>       <list>    \n1 <split [7045/1762]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n:::\n\n\nTest set metrics:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(final_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.808 Preprocessor1_Model1\n2 roc_auc  binary         0.816 Preprocessor1_Model1\n```\n:::\n:::\n\n\nTest set predictions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_predictions(final_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,762 × 7\n   id               .pred_yes .pred_no  .row .pred_class tip   .config          \n   <chr>                <dbl>    <dbl> <int> <fct>       <fct> <chr>            \n 1 train/test split     0.734   0.266     10 yes         no    Preprocessor1_Mo…\n 2 train/test split     0.827   0.173     29 yes         yes   Preprocessor1_Mo…\n 3 train/test split     0.906   0.0939    35 yes         yes   Preprocessor1_Mo…\n 4 train/test split     0.907   0.0927    42 yes         yes   Preprocessor1_Mo…\n 5 train/test split     0.919   0.0808    47 yes         no    Preprocessor1_Mo…\n 6 train/test split     0.850   0.150     54 yes         yes   Preprocessor1_Mo…\n 7 train/test split     0.586   0.414     59 yes         yes   Preprocessor1_Mo…\n 8 train/test split     0.917   0.0829    62 yes         yes   Preprocessor1_Mo…\n 9 train/test split     0.807   0.193     63 yes         yes   Preprocessor1_Mo…\n10 train/test split     0.963   0.0368    69 yes         yes   Preprocessor1_Mo…\n# ℹ 1,752 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_predictions(final_fit) %>%\n  ggplot(aes(.pred_class, fill = tip)) + \n  geom_bar() \n```\n\n::: {.cell-output-display}\n![](04-classwork_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_workflow(final_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\ntip ~ .\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  1000 \nSample size:                      7045 \nNumber of independent variables:  6 \nMtry:                             2 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.1371421 \n```\n:::\n:::\n\n\n## Your turn\n\nWhich model do you think you would decide to use?\n\nWhat surprised you the most?\n\nWhat is one thing you are looking forward to for tomorrow?\n",
    "supporting": [
      "04-classwork_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}