{
  "hash": "385a477f21d39283e40c50ca0fb00615",
  "result": {
    "markdown": "---\ntitle: \"4 - Evaluating models\"\nsubtitle: \"Machine learning with tidymodels\"\nformat:\n  revealjs: \n    slide-number: true\n    footer: <https://workshops.tidymodels.org>\n    include-before-body: header.html\n    include-after-body: footer-annotations.html\n    theme: [default, tidymodels.scss]\n    width: 1280\n    height: 720\nknitr:\n  opts_chunk: \n    echo: true\n    collapse: true\n    comment: \"#>\"\n    fig.path: \"figures/\"\n---\n\n\n\n\n## Looking at predictions\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  relocate(tip, .pred_class, .pred_yes, .pred_no)\n#> # A tibble: 7,045 Ã— 10\n#>    tip   .pred_class .pred_yes .pred_no distance company local dow   month  hour\n#>    <fct> <fct>           <dbl>    <dbl>    <dbl> <fct>   <fct> <fct> <fct> <int>\n#>  1 no    no             0.0625   0.937      5.39 Flash â€¦ no    Sat   Mar      12\n#>  2 no    yes            0.924    0.0758    18.4  Sun Taâ€¦ no    Sat   Apr       6\n#>  3 no    no             0.391    0.609      5.8  other   no    Tue   Jan      10\n#>  4 no    no             0.112    0.888      6.85 Flash â€¦ no    Fri   Apr       8\n#>  5 no    no             0.129    0.871      9.5  City Sâ€¦ no    Wed   Jan       7\n#>  6 no    no             0.326    0.674     12    other   no    Fri   Apr      11\n#>  7 no    no             0.0917   0.908      8.9  Taxi Aâ€¦ no    Mon   Feb      14\n#>  8 no    yes            0.902    0.0980     1.38 other   no    Fri   Apr      16\n#>  9 no    no             0.0917   0.908      9.12 Flash â€¦ no    Wed   Apr       9\n#> 10 no    yes            0.933    0.0668     2.28 City Sâ€¦ no    Thu   Apr      16\n#> # â„¹ 7,035 more rows\n```\n:::\n\n\n## Confusion matrix ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n![](images/confusion-matrix.png)\n\n## Confusion matrix ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  conf_mat(truth = tip, estimate = .pred_class)\n#>           Truth\n#> Prediction  yes   no\n#>        yes 4639  660\n#>        no   337 1409\n```\n:::\n\n\n## Confusion matrix ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  conf_mat(truth = tip, estimate = .pred_class) %>%\n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](figures/unnamed-chunk-5-1.svg){width=960}\n:::\n:::\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  accuracy(truth = tip, estimate = .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.858\n```\n:::\n\n:::\n\n::: {.column width=\"40%\"}\n![](images/confusion-matrix-accuracy.png)\n:::\n:::\n\n## Dangers of accuracy ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWe need to be careful of using `accuracy()` since it can give \"good\" performance by only predicting one way with imbalanced data\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  mutate(.pred_class = factor(\"yes\", levels = c(\"yes\", \"no\"))) %>%\n  accuracy(truth = tip, estimate = .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.706\n```\n:::\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  sensitivity(truth = tip, estimate = .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 sensitivity binary         0.932\n```\n:::\n\n:::\n\n::: {.column width=\"40%\"}\n![](images/confusion-matrix-sensitivity.png)\n:::\n:::\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"3-6\"}\naugment(taxi_fit, new_data = taxi_train) %>%\n  sensitivity(truth = tip, estimate = .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 sensitivity binary         0.932\n```\n:::\n\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>%\n  specificity(truth = tip, estimate = .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 specificity binary         0.681\n```\n:::\n\n:::\n\n::: {.column width=\"40%\"}\n![](images/confusion-matrix-specificity.png)\n:::\n:::\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWe can use `metric_set()` to combine multiple calculations into one\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_metrics <- metric_set(accuracy, specificity, sensitivity)\n\naugment(taxi_fit, new_data = taxi_train) %>%\n  taxi_metrics(truth = tip, estimate = .pred_class)\n#> # A tibble: 3 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 accuracy    binary         0.858\n#> 2 specificity binary         0.681\n#> 3 sensitivity binary         0.932\n```\n:::\n\n\n## Metrics for model performance ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_metrics <- metric_set(accuracy, specificity, sensitivity)\n\naugment(taxi_fit, new_data = taxi_train) %>%\n  group_by(local) %>%\n  taxi_metrics(truth = tip, estimate = .pred_class)\n#> # A tibble: 6 Ã— 4\n#>   local .metric     .estimator .estimate\n#>   <fct> <chr>       <chr>          <dbl>\n#> 1 yes   accuracy    binary         0.840\n#> 2 no    accuracy    binary         0.862\n#> 3 yes   specificity binary         0.346\n#> 4 no    specificity binary         0.719\n#> 5 yes   sensitivity binary         0.969\n#> 6 no    sensitivity binary         0.925\n```\n:::\n\n\n## Two class data\n\nThese metrics assume that we know the threshold for converting \"soft\" probability predictions into \"hard\" class predictions.\n\n. . .\n\nIs a 50% threshold good? \n\nWhat happens if we say that we need to be 80% sure to declare an event?\n\n-   sensitivity â¬‡ï¸, specificity â¬†ï¸\n\n. . .\n\nWhat happens for a 20% threshold?\n\n-   sensitivity â¬†ï¸, specificity â¬‡ï¸\n\n## Varying the threshold\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](figures/thresholds-1.svg){width=960}\n:::\n:::\n\n\n## ROC curves\n\nTo make an ROC (receiver operator characteristic) curve, we:\n\n- calculate the sensitivity and specificity for all possible thresholds\n\n- plot false positive rate (x-axis) versus true positive rate (y-axis)\n\ngiven that sensitivity is the true positive rate, and specificity is the true negative rate. Hence `1 - specificity` is the false positive rate.\n\n. . .\n\nWe can use the area under the ROC curve as a classification metric: \n\n- ROC AUC = 1 ğŸ’¯ \n- ROC AUC = 1/2 ğŸ˜¢\n\n:::notes\nROC curves are insensitive to class imbalance.\n:::\n\n## ROC curves ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assumes _first_ factor level is event; there are options to change that\naugment(taxi_fit, new_data = taxi_train) %>% \n  roc_curve(truth = tip, .pred_yes) %>%\n  slice(1, 20, 50)\n#> # A tibble: 3 Ã— 3\n#>   .threshold specificity sensitivity\n#>        <dbl>       <dbl>       <dbl>\n#> 1    -Inf          0           1    \n#> 2       0.25       0.486       0.972\n#> 3       0.6        0.705       0.920\n\naugment(taxi_fit, new_data = taxi_train) %>% \n  roc_auc(truth = tip, .pred_yes)\n#> # A tibble: 1 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 roc_auc binary         0.868\n```\n:::\n\n\n## ROC curve plot ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\naugment(taxi_fit, new_data = taxi_train) %>% \n  roc_curve(truth = tip, .pred_yes) %>%\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](figures/roc-curve-1.svg){width=576}\n:::\n:::\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Compute and plot an ROC curve for your current model.*\n\n*What data are being used for this ROC curve plot?*\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"roc-curve\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n##  {background-iframe=\"https://yardstick.tidymodels.org/reference/index.html\"}\n\n::: footer\n:::\n\n# âš ï¸ DANGERS OF OVERFITTING âš ï¸\n\n## Dangers of overfitting âš ï¸\n\n![](https://raw.githubusercontent.com/topepo/2022-nyr-workshop/main/images/tuning-overfitting-train-1.svg)\n\n## Dangers of overfitting âš ï¸\n\n![](https://raw.githubusercontent.com/topepo/2022-nyr-workshop/main/images/tuning-overfitting-test-1.svg)\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_train)\n#> # A tibble: 7,045 Ã— 10\n#>    tip   distance company local dow   month  hour .pred_class .pred_yes .pred_no\n#>    <fct>    <dbl> <fct>   <fct> <fct> <fct> <int> <fct>           <dbl>    <dbl>\n#>  1 no        5.39 Flash â€¦ no    Sat   Mar      12 no             0.0625   0.937 \n#>  2 no       18.4  Sun Taâ€¦ no    Sat   Apr       6 yes            0.924    0.0758\n#>  3 no        5.8  other   no    Tue   Jan      10 no             0.391    0.609 \n#>  4 no        6.85 Flash â€¦ no    Fri   Apr       8 no             0.112    0.888 \n#>  5 no        9.5  City Sâ€¦ no    Wed   Jan       7 no             0.129    0.871 \n#>  6 no       12    other   no    Fri   Apr      11 no             0.326    0.674 \n#>  7 no        8.9  Taxi Aâ€¦ no    Mon   Feb      14 no             0.0917   0.908 \n#>  8 no        1.38 other   no    Fri   Apr      16 yes            0.902    0.0980\n#>  9 no        9.12 Flash â€¦ no    Wed   Apr       9 no             0.0917   0.908 \n#> 10 no        2.28 City Sâ€¦ no    Thu   Apr      16 yes            0.933    0.0668\n#> # â„¹ 7,035 more rows\n```\n:::\n\n\nWe call this \"resubstitution\" or \"repredicting the training set\"\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_train) %>%\n  accuracy(tip, .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.858\n```\n:::\n\n\nWe call this a \"resubstitution estimate\"\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_train) %>%\n  accuracy(tip, .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.858\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n:::\n:::\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_train) %>%\n  accuracy(tip, .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.858\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_test) %>%\n  accuracy(tip, .pred_class)\n#> # A tibble: 1 Ã— 3\n#>   .metric  .estimator .estimate\n#>   <chr>    <chr>          <dbl>\n#> 1 accuracy binary         0.795\n```\n:::\n\n:::\n:::\n\n. . .\n\nâš ï¸ Remember that we're demonstrating overfitting \n\n. . .\n\nâš ï¸ Don't use the test set until the *end* of your modeling analysis\n\n\n##  {background-image=\"https://media.giphy.com/media/55itGuoAJiZEEen9gg/giphy.gif\" background-size=\"70%\"}\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute bottom=\"0\" left=\"0\" width=\"150\" height=\"150\"}\n\n*Use `augment()` and and a metric function to compute a classification metric like `brier_class()`.*\n\n*Compute the metrics for both training and testing data to demonstrate overfitting!*\n\n*Notice the evidence of overfitting!* âš ï¸\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"augment-metrics\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Dangers of overfitting âš ï¸ ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_train) %>%\n  brier_class(tip, .pred_yes)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 brier_class binary         0.113\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_fit %>%\n  augment(taxi_test) %>%\n  brier_class(tip, .pred_yes)\n#> # A tibble: 1 Ã— 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 brier_class binary         0.152\n```\n:::\n\n:::\n:::\n\n. . .\n\nWhat if we want to compare more models?\n\n. . .\n\nAnd/or more model configurations?\n\n. . .\n\nAnd we want to understand if these are important differences?\n\n# The testing data are precious ğŸ’\n\n# How can we use the *training* data to compare and evaluate different models? ğŸ¤”\n\n##  {background-color=\"white\" background-image=\"https://www.tmwr.org/premade/resampling.svg\" background-size=\"80%\"}\n\n## Cross-validation\n\n![](https://www.tmwr.org/premade/three-CV.svg)\n\n## Cross-validation\n\n![](https://www.tmwr.org/premade/three-CV-iter.svg)\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*If we use 10 folds, what percent of the training data*\n\n-   *ends up in analysis*\n-   *ends up in assessment*\n\n*for* **each** *fold?*\n\n![](images/taxi_spinning.svg){width=\"300\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"percent-in-folds\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvfold_cv(taxi_train) # v = 10 is default\n#> #  10-fold cross-validation \n#> # A tibble: 10 Ã— 2\n#>    splits             id    \n#>    <list>             <chr> \n#>  1 <split [6340/705]> Fold01\n#>  2 <split [6340/705]> Fold02\n#>  3 <split [6340/705]> Fold03\n#>  4 <split [6340/705]> Fold04\n#>  5 <split [6340/705]> Fold05\n#>  6 <split [6341/704]> Fold06\n#>  7 <split [6341/704]> Fold07\n#>  8 <split [6341/704]> Fold08\n#>  9 <split [6341/704]> Fold09\n#> 10 <split [6341/704]> Fold10\n```\n:::\n\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWhat is in this?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_folds <- vfold_cv(taxi_train)\ntaxi_folds$splits[1:3]\n#> [[1]]\n#> <Analysis/Assess/Total>\n#> <6340/705/7045>\n#> \n#> [[2]]\n#> <Analysis/Assess/Total>\n#> <6340/705/7045>\n#> \n#> [[3]]\n#> <Analysis/Assess/Total>\n#> <6340/705/7045>\n```\n:::\n\n\n::: notes\nTalk about a list column, storing non-atomic types in dataframe\n:::\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvfold_cv(taxi_train, v = 5)\n#> #  5-fold cross-validation \n#> # A tibble: 5 Ã— 2\n#>   splits              id   \n#>   <list>              <chr>\n#> 1 <split [5636/1409]> Fold1\n#> 2 <split [5636/1409]> Fold2\n#> 3 <split [5636/1409]> Fold3\n#> 4 <split [5636/1409]> Fold4\n#> 5 <split [5636/1409]> Fold5\n```\n:::\n\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvfold_cv(taxi_train, strata = tip)\n#> #  10-fold cross-validation using stratification \n#> # A tibble: 10 Ã— 2\n#>    splits             id    \n#>    <list>             <chr> \n#>  1 <split [6340/705]> Fold01\n#>  2 <split [6340/705]> Fold02\n#>  3 <split [6340/705]> Fold03\n#>  4 <split [6340/705]> Fold04\n#>  5 <split [6340/705]> Fold05\n#>  6 <split [6340/705]> Fold06\n#>  7 <split [6341/704]> Fold07\n#>  8 <split [6341/704]> Fold08\n#>  9 <split [6341/704]> Fold09\n#> 10 <split [6342/703]> Fold10\n```\n:::\n\n\n. . .\n\nStratification often helps, with very little downside\n\n## Cross-validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWe'll use this setup:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ntaxi_folds <- vfold_cv(taxi_train, v = 10, strata = tip)\ntaxi_folds\n#> #  10-fold cross-validation using stratification \n#> # A tibble: 10 Ã— 2\n#>    splits             id    \n#>    <list>             <chr> \n#>  1 <split [6340/705]> Fold01\n#>  2 <split [6340/705]> Fold02\n#>  3 <split [6340/705]> Fold03\n#>  4 <split [6340/705]> Fold04\n#>  5 <split [6340/705]> Fold05\n#>  6 <split [6340/705]> Fold06\n#>  7 <split [6341/704]> Fold07\n#>  8 <split [6341/704]> Fold08\n#>  9 <split [6341/704]> Fold09\n#> 10 <split [6342/703]> Fold10\n```\n:::\n\n\n. . .\n\nSet the seed when creating resamples\n\n# We are equipped with metrics and resamples!\n\n## Fit our model to the resamples\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_res <- fit_resamples(taxi_wflow, taxi_folds)\ntaxi_res\n#> # Resampling results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 Ã— 4\n#>    splits             id     .metrics         .notes          \n#>    <list>             <chr>  <list>           <list>          \n#>  1 <split [6340/705]> Fold01 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  2 <split [6340/705]> Fold02 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  3 <split [6340/705]> Fold03 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  4 <split [6340/705]> Fold04 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  5 <split [6340/705]> Fold05 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  6 <split [6340/705]> Fold06 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  7 <split [6341/704]> Fold07 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  8 <split [6341/704]> Fold08 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#>  9 <split [6341/704]> Fold09 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n#> 10 <split [6342/703]> Fold10 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]>\n```\n:::\n\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_res %>%\n  collect_metrics()\n#> # A tibble: 2 Ã— 6\n#>   .metric  .estimator  mean     n std_err .config             \n#>   <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n#> 1 accuracy binary     0.793    10 0.00293 Preprocessor1_Model1\n#> 2 roc_auc  binary     0.809    10 0.00461 Preprocessor1_Model1\n```\n:::\n\n\n. . .\n\nWe can reliably measure performance using only the **training** data ğŸ‰\n\n## Comparing metrics ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nHow do the metrics from resampling compare to the metrics from training and testing?\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_res %>%\n  collect_metrics() %>% \n  select(.metric, mean, n)\n#> # A tibble: 2 Ã— 3\n#>   .metric   mean     n\n#>   <chr>    <dbl> <int>\n#> 1 accuracy 0.793    10\n#> 2 roc_auc  0.809    10\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nThe ROC AUC previously was\n\n- 0.87 for the training set\n- 0.81 for test set\n:::\n:::\n\n. . .\n\nRemember that:\n\nâš ï¸ the training set gives you overly optimistic metrics\n\nâš ï¸ the test set is precious\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the assessment set results\nctrl_taxi <- control_resamples(save_pred = TRUE)\ntaxi_res <- fit_resamples(taxi_wflow, taxi_folds, control = ctrl_taxi)\n\ntaxi_preds <- collect_predictions(taxi_res)\ntaxi_preds\n#> # A tibble: 7,045 Ã— 7\n#>    id     .pred_yes .pred_no  .row .pred_class tip   .config             \n#>    <chr>      <dbl>    <dbl> <int> <fct>       <fct> <chr>               \n#>  1 Fold01    0.936    0.0638    10 yes         no    Preprocessor1_Model1\n#>  2 Fold01    0.898    0.102     20 yes         no    Preprocessor1_Model1\n#>  3 Fold01    0.898    0.102     47 yes         no    Preprocessor1_Model1\n#>  4 Fold01    0.101    0.899     51 no          no    Preprocessor1_Model1\n#>  5 Fold01    0.871    0.129     59 yes         no    Preprocessor1_Model1\n#>  6 Fold01    0.0815   0.918     60 no          no    Preprocessor1_Model1\n#>  7 Fold01    0.162    0.838     92 no          no    Preprocessor1_Model1\n#>  8 Fold01    0.26     0.74      97 no          no    Preprocessor1_Model1\n#>  9 Fold01    0.274    0.726     98 no          no    Preprocessor1_Model1\n#> 10 Fold01    0.804    0.196    104 yes         no    Preprocessor1_Model1\n#> # â„¹ 7,035 more rows\n```\n:::\n\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_preds %>% \n  group_by(id) %>%\n  taxi_metrics(truth = tip, estimate = .pred_class)\n#> # A tibble: 30 Ã— 4\n#>    id     .metric  .estimator .estimate\n#>    <chr>  <chr>    <chr>          <dbl>\n#>  1 Fold01 accuracy binary         0.793\n#>  2 Fold02 accuracy binary         0.8  \n#>  3 Fold03 accuracy binary         0.786\n#>  4 Fold04 accuracy binary         0.804\n#>  5 Fold05 accuracy binary         0.796\n#>  6 Fold06 accuracy binary         0.789\n#>  7 Fold07 accuracy binary         0.793\n#>  8 Fold08 accuracy binary         0.808\n#>  9 Fold09 accuracy binary         0.783\n#> 10 Fold10 accuracy binary         0.780\n#> # â„¹ 20 more rows\n```\n:::\n\n\n## Where are the fitted models? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}  {.annotation}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntaxi_res\n#> # Resampling results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 Ã— 5\n#>    splits             id     .metrics         .notes           .predictions\n#>    <list>             <chr>  <list>           <list>           <list>      \n#>  1 <split [6340/705]> Fold01 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  2 <split [6340/705]> Fold02 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  3 <split [6340/705]> Fold03 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  4 <split [6340/705]> Fold04 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  5 <split [6340/705]> Fold05 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  6 <split [6340/705]> Fold06 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  7 <split [6341/704]> Fold07 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  8 <split [6341/704]> Fold08 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#>  9 <split [6341/704]> Fold09 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>    \n#> 10 <split [6342/703]> Fold10 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble>\n```\n:::\n\n\n. . .\n\nğŸ—‘ï¸\n\n# Alternate resampling schemes\n\n## Bootstrapping\n\n![](https://www.tmwr.org/premade/bootstraps.svg)\n\n## Bootstrapping ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3214)\nbootstraps(taxi_train)\n#> # Bootstrap sampling \n#> # A tibble: 25 Ã— 2\n#>    splits              id         \n#>    <list>              <chr>      \n#>  1 <split [7045/2561]> Bootstrap01\n#>  2 <split [7045/2577]> Bootstrap02\n#>  3 <split [7045/2648]> Bootstrap03\n#>  4 <split [7045/2616]> Bootstrap04\n#>  5 <split [7045/2616]> Bootstrap05\n#>  6 <split [7045/2599]> Bootstrap06\n#>  7 <split [7045/2654]> Bootstrap07\n#>  8 <split [7045/2593]> Bootstrap08\n#>  9 <split [7045/2624]> Bootstrap09\n#> 10 <split [7045/2615]> Bootstrap10\n#> # â„¹ 15 more rows\n```\n:::\n\n\n##  {background-iframe=\"https://rsample.tidymodels.org/reference/index.html\"}\n\n::: footer\n:::\n\n## The whole game - status update\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/whole-game-resamples.jpg){fig-align='center' width=1772}\n:::\n:::\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Create:*\n\n-   *Monte Carlo Cross-Validation sets*\n-   *validation set*\n\n(use the reference guide to find the function)\n\n*Don't forget to set a seed when you resample!*\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"try-rsample\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Monte Carlo Cross-Validation ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(322)\nmc_cv(taxi_train, times = 10)\n#> # Monte Carlo cross-validation (0.75/0.25) with 10 resamples  \n#> # A tibble: 10 Ã— 2\n#>    splits              id        \n#>    <list>              <chr>     \n#>  1 <split [5283/1762]> Resample01\n#>  2 <split [5283/1762]> Resample02\n#>  3 <split [5283/1762]> Resample03\n#>  4 <split [5283/1762]> Resample04\n#>  5 <split [5283/1762]> Resample05\n#>  6 <split [5283/1762]> Resample06\n#>  7 <split [5283/1762]> Resample07\n#>  8 <split [5283/1762]> Resample08\n#>  9 <split [5283/1762]> Resample09\n#> 10 <split [5283/1762]> Resample10\n```\n:::\n\n\n## Validation set ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} {.annotation}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(853)\nvalidation_split(taxi_train, strata = tip)\n#> # Validation Set Split (0.75/0.25)  using stratification \n#> # A tibble: 1 Ã— 2\n#>   splits              id        \n#>   <list>              <chr>     \n#> 1 <split [5283/1762]> validation\n```\n:::\n\n\n. . .\n\nA validation set is just another type of resample\n\n# Decision tree ğŸŒ³\n\n# Random forest ğŸŒ³ğŸŒ²ğŸŒ´ğŸŒµğŸŒ´ğŸŒ³ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒµğŸŒ´ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒ³ğŸŒµğŸŒµğŸŒ´ğŸŒ²ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒ´ğŸŒµğŸŒ´ğŸŒ²ğŸŒ´ğŸŒµğŸŒ²ğŸŒµğŸŒ´ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒµğŸŒ³ğŸŒ´ğŸŒ³\n\n## Random forest ğŸŒ³ğŸŒ²ğŸŒ´ğŸŒµğŸŒ³ğŸŒ³ğŸŒ´ğŸŒ²ğŸŒµğŸŒ´ğŸŒ³ğŸŒµ\n\n- Ensemble many decision tree models\n\n- All the trees vote! ğŸ—³ï¸\n\n- Bootstrap aggregating + random predictor sampling\n\n. . .\n\n- Often works well without tuning hyperparameters (more on this tomorrow!), as long as there are enough trees\n\n## Create a random forest model ![](hexes/parsnip.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_spec <- rand_forest(trees = 1000, mode = \"classification\")\nrf_spec\n#> Random Forest Model Specification (classification)\n#> \n#> Main Arguments:\n#>   trees = 1000\n#> \n#> Computational engine: ranger\n```\n:::\n\n\n## Create a random forest model ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_wflow <- workflow(tip ~ ., rf_spec)\nrf_wflow\n#> â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#> Preprocessor: Formula\n#> Model: rand_forest()\n#> \n#> â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> tip ~ .\n#> \n#> â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> Random Forest Model Specification (classification)\n#> \n#> Main Arguments:\n#>   trees = 1000\n#> \n#> Computational engine: ranger\n```\n:::\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*Use `fit_resamples()` and `rf_wflow` to:*\n\n-   *keep predictions*\n-   *compute metrics*\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"try-fit-resamples\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">08</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Evaluating model performance ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nctrl_taxi <- control_resamples(save_pred = TRUE)\n\n# Random forest uses random numbers so set the seed first\n\nset.seed(2)\nrf_res <- fit_resamples(rf_wflow, taxi_folds, control = ctrl_taxi)\ncollect_metrics(rf_res)\n#> # A tibble: 2 Ã— 6\n#>   .metric  .estimator  mean     n std_err .config             \n#>   <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n#> 1 accuracy binary     0.813    10 0.00305 Preprocessor1_Model1\n#> 2 roc_auc  binary     0.832    10 0.00513 Preprocessor1_Model1\n```\n:::\n\n\n## How can we compare multiple model workflows at once?\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/taxi_spinning.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Evaluate a workflow set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkflow_set(list(tip ~ .), list(tree_spec, rf_spec))\n#> # A workflow set/tibble: 2 Ã— 4\n#>   wflow_id              info             option    result    \n#>   <chr>                 <list>           <list>    <list>    \n#> 1 formula_decision_tree <tibble [1 Ã— 4]> <opts[0]> <list [0]>\n#> 2 formula_rand_forest   <tibble [1 Ã— 4]> <opts[0]> <list [0]>\n```\n:::\n\n\n## Evaluate a workflow set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkflow_set(list(tip ~ .), list(tree_spec, rf_spec)) %>%\n  workflow_map(\"fit_resamples\", resamples = taxi_folds)\n#> # A workflow set/tibble: 2 Ã— 4\n#>   wflow_id              info             option    result   \n#>   <chr>                 <list>           <list>    <list>   \n#> 1 formula_decision_tree <tibble [1 Ã— 4]> <opts[1]> <rsmp[+]>\n#> 2 formula_rand_forest   <tibble [1 Ã— 4]> <opts[1]> <rsmp[+]>\n```\n:::\n\n\n## Evaluate a workflow set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkflow_set(list(tip ~ .), list(tree_spec, rf_spec)) %>%\n  workflow_map(\"fit_resamples\", resamples = taxi_folds) %>%\n  rank_results()\n#> # A tibble: 4 Ã— 9\n#>   wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n#>   <chr>             <chr>   <chr>   <dbl>   <dbl> <int> <chr>        <chr> <int>\n#> 1 formula_rand_forâ€¦ Preproâ€¦ accuraâ€¦ 0.813 0.00339    10 formula      randâ€¦     1\n#> 2 formula_rand_forâ€¦ Preproâ€¦ roc_auc 0.833 0.00528    10 formula      randâ€¦     1\n#> 3 formula_decisionâ€¦ Preproâ€¦ accuraâ€¦ 0.793 0.00293    10 formula      deciâ€¦     2\n#> 4 formula_decisionâ€¦ Preproâ€¦ roc_auc 0.809 0.00461    10 formula      deciâ€¦     2\n```\n:::\n\n\nThe first metric of the metric set is used for ranking. Use `rank_metric` to change that.\n\n. . .\n\nLots more available with workflow sets, like `collect_metrics()`, `autoplot()` methods, and more!\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*When do you think a workflow set would be useful?*\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"discuss-workflow-sets\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## The whole game - status update\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/whole-game-select.jpg){fig-align='center' width=1772}\n:::\n:::\n\n\n## The final fit ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} \n\nSuppose that we are happy with our random forest model.\n\nLet's fit the model on the training set and verify our performance using the test set.\n\n. . .\n\nWe've shown you `fit()` and `predict()` (+ `augment()`) but there is a shortcut:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# taxi_split has train + test info\nfinal_fit <- last_fit(rf_wflow, taxi_split) \n\nfinal_fit\n#> # Resampling results\n#> # Manual resampling \n#> # A tibble: 1 Ã— 6\n#>   splits              id               .metrics .notes   .predictions .workflow \n#>   <list>              <chr>            <list>   <list>   <list>       <list>    \n#> 1 <split [7045/1762]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n\n\n## What is in `final_fit`? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(final_fit)\n#> # A tibble: 2 Ã— 4\n#>   .metric  .estimator .estimate .config             \n#>   <chr>    <chr>          <dbl> <chr>               \n#> 1 accuracy binary         0.810 Preprocessor1_Model1\n#> 2 roc_auc  binary         0.817 Preprocessor1_Model1\n```\n:::\n\n\n. . .\n\nThese are metrics computed with the **test** set\n\n## What is in `final_fit`? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_predictions(final_fit)\n#> # A tibble: 1,762 Ã— 7\n#>    id               .pred_yes .pred_no  .row .pred_class tip   .config          \n#>    <chr>                <dbl>    <dbl> <int> <fct>       <fct> <chr>            \n#>  1 train/test split     0.732   0.268     10 yes         no    Preprocessor1_Moâ€¦\n#>  2 train/test split     0.827   0.173     29 yes         yes   Preprocessor1_Moâ€¦\n#>  3 train/test split     0.899   0.101     35 yes         yes   Preprocessor1_Moâ€¦\n#>  4 train/test split     0.914   0.0856    42 yes         yes   Preprocessor1_Moâ€¦\n#>  5 train/test split     0.911   0.0889    47 yes         no    Preprocessor1_Moâ€¦\n#>  6 train/test split     0.848   0.152     54 yes         yes   Preprocessor1_Moâ€¦\n#>  7 train/test split     0.580   0.420     59 yes         yes   Preprocessor1_Moâ€¦\n#>  8 train/test split     0.912   0.0876    62 yes         yes   Preprocessor1_Moâ€¦\n#>  9 train/test split     0.810   0.190     63 yes         yes   Preprocessor1_Moâ€¦\n#> 10 train/test split     0.960   0.0402    69 yes         yes   Preprocessor1_Moâ€¦\n#> # â„¹ 1,752 more rows\n```\n:::\n\n\n## What is in `final_fit`? ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_workflow(final_fit)\n#> â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n#> Preprocessor: Formula\n#> Model: rand_forest()\n#> \n#> â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> tip ~ .\n#> \n#> â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> Ranger result\n#> \n#> Call:\n#>  ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) \n#> \n#> Type:                             Probability estimation \n#> Number of trees:                  1000 \n#> Sample size:                      7045 \n#> Number of independent variables:  6 \n#> Mtry:                             2 \n#> Target node size:                 10 \n#> Variable importance mode:         none \n#> Splitrule:                        gini \n#> OOB prediction error (Brier s.):  0.1373147\n```\n:::\n\n\n. . .\n\nUse this for **prediction** on new data, like for deploying\n\n## The whole game\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/whole-game-final-performance.jpg){fig-align='center' width=1772}\n:::\n:::\n\n\n## Your turn {transition=\"slide-in\"}\n\n![](images/parsnip-flagger.jpg){.absolute top=\"0\" right=\"0\" width=\"150\" height=\"150\"}\n\n*End of the day discussion!*\n\n*Which model do you think you would decide to use?*\n\n*What surprised you the most?*\n\n*What is one thing you are looking forward to for tomorrow?*\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"discuss-which-model\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"04-evaluating-models_files/libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"04-evaluating-models_files/libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}