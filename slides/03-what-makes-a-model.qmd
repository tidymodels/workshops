---
title: "3 - What makes a model?"
subtitle: "Machine learning with tidymodels"
format:
  revealjs: 
    slide-number: true
    footer: <https://workshops.tidymodels.org>
    include-before-body: header.html
    theme: [default, tidymodels.scss]
    width: 1280
    height: 720
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
---

```{r}
#| include: false
#| file: setup.R
```

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

*How do you fit a linear model in R?*

*How many different ways can you think of?*

```{r}
#| echo: false
countdown(minutes = 3, id = "how-to-fit-linear-model")
```

. . .

-   `lm` for generalized linear model

-   `glmnet` for regularized regression

-   `keras` for regression using TensorFlow

-   `stan` for Bayesian regression

-   `spark` for large data sets

## To specify a model `r hexes("parsnip")`

. . .

::: columns
::: {.column width="40%"}

-   Choose a [model]{.underline}
-   Specify an engine
-   Set the mode

:::

::: {.column width="60%"}

![](images/Ac_2tads.jpg)

:::
:::

## To specify a model `r hexes("parsnip")`

```{r}
#| echo: false
library(tidymodels)
data("tree_frogs", package = "stacks")
tree_frogs <- tree_frogs %>%
  mutate(t_o_d = factor(t_o_d)) %>%
  filter(!is.na(latency)) %>%
  select(-c(clutch, hatched))

set.seed(123)
frog_split <- initial_split(tree_frogs, prop = 0.8, strata = latency)
frog_train <- training(frog_split)
frog_test <- testing(frog_split)
```

```{r}
linear_reg()
```

## To specify a model `r hexes("parsnip")` 

::: columns
::: {.column width="40%"}

-   Choose a model
-   Specify an [engine]{.underline}
-   Set the mode

:::

::: {.column width="60%"}

![](images/Ac_2tads.jpg)

:::
:::

## To specify a model `r hexes("parsnip")`

```{r}
linear_reg() %>%
  set_engine("glmnet")
```

## To specify a model `r hexes("parsnip")`

```{r}
linear_reg() %>%
  set_engine("stan")
```

## To specify a model `r hexes("parsnip")` 

::: columns
::: {.column width="40%"}

-   Choose a model
-   Specify an engine
-   Set the [mode]{.underline}

:::

::: {.column width="60%"}

![](images/Ac_2tads.jpg)

:::
:::

## To specify a model `r hexes("parsnip")`

```{r}
decision_tree()
```

## To specify a model `r hexes("parsnip")`

```{r}
decision_tree() %>% 
  set_mode("regression")
```

. . .

<br></br>

::: {.r-fit-text}
All available models are listed at <https://www.tidymodels.org/find/parsnip/>
:::

##  {background-iframe="https://www.tidymodels.org/find/parsnip/"}

::: footer
:::

## To specify a model `r hexes("parsnip")`

::: columns
::: {.column width="40%"}

-   Choose a [model]{.underline}
-   Specify an [engine]{.underline}
-   Set the [mode]{.underline}

:::

::: {.column width="60%"}

![](images/Ac_2tads.jpg)

:::
:::


## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

*Run the `tree_spec` chunk in your `.qmd`.*

*Edit this code so it creates a different model.*

```{r}
#| echo: false
countdown(minutes = 5, id = "explore-tree-spec")
```

<br></br>

::: {.r-fit-text}
All available models are listed at <https://www.tidymodels.org/find/parsnip/>
:::

# A machine learning model *learns* from data

## All models are wrong but...

::: columns
::: {.column width="60%"}

```{r}
#| echo: false
#| fig.width: 8
#| fig.height: 7
ggplot(frog_test, aes(age, latency)) +
  geom_point(color = test_color, size = 3) +
  theme_minimal(base_size = 18)
```

:::

::: {.column width="40%"}

:::
:::

## All models are wrong but...

::: columns
::: {.column width="60%"}

```{r}
#| echo: false
#| fig.width: 8
#| fig.height: 7
linear_preds <- 
  linear_reg() %>%
  fit(latency ~ age, data = frog_train) %>%
  augment(new_data = frog_test)

ggplot(data = NULL, aes(age, latency)) +
  geom_segment(data = linear_preds,
               aes(x = age, xend = age, 
                   y = latency, yend = .pred), 
               colour = train_color, alpha = 0.8) +
  geom_smooth(data = frog_train, method = "lm", 
              se = FALSE, fullrange = TRUE,
              alpha = 0.8, size = 2, color = data_color) +
  geom_point(data = linear_preds, color = test_color, size = 3) +
  theme_minimal(base_size = 18)
```

:::

::: {.column width="40%"}

:::
:::


## All models are wrong but...

::: columns
::: {.column width="60%"}

```{r}
#| echo: false
#| fig.width: 8
#| fig.height: 7

ggplot(data = NULL, aes(age, latency)) +
  geom_segment(data = linear_preds,
               aes(x = age, xend = age, 
                   y = latency, yend = .pred), 
               colour = train_color, alpha = 0.8) +
  geom_smooth(data = frog_train, method = "lm", 
              se = FALSE, fullrange = TRUE,
              alpha = 0.8, size = 2, color = data_color) +
  geom_point(data = linear_preds, color = test_color, size = 3) +
  theme_minimal(base_size = 18)
```

:::

::: {.column width="40%"}

### Linear regression

- Ordinary least squares (OLS)

- Outcome modeled as linear combination of predictors

:::
:::

## All models are wrong but...


::: columns
::: {.column width="60%"}

```{r}
#| echo: false
#| fig.width: 8
#| fig.height: 7
tree_preds <- 
  decision_tree(cost_complexity = 0.015, mode = "regression") %>%
  fit(latency ~ age, data = frog_train) %>%
  augment(new_data = frog_test)

ggplot(data = tree_preds, aes(age, latency)) +
  geom_segment(aes(x = age, xend = age, 
                   y = latency, yend = .pred), 
               colour = train_color, alpha = 0.8) +
  geom_line(aes(x = age, y = .pred), size = 2, alpha = 0.8, color = data_color) +
  geom_point(data = tree_preds, color = test_color, size = 3) +
  theme_minimal(base_size = 18)
```

:::

::: {.column width="40%"}

:::
:::

## All models are wrong but...


::: columns
::: {.column width="60%"}

```{r}
#| echo: false
#| fig.width: 8
#| fig.height: 7

ggplot(data = tree_preds, aes(age, latency)) +
  geom_segment(aes(x = age, xend = age, 
                   y = latency, yend = .pred), 
               colour = train_color, alpha = 0.8) +
  geom_line(aes(x = age, y = .pred), size = 2, alpha = 0.8, color = data_color) +
  geom_point(data = tree_preds, color = test_color, size = 3) +
  theme_minimal(base_size = 18)
```

:::

::: {.column width="40%"}

### Decision tree

- Series of splits or if/then statements based on predictors

- First the tree *grows* until some condition is met (maximum depth, no more data)

- Then the tree is *pruned* to reduce its complexity

:::
:::


# ...some are useful! 

![](images/Hatching-process.jpg)

# A model workflow

##  {background-image="https://media.giphy.com/media/xUA7b0Klw8Wfor7FWo/giphy.gif" background-size="50%"}

# Placeholder for workflow diagrams from TMwR

## Why a `workflow()`? `r hexes("workflows")`

. . .

-   Workflows handle new data better than `model.matrix()` in terms of new factor levels

. . .

-   You can use other preprocessors besides formulas (more on feature engineering tomorrow!)

. . .

-   They can help organize your work when working with multiple models

. . .

-   [Most importantly]{.underline}, a workflow captures the entire modeling process: `fit()` and `predict()` apply to the preprocessing steps in addition to the actual model fit

## A model workflow `r hexes("parsnip", "workflows")`

```{r}
tree_spec <-
  decision_tree() %>% 
  set_mode("regression")

tree_spec %>% 
  fit(latency ~ ., data = frog_train) 
```

## A model workflow `r hexes("parsnip", "workflows")`

```{r}
tree_spec <-
  decision_tree() %>% 
  set_mode("regression")

workflow() %>%
  add_model(tree_spec) %>%
  add_formula(latency ~ .) %>%
  fit(data = frog_train) 
```

## A model workflow `r hexes("parsnip", "workflows")`

```{r}
tree_spec <-
  decision_tree() %>% 
  set_mode("regression")

workflow() %>%
  add_model(tree_spec) %>%
  add_variables(outcomes = latency, predictors = everything()) %>%
  fit(data = frog_train) 
```

## A model workflow `r hexes("parsnip", "workflows")`

```{r}
tree_spec <-
  decision_tree() %>% 
  set_mode("regression")

workflow(latency ~ ., tree_spec) %>% 
  fit(data = frog_train) 
```

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

*Run the `tree_wflow` chunk in your `.qmd`.*

*Edit this code so it:*

-   *creates a different model*
-   *uses one of the other `workflow()` interfaces*

```{r}
#| echo: false
countdown(minutes = 5, id = "explore-tree-workflow")
```

## Predict with your model `r hexes("parsnip", "workflows")`

How do you use your new `tree_fit` model?

```{r}
tree_spec <-
  decision_tree() %>% 
  set_mode("regression")

tree_fit <-
  workflow(latency ~ ., tree_spec) %>% 
  fit(data = frog_train) 
```

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

*Run:*

`predict(tree_fit, new_data = frog_test)`

*What do you get?*

```{r}
#| echo: false
countdown(minutes = 3, id = "predict-tree-fit")
```

## Your turn

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

*Run:*

`augment(tree_fit, new_data = frog_test)`

*What do you get?*

```{r}
#| echo: false
countdown(minutes = 3, id = "augment-tree-fit")
```

# The tidymodels prediction guarantee! `r hexes("parsnip", "workflows")`

. . .

-   The predictions will always be inside a **tibble**
-   The column names and types are **unsurprising** and **predictable**
-   The number of rows in `new_data` and the output **are the same**

## Understand your model `r hexes("parsnip", "workflows")`

How do you **understand** your new `tree_fit` model?

. . .

You can use your fitted workflow for model and/or prediction explanations:

. . .

-   overall variable importance, such as with the [vip](https://koalaverse.github.io/vip/) package

. . .

-   flexible model explainers, such as with the [DALEXtra](https://dalex.drwhy.ai/) package

. . .

Learn more at <https://www.tmwr.org/explain.html>

## Understand your model `r hexes("parsnip", "workflows")`

How do you **understand** your new `tree_fit` model?

```{r}
#| echo: false
library(rpart.plot)
tree_fit %>%
  extract_fit_engine() %>%
  rpart.plot()
```

## Understand your model `r hexes("parsnip", "workflows")`

How do you **understand** your new `tree_fit` model?

```{r}
#| eval: false
library(rpart.plot)
tree_fit %>%
  extract_fit_engine() %>%
  rpart.plot()
```

You can `extract_*()` several components of your fitted workflow.

##  {background-iframe="https://hardhat.tidymodels.org/reference/hardhat-extract.html"}

::: footer
:::

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

*Read the [documentation for object extraction](https://hardhat.tidymodels.org/reference/hardhat-extract.html).*

*Try out some extraction methods on your trained workflow.*

⚠️ *Never `predict()` with any extracted components!*

```{r}
#| echo: false
countdown(minutes = 5, id = "extract-methods")
```

## Deploy your model `r hexes("vetiver")`

How do you use your new `tree_fit` model in **production**?

```{r}
library(vetiver)
v <- vetiver_model(tree_fit, "frog_hatching")
v
```

Learn more at <https://vetiver.rstudio.com>

## Deploy your model `r hexes("vetiver")`

How do you use your new model `tree_fit` in **production**?

```{r}
library(plumber)
pr() %>%
  vetiver_api(v)
```

Learn more at <https://vetiver.rstudio.com>

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

*Run the `vetiver` chunk in your `.qmd`.*

*Check out the automated visual documentation.*

```{r}
#| echo: false
countdown(minutes = 5, id = "vetiver")
```
