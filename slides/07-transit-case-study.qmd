---
title: "7 - Case Study on Transportation"
subtitle: "Machine learning with tidymodels"
format:
  revealjs: 
    slide-number: true
    footer: <https://workshops.tidymodels.org>
    include-before-body: header.html
    include-after-body: footer-annotations.html
    theme: [default, tidymodels.scss]
    width: 1280
    height: 720
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
---

```{r}
#| label: setup
#| include: false
#| file: setup.R
```

```{r}
#| label: more-setup
#| include: false

library(leaflet)
library(tidymodels)
tidymodels_prefer()

data(Chicago)

cores <- parallel::detectCores(logical = FALSE)
cl <- parallel::makePSOCKcluster(cores)
doParallel::registerDoParallel(cl)

options(width = 200)

ggplot2::theme_set(ggplot2::theme_bw())
```

## Chicago L-Train data

Several years worth of pre-pandemic data were assembled to try to predict the daily number of people entering the Clark and Lake elevated ("L") train station in Chicago. 


More information: 

- Several Chapters in _Feature Engineering and Selection_. 

  - Start with [Section 4.1](https://bookdown.org/max/FES/chicago-intro.html) 
  - See [Section 1.3](https://bookdown.org/max/FES/a-more-complex-example.html)

- Video: [_The Global Pandemic Ruined My Favorite Data Set_](https://www.youtube.com/watch?v=KkpKSqbGnBA)


## Predictors

- the 14-day lagged ridership at this and other stations (units: thousands of rides/day)
- weather data
- home/away game schedules for Chicago teams
- the date

The data are in `modeldata`. See `?Chicago`. 


## L Train Locations

```{r}
#| label: chicago
#| echo: false
#| out-width: 100%
load("station_locations.RData")
other_stations <- 
  station_locations %>% 
  filter(!grepl("Clark/Lake", description, fixed = TRUE))
clark_lake <- 
  anti_join(station_locations, other_stations, by = c("lon", "lat", "description"))
leaflet() %>%
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addCircleMarkers(
    other_stations$lon,
    other_stations$lat,
    popup = other_stations$description,
    color = "red",
    radius = 3
  ) %>%
  addCircleMarkers(
    clark_lake$lon,
    clark_lake$lat,
    color = "green",
    radius = 6
  )
```

## Your turn: Explore the Data

Take a look at these data for a few minutes and see if you can find any interesting characteristics in the predictors or the outcome.  


```{r}
#| label: turn-setup
library(tidymodels)
data("Chicago")
dim(Chicago)
stations
```

```{r}
#| echo: false
countdown(minutes = 5, id = "explore-chicago")
```


## Splitting with Chicago data

Let's put the last two weeks of data into the test set. `initial_time_split()` can be used for this purpose:

```{r}
#| label: split

data(Chicago)

chi_split <- initial_time_split(Chicago, prop = 1 - (14/nrow(Chicago)))
chi_split

chi_train <- training(chi_split)
chi_test  <- testing(chi_split)

c(training = nrow(chi_train), testing = nrow(chi_test))
```

## Time series resampling

Our Chicago data is over time. Regular cross-validation, which uses random sampling, may not be the best idea. 

We can emulate our training/test split by making similar resamples. 

* Fold 1: Take the first X years of data as the analysis set, the next 2 weeks as the assessment set.

* Fold 2: Take the first X years + 2 weeks of data as the analysis set, the next 2 weeks as the assessment set.

* and so on

##  Rolling forecast origin resampling

```{r}
#| label: rolling
#| echo: false
#| out.width: 65%
#| fig.align: center
#| out-width: "70%"

knitr::include_graphics("images/rolling.svg")
```

##  Using rsample to do this

```{r}
#| eval: false
#| code-line-numbers: "4"

chi_rs <-
  chi_train %>%
  sliding_period(
    index = "date"  
    
    
    
    
  )
```

Use the `date` column to find the date data. 


##   Using rsample to do this

```{r}
#| eval: false
#| code-line-numbers: "5"

chi_rs <-
  chi_train %>%
  sliding_period(
    index = "date",  
    period = "week"  
    
    
  )
```

Our units will be weeks. 


##   Using rsample to do this

```{r}
#| eval: false
#| code-line-numbers: "6"

chi_rs <-
  chi_train %>%
  sliding_period(
    index = "date",  
    period = "week",
    lookback = 52 * 15  
    
  )
```

Every analysis set has 15 years of data



##   Using rsample to do this

```{r}
#| eval: false
#| code-line-numbers: "7"

chi_rs <-
  chi_train %>%
  sliding_period(
    index = "date",  
    period = "week",
    lookback = 52 * 15,
    assess_stop = 2 
    
  )
```

Every assessment set has 2 weeks of data


##   Using rsample to do this

```{r}
#| code-line-numbers: "8"

chi_rs <-
  chi_train %>%
  sliding_period(
    index = "date",  
    period = "week",
    lookback = 52 * 15,
    assess_stop = 2,
    step = 2 
  )
```

Increment by 2 weeks so that there are no overlapping assessment sets. 

```{r}
chi_rs$splits[[1]] %>% assessment() %>% pluck("date") %>% range()
chi_rs$splits[[2]] %>% assessment() %>% pluck("date") %>% range()
```

## Feature engineering



## Our resampling object

::: columns
::: {.column width="45%"}

```{r}
chi_rs
```

:::

::: {.column width="5%"}

:::

::: {.column width="50%"}

We will fit `r nrow(chi_rs)` models on  `r nrow(chi_rs)` slightly different analysis sets. 

Each will produce a separate RMSE and we will average the  `r nrow(chi_rs)` RMSE values to get the resampling estimate of that statistic. 

:::
:::


## Feature engineering



## A recipe

```{r}
chi_rec <- 
  recipe(ridership ~ ., data = chi_train)
# If ncol(data) is large, you can use
# recipe(data = chi_train)
```

Based on the formula, the function assigns columns to roles of "outcome" or "predictor"

## A recipe

```{r}
summary(chi_rec)
```



## A recipe - work with dates

```{r}
#| code-line-numbers: "3"
chi_rec <- 
  recipe(ridership ~ ., data = chi_train) %>% 
  step_date(date, features = c("dow", "month", "year")) 
```

This creates three new columns in the data based on the date. Now that the day-of-the-week column is a factor.


## A recipe - work with dates

```{r}
#| code-line-numbers: "4"
chi_rec <- 
  recipe(ridership ~ ., data = chi_train) %>% 
  step_date(date, features = c("dow", "month", "year")) %>% 
  step_holiday(date) 
```

Add indicators for major holidays. Specific holidays, especially those ex-US, can also be generated. 

At this point, we don't need `date` anymore. Instead of deleting it (there is a step for that) we will change its _role_ to be an identification variable. 


## A recipe - work with dates

```{r}
#| code-line-numbers: "5"
chi_rec <- 
  recipe(ridership ~ ., data = chi_train) %>% 
  step_date(date, features = c("dow", "month", "year")) %>% 
  step_holiday(date) %>% 
  update_role(date, new_role = "id")
```

`date` is still in the data set but tidymodels knows not to treat it as an analysis column. 


## A recipe -create indicator variables

```{r}
#| code-line-numbers: "6"
chi_rec <- 
  recipe(ridership ~ ., data = chi_train) %>% 
  step_date(date, features = c("dow", "month", "year")) %>% 
  step_holiday(date) %>% 
  update_role(date, new_role = "id") %>% 
  step_dummy(all_nominal_predictors()) 
```

For any factor or character predictors, make binary indicators. 

There are _many_ recipe steps that can convert categorical predictors to numeric columns. 



## A recipe - filter out constant columns

```{r}
#| code-line-numbers: "7"
chi_rec <- 
  recipe(ridership ~ ., data = chi_train) %>% 
  step_date(date, features = c("dow", "month", "year")) %>% 
  step_holiday(date) %>% 
  update_role(date, new_role = "id") %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) 
```

In case there is a holiday that never was observed, we can delete any _zero-variance_ predictors that have a single unique value.

Note that the selector chooses all columns with a role of "predictor"



## A recipe - normalization

```{r}
#| code-line-numbers: "8"
chi_rec <- 
  recipe(ridership ~ ., data = chi_train) %>% 
  step_date(date, features = c("dow", "month", "year")) %>% 
  step_holiday(date) %>% 
  update_role(date, new_role = "id") %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors()) 
```

This centers and scales the numeric predictors. 

Note that this will use the training set to estimate the means and standard deviations of the data. 

All data put through the recipe will be normalized using those statistics (there is no re-estimation). 



