---
title: "Extras - Recipes"
subtitle: "Introduction to tidymodels"
format:
  revealjs: 
    slide-number: true
    footer: <https://workshops.tidymodels.org>
    include-before-body: header.html
    include-after-body: footer-annotations.html
    theme: [default, tidymodels.scss]
    width: 1280
    height: 720
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
    fig.path: "figures/"
---

```{r}
#| label: setup
#| include: false
#| file: setup.R
```

## Looking at the predictors

```{r}
#| label: setup-previous
#| echo: false
library(countdown)
library(tidymodels)
library(modeldatatoo)
taxi <- data_taxi()

set.seed(123)
taxi_split <- initial_split(taxi, prop = 0.8, strata = tip)
taxi_train <- training(taxi_split)
taxi_test <- testing(taxi_split)

tree_spec <- decision_tree(cost_complexity = 0.0001, mode = "classification")
taxi_wflow <- workflow(tip ~ ., tree_spec)
taxi_fit <- fit(taxi_wflow, taxi_train)
```

```{r}
#| label: more-setup
#| include: false
library(countdown)

options(width = 200)

ggplot2::theme_set(ggplot2::theme_bw())
```

```{r}
#| label: taxi_train
taxi_train
```

## Working with other models

Some models can't handle non-numeric data

-   Linear Regression
-   K Nearest Neighbors

<br>

::: fragment
Some models struggle if numeric predictors aren't scaled

-   K Nearest Neighbors
-   Anything using gradient descent
:::

## Types of needed preprocessing

-   Do qualitative predictors require a numeric encoding?

-   Should columns with a single unique value be removed?

-   Does the model struggle with missing data?

-   Does the model struggle with correlated predictors?

-   Should predictors be centered and scaled?

-   Is it helpful to transform predictors to be more symmetric?

::: footer
<https://www.tmwr.org/pre-proc-table.html>
:::

## Two types of preprocessing

![](images/fe_venn.svg){fig-align="center"}

## Two types of preprocessing

![](images/fe_venn_info.svg){fig-align="center"}

## General definitions

* _Data preprocessing_ are the steps that you take to make your model **successful**.
* _Feature engineering_ are what you do to the original predictors to make the model do the **least work** to perform great.

## Working with dates

Datetime variables are automatically converted to an integer if given as a raw predictor. To avoid this, it can be re-encoded as:

* Days since a reference date
* Day of the week
* Month
* Year
* Leap year
* Indicators for holidays

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

<br>

*What other transformations could we do with the raw time variable?*

*Remember that the transformations are tied to the specific modeling problem.*

```{r}
#| label: datetime-split-exercise
#| echo: false
countdown(minutes = 3, id = "datetime-split")
```

## Two types of transformations

<br>

::: columns
::: {.column width="50%"}

### Static

- Square root, log, inverse
- Dummies for known levels
- Date time extractions

:::

::: {.column width="50%"}

### Trained

- Centering & scaling
- Imputation
- PCA
- Anything for unknown factor levels

:::

:::

::: fragment
Trained methods need to calculate **sufficient information** to be applied again.
:::

## The recipes package

::: {.incremental .highlight-last}
- Modular + extensible
- Works well with pipes ,`|>` and `%>%`
- Deferred evaluation
- Isolates test data from training data
- Can do things formulas can't
:::


## How to write a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
taxi_rec <- recipe(tip ~ ., data = taxi_train) %>%  
\ \ step_unknown(all_nominal_predictors()) %>%  
\ \ step_dummy(all_nominal_predictors()) %>%  
\ \ step_zv(all_predictors()) %>%  
\ \ step_log(distance, offset = 0.5) %>%  
\ \ step_normalize(all_numeric_predictors())
:::

## How to write a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
taxi_rec <- [recipe(tip ~ ., data = taxi_train)]{style="color: #CA225E;"} %>%  
\ \ step_unknown(all_nominal_predictors()) %>%  
\ \ step_dummy(all_nominal_predictors()) %>%  
\ \ step_zv(all_predictors()) %>%  
\ \ step_log(distance, offset = 0.5) %>%  
\ \ step_normalize(all_numeric_predictors())
:::

<br>

Start by calling `recipe()` to denote the data source and variables used.

## How to write a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
taxi_rec <- recipe(tip ~ ., data = taxi_train) %>%  
\ \ [step_unknown]{style="color: #CA225E;"}(all_nominal_predictors()) %>%  
\ \ [step_dummy]{style="color: #CA225E;"}(all_nominal_predictors()) %>%  
\ \ [step_zv]{style="color: #CA225E;"}(all_predictors()) %>%  
\ \ [step_log]{style="color: #CA225E;"}(distance, offset = 0.5) %>%  
\ \ [step_normalize]{style="color: #CA225E;"}(all_numeric_predictors())
:::

<br>

Specify what actions to take by adding `step_*()`s.

## How to write a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
taxi_rec <- recipe(tip ~ ., data = taxi_train) %>%  
\ \ step_unknown([all_nominal_predictors()]{style="color: #CA225E;"}) %>%  
\ \ step_dummy([all_nominal_predictors()]{style="color: #CA225E;"}) %>%  
\ \ step_zv([all_predictors()]{style="color: #CA225E;"}) %>%  
\ \ step_log([distance]{style="color: #CA225E;"}, offset = 0.5) %>% 
\ \ step_normalize([all_numeric_predictors()]{style="color: #CA225E;"})
:::
<br>

Use {tidyselect} and recipes-specific selectors to denote affected variables.

## Using a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
taxi_rec <- recipe(tip ~ ., data = taxi_train) %>%  
\ \ step_unknown(all_nominal_predictors()) %>%  
\ \ step_dummy(all_nominal_predictors()) %>%  
\ \ step_zv(all_predictors()) %>%  
\ \ step_log(distance, offset = 0.5) %>% 
\ \ step_normalize(all_numeric_predictors())
:::

<br>

Save the recipe we like so that we can use it in various places, e.g., with different models.

<br>

## Using a recipe with workflows

Recipes are typically combined with a model in a `workflow()` object:

<br>

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
taxi_wflow <- workflow() %>%  
\ \ [add_recipe(taxi_rec)]{style="color: #CA225E;"} %>%  
\ \ add_model(linear_reg())
:::

## Recipes are estimated

Every preprocessing step in a recipe that involved calculations uses the *training* set. For example:

- Levels of a factor
- Determination of zero-variance
- Normalization
- Feature extraction

Once a recipe is added to a workflow, this occurs when `fit()` is called.


## Debugging a recipe

- Typically, you will want to use a workflow to estimate and apply a recipe.

. . .

- If you have an error and need to debug your recipe, the original recipe object (e.g. `taxi_rec`) can be estimated manually with a function called `prep()`. It is analogous to `fit()`. See [TMwR section 16.4](https://www.tmwr.org/dimensionality.html#recipe-functions).

. . .

- Another function, `bake()`, is analogous to `predict()`, and gives you the processed data back.

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

<br>

*Take the recipe and `prep()` then `bake()` it to see what the resulting data set looks like.*

*Try removing steps to see how the result changes.*

<br>

```{r}
#| label: recipes-prep-exercise
#| echo: false
countdown(minutes = 5, id = "recipes-prep")
```

## Printing a recipe

```{r}
#| label: taxi_rec
#| echo: false
taxi_rec <- recipe(tip ~ ., data = taxi_train) %>%  
  step_unknown(all_nominal_predictors()) %>%  
  step_dummy(all_nominal_predictors()) %>%  
  step_zv(all_predictors()) %>%  
  step_log(distance, offset = 0.5) %>% 
  step_normalize(all_numeric_predictors())
```

```{r}
#| label: taxi_rec-printing
#| message: true
taxi_rec
```

## Prepping a recipe

```{r}
#| label: taxi_rec-prep-printing
#| message: true
prep(taxi_rec)
```

## Baking a recipe

```{r}
#| label: taxi_rec-prep-bake-printing
prep(taxi_rec) %>%
  bake(new_data = taxi_train)
```

## Tidying a recipe

Once a recipe as been estimated, there are various bits of information saved in it.

- The `tidy()` function can be used to get specific results from the recipe.

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

*Take a prepped recipe and use the `tidy()` function on it.*

*Use the `number` argument to inspect different steps.*

<br>

```{r}
#| label: recipes-tidy-exercise
#| echo: false
countdown(minutes = 5, id = "recipes-tidy")
```

## Tidying a recipe

```{r}
#| label: taxi_rec-tidy
prep(taxi_rec) %>%
  tidy()
```

## Tidying a recipe

```{r}
#| label: taxi_rec-tidy-2
prep(taxi_rec) %>%
  tidy(number = 2)
```


## Using a recipe in tidymodels

The recommended way to use a recipe in tidymodels is to use it as part of a `workflow()`.

```{r}
#| label: recipes-and-workflows
taxi_wflow <- workflow() %>%  
  add_recipe(taxi_rec) %>%  
  add_model(linear_reg())
```

When used in this way, you don't need to worry about `prep()` and `bake()` as it is handled for you.

## More information

- <https://recipes.tidymodels.org/>
- <https://www.tmwr.org/recipes.html>
