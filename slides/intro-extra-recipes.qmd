---
title: "Extras - Recipes"
subtitle: "Introduction to tidymodels"
format:
  revealjs: 
    slide-number: true
    footer: <https://workshops.tidymodels.org>
    include-before-body: header.html
    include-after-body: footer-annotations.html
    theme: [default, tidymodels.scss]
    width: 1280
    height: 720
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
    fig.path: "figures/"
---

```{r}
#| label: setup
#| include: false
#| file: setup.R
```

## Looking at the predictors

```{r}
#| label: setup-previous
#| echo: false
library(tidymodels)
library(forested)

set.seed(123)
forested_split <- initial_split(forested_ga, prop = 0.8)
forested_train <- training(forested_split)
forested_test <- testing(forested_split)

tree_spec <- decision_tree(cost_complexity = 0.0001, mode = "classification")
forested_wflow <- workflow(forested ~ ., tree_spec)
forested_fit <- fit(forested_wflow, forested_train)
```

```{r}
#| label: more-setup
#| include: false
options(width = 200)

ggplot2::theme_set(ggplot2::theme_bw())
```

```{r}
#| label: forested_train
forested_train
```

## Working with other models

Some models can't handle non-numeric data

-   Linear Regression
-   K Nearest Neighbors

<br>

::: fragment
Some models struggle if numeric predictors aren't scaled

-   K Nearest Neighbors
-   Anything using gradient descent
:::

## Types of needed preprocessing

-   Do qualitative predictors require a numeric encoding?

-   Should columns with a single unique value be removed?

-   Does the model struggle with missing data?

-   Does the model struggle with correlated predictors?

-   Should predictors be centered and scaled?

-   Is it helpful to transform predictors to be more symmetric?

::: footer
<https://www.tmwr.org/pre-proc-table.html>
:::

## Two types of preprocessing

![](images/fe_venn.svg){fig-align="center"}

## Two types of preprocessing

![](images/fe_venn_info.svg){fig-align="center"}

## General definitions

* _Data preprocessing_ is what you do to make your model **successful**.
* _Feature engineering_ is what you do to the original predictors to make the model do the **least work** to perform great.

## Working with dates

Datetime variables are automatically converted to an integer if given as a raw predictor. To avoid this, it can be re-encoded as:

* Days since a reference date
* Day of the week
* Month
* Year
* Leap year
* Indicators for holidays

## Two types of transformations

<br>

::: columns
::: {.column width="50%"}

### Static

- Square root, log, inverse
- Dummies for known levels
- Date time extractions

:::

::: {.column width="50%"}

### Trained

- Centering & scaling
- Imputation
- PCA
- Anything for unknown factor levels

:::

:::

::: fragment
Trained methods need to calculate **sufficient information** to be applied again.
:::

## The recipes package

::: {.incremental .highlight-last}
- Modular + extensible
- Works well with pipes ,`|>` and `%>%`
- Deferred evaluation
- Isolates test data from training data
- Can do things formulas can't
:::


## How to write a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
forested_rec <- recipe(forested ~ ., data = forested_train) |>  
\ \ step_dummy(all_nominal_predictors()) |>  
\ \ step_zv(all_predictors()) |>  
\ \ step_log(canopy_cover, offset = 0.5) |>  
\ \ step_normalize(all_numeric_predictors())
:::

## How to write a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
forested_rec <- [recipe(forested ~ ., data = forested_train)]{style="color: #CA225E;"} |>  
\ \ step_dummy(all_nominal_predictors()) |>  
\ \ step_zv(all_predictors()) |>  
\ \ step_log(canopy_cover, offset = 0.5) |>  
\ \ step_normalize(all_numeric_predictors())
:::

<br>

Start by calling `recipe()` to denote the data source and variables used.

## How to write a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
forested_rec <- recipe(forested ~ ., data = forested_train) |>  
\ \ [step_dummy]{style="color: #CA225E;"}(all_nominal_predictors()) |>  
\ \ [step_zv]{style="color: #CA225E;"}(all_predictors()) |>  
\ \ [step_log]{style="color: #CA225E;"}(canopy_cover, offset = 0.5) |>  
\ \ [step_normalize]{style="color: #CA225E;"}(all_numeric_predictors())
:::

<br>

Specify what actions to take by adding `step_*()`s.

## How to write a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
forested_rec <- recipe(forested ~ ., data = forested_train) |>  
\ \ step_dummy([all_nominal_predictors()]{style="color: #CA225E;"}) |>  
\ \ step_zv([all_predictors()]{style="color: #CA225E;"}) |>  
\ \ step_log([canopy_cover]{style="color: #CA225E;"}, offset = 0.5) |> 
\ \ step_normalize([all_numeric_predictors()]{style="color: #CA225E;"})
:::
<br>

Use {tidyselect} and recipes-specific selectors to denote affected variables.

## Using a recipe

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
forested_rec <- recipe(forested ~ ., data = forested_train) |>  
\ \ step_dummy(all_nominal_predictors()) |>  
\ \ step_zv(all_predictors()) |>  
\ \ step_log(canopy_cover, offset = 0.5) |> 
\ \ step_normalize(all_numeric_predictors())
:::

<br>

Save the recipe we like so that we can use it in various places, e.g., with different models.

<br>

## Using a recipe with workflows

Recipes are typically combined with a model in a `workflow()` object:

<br>

:::{style="font-family: 'Source Code Pro', monospace; font-size: 0.8em;"}
forested_wflow <- workflow() |>  
\ \ [add_recipe(forested_rec)]{style="color: #CA225E;"} |>  
\ \ add_model(linear_reg())
:::

## Recipes are estimated

Every preprocessing step in a recipe that involved calculations uses the *training* set. For example:

- Levels of a factor
- Determination of zero-variance
- Normalization
- Feature extraction

Once a recipe is added to a workflow, this occurs when `fit()` is called.


## Debugging a recipe

- Typically, you will want to use a workflow to estimate and apply a recipe.

. . .

- If you have an error and need to debug your recipe, the original recipe object (e.g. `forested_rec`) can be estimated manually with a function called `prep()`. It is analogous to `fit()`. See [TMwR section 16.4](https://www.tmwr.org/dimensionality.html#recipe-functions).

. . .

- Another function, `bake()`, is analogous to `predict()`, and gives you the processed data back.

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

<br>

*Take the recipe and `prep()` then `bake()` it to see what the resulting data set looks like.*

*Try removing steps to see how the result changes.*

<br>

```{r}
#| label: recipes-prep-exercise
#| echo: false
countdown::countdown(minutes = 5, id = "recipes-prep")
```

## Printing a recipe

```{r}
#| label: forested_rec
#| echo: false
forested_rec <- recipe(forested ~ ., data = forested_train) |>  
  step_dummy(all_nominal_predictors()) |>  
  step_zv(all_predictors()) |>  
  step_log(canopy_cover, offset = 0.5) |> 
  step_normalize(all_numeric_predictors())
```

```{r}
#| label: forested_rec-printing
#| message: true
forested_rec
```

## Prepping a recipe

```{r}
#| label: forested_rec-prep-printing
#| message: true
prep(forested_rec)
```

## Baking a recipe

```{r}
#| label: forested_rec-prep-bake-printing
prep(forested_rec) |>
  bake(new_data = forested_train)
```

## Tidying a recipe

Once a recipe as been estimated, there are various bits of information saved in it.

- The `tidy()` function can be used to get specific results from the recipe.

## Your turn {transition="slide-in"}

![](images/parsnip-flagger.jpg){.absolute top="0" right="0" width="150" height="150"}

*Take a prepped recipe and use the `tidy()` function on it.*

*Use the `number` argument to inspect different steps.*

<br>

```{r}
#| label: recipes-tidy-exercise
#| echo: false
countdown::countdown(minutes = 5, id = "recipes-tidy")
```

## Tidying a recipe

```{r}
#| label: forested_rec-tidy
prep(forested_rec) |>
  tidy()
```

## Tidying a recipe

```{r}
#| label: forested_rec-tidy-2
prep(forested_rec) |>
  tidy(number = 1)
```


## Using a recipe in tidymodels

The recommended way to use a recipe in tidymodels is to use it as part of a `workflow()`.

```{r}
#| label: recipes-and-workflows
forested_wflow <- workflow() |>  
  add_recipe(forested_rec) |>  
  add_model(linear_reg())
```

When used in this way, you don't need to worry about `prep()` and `bake()` as it is handled for you.

## More information

- <https://recipes.tidymodels.org/>
- <https://www.tmwr.org/recipes.html>
