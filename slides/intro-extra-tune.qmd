---
title: "Extras - Tuning"
subtitle: "Introduction to tidymodels"
format:
  revealjs: 
    slide-number: true
    footer: <https://workshops.tidymodels.org>
    include-before-body: header.html
    include-after-body: footer-annotations.html
    theme: [default, tidymodels.scss]
    width: 1280
    height: 720
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
    fig.path: "figures/"
---

```{r}
#| label: setup
#| include: false
#| file: setup.R
```

```{r setup-previous}
#| echo: false
library(tidymodels)
library(modeldatatoo)

taxi <- data_taxi()

set.seed(123)
taxi_split <- initial_split(taxi, prop = 0.8, strata = tip)
taxi_train <- training(taxi_split)
taxi_test <- testing(taxi_split)

set.seed(123)
taxi_folds <- vfold_cv(taxi_train, v = 10, strata = tip)
```

## Tuning parameters

Some model or preprocessing parameters cannot be estimated directly from the data.

. . .

Some examples:

- Tree depth in decision trees
- Number of neighbors in a K-nearest neighbor model

## Optimize tuning parameters

- Try different values and measure their performance.

. . .

- Find good values for these parameters.

. . .

- Once the value(s) of the parameter(s) are determined, a model can be finalized by fitting the model to the entire training set.

## Optimize tuning parameters

The main two strategies for optimization are:

. . .

-   **Grid search** ðŸ’  which tests a pre-defined set of candidate values

-   **Iterative search** ðŸŒ€ which suggests/estimates new values of candidate parameters to evaluate

## Specifying tuning parameters

Let's take our previous random forest workflow and tag the number of trees for tuning:

```{r}
#| label: tag-for-tuning
#| code-line-numbers: "1|"

rf_spec <- rand_forest(trees = tune()) %>% 
  set_mode("classification")

rf_wflow <- workflow(tip ~ ., rf_spec)
rf_wflow
```

## Try out multiple values

`tune_grid()` works similar to `fit_resamples()` but covers multiple parameter values:

```{r}
#| label: rf-tune_grid
#| code-line-numbers: "2|3-4|5|"

set.seed(2)
rf_res <- tune_grid(
  rf_wflow,
  taxi_folds,
  grid = 3
)
```

## Compare results

Inspecting results and select the best-performing hyperparameter(s):

```{r}
#| label: rf-results

show_best(rf_res)

best_parameter <- select_best(rf_res)
best_parameter
```

`collect_metric()` and `autoplot()` are also available for tune results.

## The final fit

```{r}
#| label: rf-finalize

rf_wflow <- finalize_workflow(rf_wflow, best_parameter)

final_fit <- last_fit(rf_wflow, taxi_split) 

collect_metrics(final_fit)
```
